
Appendix I: Autonomous Weapons Systems: The Third Revolution in Warfare

1.0 Introduction: A New Paradigm of Conflict

1.1 The Dawn of Algorithmic Warfare

The character of warfare is undergoing a transformation as profound as those precipitated by the invention of gunpowder and the advent of nuclear arms.1 This contemporary shift is driven by the maturation of artificial intelligence (AI) and robotics, giving rise to a new class of military technology: Autonomous Weapons Systems (AWS). These systems represent a fundamental departure from previous military innovations by delegating aspects of lethal decision-making from human soldiers and commanders to machines.3 At their core, AWS are military platforms that, once activated, can independently conduct missions—including searching for, identifying, tracking, and in some cases, engaging targets—without direct human intervention.4
The integration of AI into weapon systems allows for military operations to be conducted at a speed, scale, and level of complexity that exceeds the limits of human cognition and reaction time.3 This algorithmic capability promises significant military advantages, such as the ability to operate in communications-denied environments, reduce casualties by removing human warfighters from dangerous missions, and act as a "force multiplier" by allowing fewer personnel to manage a greater number of assets.2 However, this same capability introduces unprecedented strategic risks. The prospect of machines with the power and discretion to take human lives without direct human involvement raises profound ethical questions, creates complex legal challenges regarding accountability, and threatens global security through the potential for accidental and rapid conflict escalation.3

1.2 The Spectrum of Autonomy

It is crucial to understand that autonomy in weapon systems is not a monolithic or binary concept. Rather than a simple switch from "human-controlled" to "machine-controlled," autonomy exists on a spectrum defined by the nature and degree of human involvement in the decision-making process.6 This spectrum ranges from semi-autonomous systems, such as "fire and forget" missiles that guide themselves to a human-selected target, to highly autonomous defensive systems that can react to incoming threats faster than a human operator, to the theoretical and highly contentious category of fully autonomous systems that could independently execute an entire lethal mission from start to finish.6
The discourse surrounding AWS is often clouded by sensationalized imagery of "killer robots," a term that, while evocative, fails to capture the nuanced technical and operational realities of these systems.3 A more precise understanding requires a framework for classifying systems based on their control architecture—the specific relationship between the human operator and the machine's functions. This appendix will provide a detailed technical and strategic breakdown of these systems, moving beyond simplistic tropes to analyze the current state of autonomous military technology, the enabling technologies driving its evolution, and the critical legal, ethical, and geopolitical dilemmas it presents to the international community.

2.0 Defining Autonomy in Weapon Systems

The foundation of any rigorous analysis of autonomous warfare is a clear and precise lexicon. However, the international community has yet to reach a consensus on a universal definition for these systems, a factor that significantly complicates diplomatic efforts to establish regulations.6 This lack of a common definition is not merely an academic oversight but a central feature of the geopolitical landscape, as different definitions can be strategically employed to either constrain or permit the development of certain technologies.

2.1 Clarifying the Terminology

For the purposes of this analysis, it is useful to distinguish between two key terms:
Autonomous Weapons Systems (AWS): This is a broad category encompassing any military system that, once activated, can independently conduct assigned missions or carry out specific tasks without human intervention.4 This can include non-lethal functions such as intelligence, surveillance, and reconnaissance (ISR), navigation in complex environments, or logistical support.
Lethal Autonomous Weapon Systems (LAWS): This is a specific and more controversial subset of AWS. LAWS are defined as weapon systems that utilize sensor suites and computer algorithms to independently search for, identify, select, and engage targets with lethal force without manual human control of the system.6 These systems, sometimes referred to as "slaughterbots" by critics, are pre-programmed to kill a specific "target profile" and, once deployed, use AI to find and eliminate anything that matches that profile based on sensor data alone.3 It is this category of weapon that sits at the heart of the global debate.
The definitional ambiguity is a critical component of international strategy. For instance, China has publicly supported a ban on LAWS but has proposed an exceedingly narrow definition that includes criteria such as the "impossibility of termination" and the ability to "autonomously learn and expand its functions and capabilities beyond human expectations".12 Such a definition describes a hypothetical, highly advanced future system that does not currently exist, thereby excluding a wide range of highly autonomous systems from any potential prohibition. This approach allows a nation to appear supportive of arms control while simultaneously pursuing the development of sophisticated AWS that fall outside its own restrictive definition. This semantic maneuvering highlights that the debate over definitions is, in itself, a strategic effort to shape the future legal and operational environment for autonomous warfare.

2.2 The U.S. Department of Defense Framework (DoDD 3000.09)

In the absence of an international consensus, the most influential and detailed policy framework governing autonomous weapons is the United States Department of Defense (DoD) Directive 3000.09, "Autonomy in Weapons Systems," last updated in January 2023.6 This directive provides the definitions and policies that guide U.S. development and deployment.
According to DoDD 3000.09, a LAWS is a "weapon system that, once activated, can select and engage targets without further intervention by a human operator".6 The central tenet of the directive, however, is the mandate that all autonomous and semi-autonomous weapon systems "be designed to allow commanders and operators to exercise appropriate levels of human judgment over the use of force".6
The term "appropriate" is deliberately flexible, acknowledging that the necessary level of human judgment can vary based on the context of the mission, the weapon system's capabilities, and the operational environment.6 Importantly, the directive clarifies that "human judgment over the use of force" does not strictly require manual human "control" over the firing mechanism. Instead, it implies broader human involvement in the decisions about how, when, where, and why the weapon will be employed. This includes ensuring its use complies with the law of war, applicable treaties, weapon safety rules, and rules of engagement (ROE).6
To ensure this standard is met, DoDD 3000.09 establishes a rigorous review and testing process. Systems must be proven to:
Function as anticipated in realistic operational environments against adaptive adversaries.6
Complete engagements within a pre-defined timeframe and geographic area consistent with the commander's intent.6
Be sufficiently robust to minimize the probability and consequences of failures.6
Undergo a complete re-evaluation and re-certification if the system's behavior changes as a result of machine learning or other updates.6

2.3 Control Architectures: The Human-Machine Relationship

The spectrum of autonomy is best understood through its control architectures, which define the functional relationship between the human operator and the weapon system's decision-making loop. These architectures are primarily distinguished by the role the human plays in the final decision to apply lethal force.
Human-in-the-Loop (HITL): In a HITL system, the machine can perform many autonomous functions, such as searching for, detecting, and tracking potential targets. However, a human operator is an essential and active part of the decision-making loop and must give a final, affirmative command to authorize the use of lethal force.6 This architecture is also referred to as semi-autonomous and is characteristic of most currently deployed armed unmanned systems, such as the MQ-9 Reaper drone, as well as many precision-guided munitions.14 The machine provides decision support, but the human makes the ultimate lethal decision.
Human-on-the-Loop (HOTL): In a HOTL system, the machine is capable of autonomously selecting and engaging targets based on its programming and sensor data. The human operator acts in a supervisory role, monitoring the system's operations with the ability to intervene and override its decisions, effectively holding a power of veto.6 This model is common in defensive systems where the speed of the threat—such as an incoming missile or rocket—is too fast for a human to complete a full decision cycle. In these cases, human inaction permits the system to execute its pre-authorized lethal action.14
Human-out-of-the-Loop (HOOTL): A HOOTL system is a truly autonomous weapon. Once activated, it can select and engage targets without any further human intervention, authorization, or supervision.6 The human role is limited to programming the initial mission parameters, rules of engagement, and target profiles before deployment. After launch, the machine makes all subsequent decisions, including the final determination to use lethal force.8 This is the architecture that defines a LAWS in the strictest sense and is the primary focus of international calls for prohibition, as it fully delegates the lethal decision to an algorithm.3
Control Level
Definition
Human Role
System Autonomy Level
Key Operational Nuance
Exemplar Systems
Human-in-the-Loop (HITL)
The system requires a direct command from a human to apply lethal force.
Active Decision-Maker
Low-Medium (Decision Support)
Human action is required for lethal force.
Remotely piloted drones (e.g., MQ-9 Reaper), many loitering munitions.
Human-on-the-Loop (HOTL)
The system can autonomously apply lethal force, but a human can override the action.
Supervisor / Veto Power
High (Supervised Autonomy)
Human inaction permits lethal force.
Defensive systems (e.g., Phalanx CIWS, Iron Dome), some loitering munitions.
Human-out-of-the-Loop (HOOTL)
The system can apply lethal force without any real-time human input or oversight.
Mission Planner / Programmer
Full (Unsupervised Autonomy)
Human has no real-time role in lethal force decisions.
Hypothetical future offensive LAWS (e.g., "Slaughterbots"), some anti-vehicle mines.

Table 1: Spectrum of Human Control Architectures. This table provides a comparative overview of the three primary control models, clarifying the critical operational, legal, and ethical distinctions that define the human-machine relationship in weapon systems.

3.0 Current and Emerging Systems: A Multi-Domain Survey

The theoretical constructs of autonomous warfare are rapidly materializing into tangible military hardware across all operational domains. From the skies over Ukraine to the depths of the Pacific Ocean, systems with increasing levels of autonomy are being developed, tested, and deployed. This section provides a survey of key current and emerging autonomous systems in the air, on land, and at sea, illustrating the practical application of the concepts defined above. A notable trend has been the shift in the role of autonomy from primarily supporting "dull, dirty, and dangerous" missions, such as long-duration surveillance, to becoming an active participant in the "detect, decide, and destroy" sequence of the kill chain.2 This evolution from a passive sensor to an active shooter is the central dynamic driving the development of modern AWS.

3.1 Aerial Systems: From Attritable Drones to "Loyal Wingmen"

The aerial domain has been the most visible and dynamic theater for the advancement of autonomous technologies, spurred by both high-end state-led programs and rapid, battlefield-driven innovation.

3.1.1 Loitering Munitions ("Suicide Drones")

Loitering munitions are a hybrid of a cruise missile and a drone. They can be launched without a specific target designated and can "loiter" over a battlefield for an extended period, using their onboard sensors to autonomously search for, detect, and classify targets that match a pre-programmed profile. Once a target is identified, the munition attacks by crashing into it, detonating its warhead.10 While many systems retain a human-in-the-loop for the final attack authorization, their ability to autonomously hunt for targets represents a significant step in operational autonomy.
The 2022 Russian invasion of Ukraine has served as a crucible for loitering munition technology, demonstrating its tactical effectiveness and spurring rapid evolution.16
Key Systems in Ukraine: Ukrainian forces have extensively used American-supplied systems like the AeroVironment Switchblade (a small, backpack-portable system) and the Phoenix Ghost.4 Russia has deployed its domestically produced ZALA Lancet and Iranian-supplied drones like the Shahed-136.17
Low-Cost Innovation: The conflict has also seen the proliferation of improvised "FPV loitering munitions," where commercial first-person-view racing drones are modified to carry small explosive payloads like RPG warheads or grenades. These low-cost systems, often funded by volunteer groups and produced in the thousands per month, have proven highly effective against armored vehicles and personnel, demonstrating a powerful form of asymmetric warfare.17
Next-Generation Systems: Recognizing the importance of this capability, nations like France are investing in more sophisticated platforms. The MATARIS family of loitering munitions, developed by KNDS, includes systems like the fixed-wing MV-25 Oskar (already deployed in Ukraine) and the quadcopter MX-10 Damocles. These systems feature advanced capabilities such as jam-resistant data links and the ability to navigate in GNSS-denied environments, while explicitly keeping a human operator in the loop for the final attack command, allowing an attack to be aborted up to the point of impact.18

3.1.2 Collaborative Combat Aircraft (CCAs)

CCAs represent the next major evolution in air combat, moving beyond single unmanned platforms to teams of manned and unmanned aircraft. Often referred to as "loyal wingmen," CCAs are large, high-performance, semi-autonomous UCAVs designed to fly alongside and in support of crewed fighter jets like the F-35 and the future Next-Generation Air Dominance (NGAD) fighter.20 The U.S. Air Force's vision is to procure a fleet of at least 1,000 CCAs, pairing two with each of its 500 advanced fighters, to add mass to its force structure at a fraction of the cost of additional crewed aircraft.21 CCAs are expected to perform a variety of missions, including ISR, electronic warfare, and carrying additional munitions to engage targets at the direction of the manned fighter pilot.20
Boeing MQ-28 Ghost Bat: Developed in partnership with the Royal Australian Air Force, the Ghost Bat is a foundational program for CCA development. It is a stealthy, fighter-like UCAV designed to act as a force multiplier. Flight tests have demonstrated its ability to team with crewed assets, such as an E-7 Wedgetail airborne early warning and control aircraft, to perform missions like extending sensor range and providing a defensive screen for the higher-value manned platform.23
Kratos XQ-58A Valkyrie: The Valkyrie is a key platform in the U.S. military's exploration of "attritable" aircraft—systems that are cheap enough to be risked or lost in high-threat environments without catastrophic strategic consequences. It is a high-subsonic, long-range UCAV that can be launched from a rail system without a runway.27 The U.S. Air Force and Marine Corps are testing it extensively for various roles, including as a communications gateway and in an electronic attack configuration.28 While the Air Force's formal CCA program has moved forward with contracts to General Atomics for the YFQ-42A and Anduril for the YFQ-44A, the Valkyrie's development has been instrumental in proving the operational concepts.22

3.2 Ground Systems: The Dawn of the Robotic Battlefield

The development of autonomous ground systems has proven more challenging than in the air due to the complexity and unpredictability of terrestrial terrain. However, significant research and development efforts are underway to field Robotic Combat Vehicles (RCVs) that can perform reconnaissance, provide fire support, and breach obstacles, reducing risk to human soldiers.

3.2.1 The U.S. Army's Robotic Combat Vehicle (RCV) Program

The U.S. Army's RCV program has been a major, albeit turbulent, effort to integrate autonomy into its ground forces. The initial vision was for a family of vehicles in light, medium, and heavy classes.30 However, the program has faced significant headwinds. By 2023, the effort was narrowed to focus solely on the RCV-Light variant.31
In a major development in May 2025, the Army announced it was halting the RCV program as currently structured.32 This decision was not a rejection of the need for robotic vehicles but rather a fundamental reassessment of the acquisition strategy. Army leadership cited concerns over high costs (nearly $3 million per vehicle), the risk of being locked into a single vendor, and, most critically, the recognition that the core autonomy software and off-road navigation capabilities were not yet mature enough for a large-scale production program.30 The Army plans to reopen the effort to a wider consortium of vendors to focus on developing more robust and cost-effective software before selecting a final vehicle platform.32

3.2.2 DARPA's Foundational Research

The technical challenges highlighted by the RCV program's pause are being directly addressed by foundational research at the Defense Advanced Research Projects Agency (DARPA).
RACER (Robotic Autonomy in Complex Environments with Resiliency): The RACER program is focused squarely on the most difficult problem for ground autonomy: high-speed, off-road navigation in unstructured, military-relevant environments.33 The goal is to develop platform-agnostic software algorithms that can enable an unmanned ground vehicle (UGV) to maneuver across complex terrain at speeds on par with a human driver, a capability far beyond that of commercial self-driving cars which operate in highly structured road networks.34 The program is testing its algorithms on multiple vehicle types, including 12-ton tracked vehicles similar in size to future RCVs.34
GXV-T (Ground X-Vehicle Technologies): This program seeks to disrupt the traditional paradigm of armored vehicle design, which equates survivability with heavy armor. GXV-T's goal is to improve vehicle mobility and survivability through other means, such as agility and signature reduction.35 Its ambitious technical goals include reducing vehicle size and weight by 50%, increasing speed by 100%, and developing concepts for "survivability through agility," such as autonomously avoiding incoming threats or actively repositioning armor to defeat a projectile in real time.35

3.3 Naval and Undersea Systems: Autonomy at Sea and in the Deep

Naval forces are increasingly leveraging autonomy for missions ranging from surface protection to long-duration undersea surveillance, taking advantage of the less cluttered maritime environment.

3.3.1 Surface Defense

Phalanx Close-In Weapon System (CIWS): A ubiquitous feature on U.S. Navy and allied warships, the Phalanx is a self-contained, automated gun system that serves as the last line of defense against anti-ship missiles, aircraft, and small boats.36 Its integrated radar and fire-control system allows it to autonomously search for, detect, track, engage, and perform kill assessment on incoming threats at a high rate of fire.37 The Block 1B upgrade adds a Forward-Looking Infrared (FLIR) sensor, which significantly improves its ability to engage small, maneuvering surface craft and low-flying threats in littoral environments.36 The Phalanx is a classic example of a human-on-the-loop system, operating automatically due to extreme time constraints but under the supervision of the ship's crew.

3.3.2 Extra-Large Unmanned Undersea Vessels (XLUUVs)

XLUUVs represent a new frontier in undersea warfare, envisioned as large, long-endurance autonomous submarines capable of carrying out missions for weeks or months without human intervention.
Boeing Orca: The U.S. Navy's first XLUUV, the Orca is based on Boeing's earlier Echo Voyager prototype.39 It is a modular, 50-ton diesel-electric submarine with a large payload bay designed for missions such as covert mine-laying, anti-submarine warfare, and undersea surveillance.39 The program has faced significant challenges, with reports of being three years behind schedule and 64% over budget.39 Despite these setbacks, Boeing delivered the first Orca test vehicle to the Navy in December 2023, marking a major milestone in the development of this capability.39
Northrop Grumman Manta Ray: A DARPA-funded program, Manta Ray aims to develop a new class of UUV capable of long-duration, long-range missions in ocean environments where humans cannot go.41 Key innovations include a highly modular design that allows the vehicle to be shipped in standard containers and assembled in the field, and the ability to anchor to the seafloor and enter a low-power hibernation state to conserve energy and extend its operational persistence.41

3.4 Defensive Interceptor Systems: High-Speed, Automated Protection

Some of the most mature and widely deployed autonomous systems are defensive in nature. Their autonomy is a direct response to the operational necessity of countering threats, such as rockets and mortars, whose flight times are too short for a human to effectively complete the entire engagement cycle. These systems operate on a human-on-the-loop basis, where human commanders set the rules of engagement, but the system executes the intercept autonomously.
Israel's Iron Dome: This Counter-Rocket, Artillery, and Mortar (C-RAM) system is one of the world's most successful air defense systems.42 Developed by Rafael Advanced Defense Systems, it uses a sophisticated radar to detect and track incoming short-range rockets and shells.43 Its battle management and control (BMC) system employs advanced algorithms, recently enhanced with AI, to calculate the projectile's trajectory and predicted impact point.44 Crucially, the system is programmed to engage
only those projectiles that pose a threat to designated populated areas or critical infrastructure, conserving expensive interceptors.43 This autonomous prioritization and engagement capability has allowed the Iron Dome to achieve a success rate reported to be over 90%.42
Land-Based Phalanx Weapon System (LPWS / C-RAM): This system adapts the naval Phalanx CIWS for land-based point defense of forward operating bases and other critical sites.38 The system networks the Phalanx gun with ground-based radars, such as the AN/TPQ-36 Firefinder, which detect incoming mortar and rocket fire.38 When a threat is detected, the system provides a warning to personnel and can autonomously engage and destroy the projectile in flight with high-explosive rounds.38 The high level of automation is essential to react within the seconds-long engagement window typical of these threats.46
The widespread deployment and success of these systems illustrate a critical point in the autonomy debate: in certain well-defined, defensive scenarios, a high degree of autonomy is not only accepted but is considered essential for effective protection.

4.0 The Technological Vanguard: Core Enablers of Autonomy

The proliferation of autonomous systems across military domains is not the result of a single breakthrough but rather the convergence of several key technological streams. Advances in artificial intelligence, sensor technology, and networking are the foundational pillars upon which modern AWS are built. Understanding these core enablers is essential to appreciating both the capabilities and the limitations of current and future autonomous weapons.

4.1 Artificial Intelligence: The "Brain" of the Machine

Artificial intelligence is the central enabling technology for AWS, providing the "brain" that allows a machine to perceive its environment, make decisions, and take action without direct human control.1 While AI is not a prerequisite for all autonomous functions, its incorporation dramatically expands a system's capabilities, allowing it to move from simple pre-programmed actions to adaptive, data-driven behaviors.10

4.1.1 Computer Vision and Target Recognition

The most critical AI function for any weapon system is the ability to correctly identify a target. Computer vision, a field of AI that trains computers to interpret and understand the visual world, is at the heart of this capability.48 In an AWS context, algorithms analyze vast streams of data from electro-optical, infrared, and other sensors to perform three key tasks:
Detection: Identifying an object of interest within the sensor's field of view.
Classification: Determining what the object is (e.g., a tank, a truck, a person).
Tracking: Following the object's movement over time.49
This technology is already being used in a decision-support role in systems like loitering munitions, where AI-powered target recognition assists a human operator in identifying and confirming a target before an attack.4 The primary legal and ethical challenge arises when this function is fully automated. The ability of an algorithm to reliably distinguish between a combatant holding a weapon and a civilian holding a farm tool, or between an active enemy soldier and one who is surrendering (
hors de combat), requires a level of contextual understanding and nuanced judgment that remains a profound technical hurdle.49

4.1.2 Decision Algorithms and Reinforcement Learning

Beyond simple recognition, the next frontier for military AI is tactical decision-making. This involves programming systems not just to see but to decide on a course of action. A key area of research is Deep Reinforcement Learning (DRL), a type of machine learning where an AI "agent" learns to achieve a goal in a complex, uncertain environment.51
In DRL, the agent learns through trial and error. It interacts with a simulated environment, takes actions, and receives feedback in the form of "rewards" or "penalties." Over millions of iterations, the agent's neural network learns a policy—a strategy for mapping situations to actions—that maximizes its cumulative reward.51 This approach allows a system to develop complex, adaptive behaviors for tasks like autonomous navigation, obstacle avoidance, and even combat engagement, without being explicitly programmed for every possible contingency.51 This ability to learn and adapt is what promises to give future AWS a decisive edge in dynamic battlefield conditions, but it is also a source of significant concern due to the inherent unpredictability of emergent behaviors.

4.2 Sensing and Perception: Seeing and Understanding the Battlefield

An autonomous system's intelligence is only as good as the data it receives. The ability to build a rich, accurate, real-time model of the operational environment is a prerequisite for any meaningful autonomous action.

4.2.1 Advanced Sensor Suites and Fusion

Modern military platforms are equipped with a diverse array of sensors, including high-resolution electro-optical (EO) cameras, infrared (IR) sensors for detecting heat signatures, radar for tracking objects through weather and obscurants, and LiDAR (Light Detection and Ranging) for creating precise 3D maps of the surroundings.11
However, the critical enabling technology is not the individual sensors but sensor fusion. This is the process by which AI algorithms intelligently combine the data streams from multiple, disparate sensors to produce a single, unified operational picture that is more accurate, complete, and reliable than the information from any single sensor alone.56 For example, sensor fusion can correlate a radar track with an IR signature and an EO image to confirm with high confidence that a detected object is an enemy tank and not a civilian bus, even in cluttered or adverse conditions.58 This ability to create a robust perception of reality is fundamental to autonomous targeting and navigation.

4.2.2 Navigation in Contested Environments

A primary driver for military autonomy is the need to operate effectively in environments where adversaries will actively try to disrupt command and control links, including by jamming or spoofing the Global Navigation Satellite System (GNSS), such as GPS.4 Consequently, a crucial capability for AWS is the ability to navigate accurately in these "GNSS-denied" environments. Key technologies being developed to address this challenge include:
Inertial Navigation Systems (INS): These systems use accelerometers and gyroscopes to track a vehicle's position relative to a known starting point. While self-contained, they are prone to drift over time.59
Visual-Based Navigation: These techniques use cameras and computer vision algorithms to navigate. Visual Inertial Odometry (VIO) combines camera data with INS data to correct for drift.60
Simultaneous Localization and Mapping (SLAM) allows a system to build a map of an unknown environment while simultaneously keeping track of its own location within that map.60 These technologies enable a drone or UGV to navigate by referencing landmarks and features in its immediate surroundings, much like a human does, providing resilience against GNSS disruption.18

4.3 Swarm Intelligence: The Power of the Collective

Drone swarms represent a paradigm shift in unmanned systems, moving from the operation of single, high-value platforms to the coordinated use of many, often low-cost and attritable, agents to achieve a collective goal.5 The military utility of swarms lies in their ability to saturate enemy defenses, provide resilient and redundant sensing over a wide area, and execute complex, multi-axis attacks that would be impossible to coordinate with human pilots alone.63

4.3.1 Decentralized Control and Communication

A true swarm is distinguished from a simple group of drones by its control architecture. Rather than each drone being individually controlled by a central command station, swarm members communicate directly with each other in a decentralized, ad-hoc network.62 They employ "swarm intelligence" algorithms, often inspired by biological systems like ant colonies or flocks of birds, to make collective decisions and coordinate their actions based on a shared understanding of the mission and the environment.62 This decentralized structure makes the swarm highly resilient; the loss of individual units does not compromise the mission, as the remaining agents can dynamically reconfigure the network and adapt their behavior.65 This requires robust, jam-resistant, and self-healing communication protocols, often forming what is known as a Flying Ad-Hoc Network (FANET).67

4.3.2 Major International Programs

The strategic potential of swarm technology has led to significant investment from major military powers.
United States: In August 2023, the Pentagon announced the Replicator initiative, a major strategic effort to field thousands of small, smart, and inexpensive autonomous systems across all domains within 18-24 months. The explicit goal is to use "attritable mass" to counter the numerical advantage of potential adversaries like China.62 This initiative is supported by extensive experimentation in exercises like the Army's
Project Convergence and Vanguard 24, which are testing swarm ISR and teaming capabilities.69 The U.S. Navy is also pursuing a
"Super Swarm" project to develop methodologies for overwhelming enemy defenses with large numbers of small drones.71
China: China has demonstrated its prowess in drone coordination through massive public light shows, one of which featured over 11,000 drones flying in formation.72 Militarily, it is developing advanced swarm capabilities, highlighted by the unveiling of the
Jiu Tian "mothership", a large UAV designed to carry and deploy smaller swarms of drones deep into contested airspace.62
Other Nations: Development is widespread. The United Kingdom is developing a secure architecture for Mixed Multi-Domain Swarms (MMDS) of air, land, and sea vehicles.62
Germany's KITU 2 program integrates AI-driven swarm behaviors for multi-UAV coordination in GPS-deprived conditions.62
Sweden has unveiled software capable of controlling up to 100 UAS simultaneously.62
Turkey has been developing swarming technology for its Kargu-2 loitering munition since 2020, with the capability to operate in swarms of up to 20 drones.62
Country/Bloc
Program Name/Initiative
Domain
Stated Objective
United States
Replicator Initiative / Collaborative Combat Aircraft (CCA)
Multi-Domain / Air
Mass attritable autonomy; "Loyal wingman" for fighters.
China
Jiu Tian Mothership
Air
Long-range deployment of smaller drone swarms.
United Kingdom
Progeny Maritime Research Framework (MMDS)
Multi-Domain
Secure architecture for mixed air, land, and sea swarms.
Germany
KITU 2
Air
AI-driven swarm behaviors and coordination in GPS-denied environments.
France
Larinae / Colibri
Air
Development of advanced, networked loitering munitions.
Turkey
Kargu-2 Swarm
Air
Coordinated precision strikes with swarms of up to 20 loitering munitions.

Table 2: Key International Autonomous Weapons Programs (c. 2025). This table provides a comparative snapshot of major global efforts in developing advanced autonomous systems, highlighting the competitive nature of AWS development and national areas of focus.
The core technologies enabling autonomy reveal a fundamental tension at the heart of AWS development. While the goal is to create intelligent, adaptive, and resilient systems, the very nature of advanced AI introduces unpredictability. Machine learning models, particularly those trained via DRL, are often described as "brittle".74 Their behavior is derived from complex interactions between their algorithms and a dynamic environment, making it extremely difficult to predict or guarantee their actions in novel, real-world settings that differ from their training data.3 This creates a direct conflict between military and legal requirements. For a weapon to be lawful under International Humanitarian Law (IHL), its effects must be predictable and controllable.75 For that same weapon to be militarily effective against an intelligent, adaptive adversary, it may need to be deliberately unpredictable to maintain a tactical edge.3 This "brittleness" of AI is not merely a technical bug to be fixed but a fundamental characteristic of current machine learning paradigms, posing a deep challenge to the very premise of lawful autonomous warfare.

5.0 The Human Element: Control, Judgment, and Trust

As machines assume more functions on the battlefield, the role of the human operator is not eliminated but transformed. The debate over autonomous weapons is fundamentally a debate about the proper nature of the human-machine relationship in the context of lethal force. While concepts like "human-in-the-loop" provide a useful taxonomy, practical experience with highly automated systems reveals significant complexities and cognitive challenges that call into question the efficacy of human oversight in high-tempo, high-stakes environments.

5.1 The Spectrum of Human Control in Practice

Case studies of existing, highly automated military systems provide crucial lessons about the challenges of human-machine teaming and the phenomenon of "automation bias"—the tendency for humans to over-trust and uncritically accept the outputs of an automated system.

5.1.1 Case Study: The Aegis Combat System

The Aegis Combat System is a sophisticated, integrated naval weapon system that automates the entire air defense process from detection to kill.76 Its powerful AN/SPY-1 radar and advanced computer systems can track over 100 targets simultaneously and guide missiles to intercept them.78 While the system has multiple modes of operation, it is designed to operate with a high degree of automation to counter saturation attacks.79
The tragic 1988 downing of Iran Air Flight 655 by the Aegis-equipped cruiser USS Vincennes is a seminal case study in the perils of human-machine interaction under stress.78 The official investigation found that the Aegis system was functioning correctly and was tracking the aircraft as a civilian airliner on a normal flight path. However, the human crew in the combat information center, operating under immense psychological pressure in a hostile environment, misinterpreted the system's data. They reported to the captain that the aircraft was descending and accelerating as if on an attack profile, despite the system's display showing it was climbing.78 The crew trusted their preconceived scenario of an attack over the raw data presented by the machine, leading them to misidentify the airliner as an enemy F-14 fighter and shoot it down.80 This incident starkly illustrates that simply having a human "in the loop" does not guarantee a safe or correct outcome, especially when cognitive biases and a poorly designed human-machine interface lead to catastrophic errors in judgment.

5.1.2 Case Study: The Patriot Missile System

The MIM-104 Patriot is the U.S. Army's premier air and missile defense system, capable of engaging aircraft, cruise missiles, and ballistic missiles.81 Like Aegis, it is a "detection-to-kill" system, with a single radar performing all search, track, and engagement functions.81 Due to the extremely short engagement timelines, particularly against ballistic missiles, the system operates with a high degree of automation. A battery of launchers is managed by a crew of just three soldiers in the Engagement Control Station (ECS), who supervise the system's operation.82
During the 2003 invasion of Iraq, the Patriot system was involved in two fratricide incidents, shooting down a British Tornado and a U.S. Navy F/A-18 Hornet.80 In these cases, the system's algorithms misclassified the friendly aircraft as hostile anti-radiation missiles. The human operators, required to make split-second decisions based on the system's recommendations, confirmed the engagements.80 These incidents highlight the immense difficulty of exercising effective supervision (the HOTL model) in a fast-paced, complex battlespace where the "fog of war" can lead both humans and machines to make fatal errors.
These cases reveal a critical paradox: the more advanced, complex, and reliable an autonomous system becomes, the more difficult it can be for a human to exercise meaningful control over it. The very speed that makes the system effective can compress decision timelines to the point where human intervention becomes impractical.3 The opacity of complex AI algorithms—often referred to as "black boxes"—means a human supervisor may see a system's recommendation but be unable to understand the reasoning behind it, making it difficult to challenge.84 Finally, as a system proves its reliability over time, human operators inevitably develop automation bias, becoming more complacent and less likely to question the machine's judgment, even when their own intuition or other data sources suggest something is wrong.48 This creates a dangerous feedback loop where increasing a system's autonomy to enhance its performance can paradoxically erode the very conditions necessary for effective human oversight.

5.2 The Quest for "Meaningful Human Control" (MHC)

In response to the challenges posed by increasing autonomy, the concept of "Meaningful Human Control" (MHC) has become the central focus of international diplomatic and civil society efforts to regulate LAWS.86 The principle posits that humans, not machines, must ultimately remain in control of, and thus morally responsible for, all decisions to use lethal force.86
However, MHC is a political and legal concept, not a technical specification, and it lacks a universally agreed-upon definition.84 This ambiguity is the primary fault line in the international debate:
Proponents of a Ban: Groups like the Campaign to Stop Killer Robots and many states argue that MHC requires a human to have sufficient contextual information and the practical ability to make a deliberate, case-by-case decision before every single application of force.89 Under this interpretation, systems that can autonomously select and engage targets without such specific, real-time human authorization would be prohibited.
Major Military Powers: States actively developing AWS, such as the United States, tend to avoid the term MHC in favor of more flexible language. U.S. policy, for example, calls for "appropriate levels of human judgment".6 This phrasing allows for a context-dependent approach where the degree of direct human control can be varied. It implies that in certain highly constrained and predictable scenarios—such as the terminal defense of a ship against an incoming sea-skimming missile—it may be "appropriate" to cede direct control to the machine, provided a human has set the overarching rules of engagement.
This fundamental disagreement over whether human control must be direct and absolute for every engagement (MHC) or can be supervisory and context-dependent ("appropriate judgment") remains the core obstacle to achieving an international consensus on regulating LAWS.

6.0 The Global Dilemma: Ethical, Legal, and Strategic Implications

The rapid advancement of autonomous weapons technology presents the international community with a series of profound and interconnected dilemmas. These challenges extend beyond the battlefield, touching upon fundamental principles of law, ethics, and global strategic stability. Failure to address them risks not only a future of unpredictable and automated conflict but also the erosion of long-standing norms governing the use of force.

6.1 The Accountability Gap

One of the most pressing legal and ethical problems posed by LAWS is the "accountability gap".91 When a fully autonomous weapon unlawfully kills a civilian or destroys protected property, it is unclear who can be held legally responsible for the action.
The Machine: An autonomous system itself cannot be held accountable. It is a machine, not a moral agent, and lacks the legal standing and the concept of mens rea (criminal intent) necessary for legal culpability.93
The Operator/Commander: Holding the human commander or operator criminally responsible is also fraught with difficulty. Under the doctrine of command responsibility, a superior is only liable if they knew or should have known that a subordinate (in this case, the machine) would commit a crime and failed to prevent it.93 If the AWS acts in an unpredictable way that was not foreseeable to the commander at the time of deployment—a key concern with learning-based AI systems—it becomes nearly impossible to establish the necessary standard of intent or negligence for criminal liability.3
The Programmer/Manufacturer: Assigning liability to the software developers or manufacturers of the weapon faces significant legal hurdles. In many jurisdictions, military contractors are shielded by doctrines of sovereign immunity. Furthermore, proving that a specific line of code or design choice was the direct and faulty cause of an unlawful act amidst millions of lines of code and complex environmental interactions would be an immense technical and legal challenge.93
This potential for an "accountability vacuum" is a grave concern. It creates a situation where war crimes could be committed with no one—neither machine, soldier, nor corporation—being held legally responsible, undermining the entire framework of international justice and deterrence.92

6.2 Compliance with International Humanitarian Law (IHL)

It is a universally accepted principle that all new weapons, including AWS, must be capable of being used in compliance with International Humanitarian Law (IHL), also known as the laws of armed conflict.75 However, the core principles of IHL are based on nuanced, context-dependent human judgment, posing a fundamental challenge for an algorithmic system.
Distinction: This principle requires combatants to distinguish between military objectives and civilians or civilian objects, and to direct attacks only at the former.95 An AWS would have to make this distinction based on sensor data and pre-programmed target profiles. It is highly questionable whether an algorithm could reliably differentiate between a combatant and a civilian who may look similar (e.g., a farmer carrying a tool versus a soldier carrying a rifle), or recognize the surrender of an enemy soldier (
hors de combat), an act often communicated through subtle gestures and context.44
Proportionality: This rule prohibits attacks in which the expected incidental loss of civilian life or damage to civilian property would be excessive in relation to the concrete and direct military advantage anticipated.95 This is not a simple mathematical calculation; it is a subjective, value-laden judgment that requires weighing incommensurable factors. It is unclear how a machine could be programmed to make such a deeply human ethical assessment in the heat of battle.50
Precaution: This principle requires combatants to take all feasible precautions to avoid or minimize civilian harm. This includes verifying targets, choosing appropriate weapons, and canceling an attack if it becomes apparent that the target is not a military objective or the attack would be disproportionate.95 This demands a high level of real-time situational awareness and the ability to make a final, ethically informed judgment call, capabilities that are hallmarks of human cognition, not machine processing.50

6.3 The Geopolitical Landscape: A Fractured Consensus

The international community is deeply divided on how to address the challenges of LAWS. Diplomatic efforts, primarily centered at the United Nations Convention on Certain Conventional Weapons (CCW) Group of Governmental Experts (GGE) in Geneva, have been characterized by a stalemate, largely due to the consensus-based nature of the forum which allows a single state to block progress.96 The key positions of major actors are as follows:

Country/Bloc
Stance on Legally Binding Instrument
Key Concept for Human Oversight
Key Policy Document/Statement
United States
Opposes a pre-emptive ban; argues existing IHL is sufficient.
"Appropriate levels of human judgment"
DoD Directive 3000.09 6
China
Supports a ban on use but not development; promotes a very narrow definition.
"Human control over the entire process"
GGE Position Papers 12
Russia
Opposes any new legally binding instrument.
"Sovereign discretion of States"
Statements at UNGA/GGE 98
United Kingdom
Supports regulation to ensure human control; does not support a total ban.
"Context-appropriate human involvement"
Defence AI Strategy 100
European Union
Supports regulation to ensure "meaningful human control" and accountability.
"Meaningful human control"
EEAS Statements / EP Resolutions 102

Table 3: Comparative Stances of Major Powers on LAWS Regulation. This table summarizes the divergent positions of key global actors, illustrating the core disagreements that have stalled international regulatory efforts.
In contrast to the positions of these major military powers, a large coalition of states, particularly from the Non-Aligned Movement and Latin America, as well as international organizations like the International Committee of the Red Cross (ICRC) and civil society groups like the Campaign to Stop Killer Robots, advocate for the urgent negotiation of a new legally binding international treaty. They typically propose a two-tiered approach: prohibiting systems that are inherently unpredictable or that target humans directly, and strictly regulating all other AWS to ensure meaningful human control is always maintained.97

6.4 Strategic Stability and the Proliferation Threat

Beyond the legal and ethical dimensions, the development of AWS poses grave risks to global strategic stability.
Risk of a New AI Arms Race: The competitive pursuit of autonomous capabilities by major powers like the U.S., China, and Russia is fueling a new AI arms race.74 This dynamic creates intense pressure to develop and deploy these systems rapidly to avoid being at a strategic disadvantage, potentially lowering the threshold for conflict and prioritizing speed over safety and ethical considerations.107 The introduction of AI-driven warfare, operating at machine speeds, could also lead to rapid, uncontrolled escalation in a crisis—so-called "flash wars"—as events unfold too quickly for human diplomats or commanders to de-escalate.3
The Danger of Proliferation: Perhaps the most insidious long-term threat is proliferation. Unlike nuclear weapons, which require vast industrial infrastructure and rare materials, the core technologies for many forms of AWS are dual-use, relatively inexpensive, and widely available. Sophisticated AI software is often open-source, and capable commercial drones can be purchased for thousands of dollars, not billions.109 This dramatically lowers the barrier to entry, making it feasible for smaller states, and more alarmingly, non-state actors like terrorist groups and transnational criminal organizations, to acquire and weaponize autonomous systems. This could level the battlefield in dangerous ways, creating new asymmetric threats and undermining the conventional military superiority that has long been a cornerstone of international stability.3

7.0 Conclusion: Navigating the Future of Warfare

The development of Autonomous Weapons Systems is not a distant, science-fiction possibility; it is a present-day reality that is actively reshaping the technological and strategic landscape of modern conflict. From the widespread use of loitering munitions and FPV drones in Ukraine to the sophisticated development of collaborative combat aircraft and extra-large unmanned undersea vessels by major powers, the delegation of battlefield functions to machines is accelerating across all domains.
The technological vectors driving this revolution are clear: the increasing sophistication of AI for perception and decision-making; the operational necessity of functioning in communications-denied environments; and the strategic allure of deploying attritable, swarming systems to create mass and overwhelm adversaries. These technologies promise to make military operations faster, more precise, and potentially less costly in terms of human casualties on the user's side.
However, this appendix has detailed how these potential benefits are shadowed by profound and unresolved challenges. The core technologies of machine learning, while powerful, are also inherently unpredictable, creating a fundamental tension between military effectiveness and the legal requirement for predictable and controllable force. The operational realities of human-machine teaming, as evidenced by decades of experience with highly automated systems like Aegis and Patriot, demonstrate that human oversight is fallible and prone to cognitive biases that can lead to catastrophic failure.
Ultimately, the most critical challenges posed by AWS are not technical but are deeply rooted in ethics, law, and strategy. The international community remains fractured, unable to agree on even a common definition for these systems, let alone a framework for their regulation. The unresolved questions of how to ensure meaningful human control over the use of lethal force, how to close the legal accountability gap when autonomous systems err, and how to maintain strategic stability in an era of AI-driven arms races and widespread proliferation are paramount. Navigating this future requires urgent and substantive international dialogue. Failure to address these foundational dilemmas risks a future of automated conflict that is dangerously unpredictable, ethically fraught, and potentially catastrophic for global security.
Works cited
Educating about Autonomous Weapons - Future of Life Institute, accessed on July 23, 2025, <https://futureoflife.org/project/autonomous-weapons-systems/>
Pros and Cons of Autonomous Weapons Systems - Army University Press, accessed on July 23, 2025, <https://www.armyupress.army.mil/Journals/Military-Review/English-Edition-Archives/May-June-2017/Pros-and-Cons-of-Autonomous-Weapons-Systems/>
Autonomous Weapons Systems: Homepage, accessed on July 23, 2025, <https://autonomousweapons.org/>
What are Autonomous Weapon Systems? - Belfer Center, accessed on July 23, 2025, <https://www.belfercenter.org/what-are-autonomous-weapon-systems>
Artificial Intelligence in the Military: How AI Is Reshaping the Future of War - TS2 Space, accessed on July 23, 2025, <https://ts2.tech/en/artificial-intelligence-in-the-military-how-ai-is-reshaping-the-future-of-war/>
Defense Primer: U.S. Policy on Lethal Autonomous Weapon ..., accessed on July 23, 2025, <https://www.congress.gov/crs-product/IF11150>
Human-Machine Interaction and Human Agency in the Military Domain - Centre for International Governance Innovation (CIGI), accessed on July 23, 2025, <https://www.cigionline.org/documents/3094/PB_no.193.pdf>
Lethal autonomous weapon - Wikipedia, accessed on July 23, 2025, <https://en.wikipedia.org/wiki/Lethal_autonomous_weapon>
Lethal autonomous weapons (LAWs) | EBSCO Research Starters, accessed on July 23, 2025, <https://www.ebsco.com/research-starters/social-sciences-and-humanities/lethal-autonomous-weapons-laws>
Lethal Autonomous Weapon Systems (LAWS) – UNODA, accessed on July 23, 2025, <https://disarmament.unoda.org/the-convention-on-certain-conventional-weapons/background-on-laws-in-the-ccw/>
<www.congress.gov>, accessed on July 23, 2025, <https://www.congress.gov/crs-product/IF11150#:~:text=Lethal%20autonomous%20weapon%20systems%20(LAWS,human%20control%20of%20the%20system>.
Weaponised Artificial Intelligence and Chinese Practices of Human ..., accessed on July 23, 2025, <https://academic.oup.com/cjip/article/16/1/106/6976053>
Legal aspects of the development of weapon systems with artificial intelligence in 2025, accessed on July 23, 2025, <https://www.arws.cz/news-at-arrows/legal-aspects-of-the-development-of-weapon-systems-with-artificial-intelligence-in-2025>
Offensive Autonomous Weapons: Should We Be Worried? - Michigan Journal of International Law, accessed on July 23, 2025, <https://www.mjilonline.org/offensive-autonomous-weapons-should-we-be-worried/>
Human-in-the-loop - Wikipedia, accessed on July 23, 2025, <https://en.wikipedia.org/wiki/Human-in-the-loop>
Loitering Munitions and the Future of Modern Artillery - IDGA.org, accessed on July 23, 2025, <https://www.idga.org/land/articles/loitering-munitions-and-the-future-of-modern-artillery>
Loitering munition - Wikipedia, accessed on July 23, 2025, <https://en.wikipedia.org/wiki/Loitering_munition>
KNDS's Mataris loitering munitions finding contracts from French ..., accessed on July 23, 2025, <https://breakingdefense.com/2025/06/knds-mataris-loitering-munitions-finding-contracts-from-french-government/>
MATARIS: The First French Range of Loitering Munitions - ASDNews, accessed on July 23, 2025, <https://www.asdnews.com/news/defense/2025/06/17/mataris-first-french-range-loitering-munitions>
U.S. Air Force Collaborative Combat Aircraft (CCA) | Congress.gov ..., accessed on July 23, 2025, <https://www.congress.gov/crs-product/IF12740>
Tracking 2024 Updates to the Air Force's Collaborative Combat Aircraft - IDGA.org, accessed on July 23, 2025, <https://www.idga.org/aviation/articles/2024-updates-to-air-force-collaborative-combat-aircraft-cca>
The US Air Force's New Drones Are a Game Changer - The National Interest, accessed on July 23, 2025, <https://nationalinterest.org/blog/buzz/the-us-air-forces-new-drones-are-a-game-changer>
MQ-28 Ghost Bat - Boeing Australia, accessed on July 23, 2025, <https://www.boeing.com.au/products-services/defence-space-security/ghost-bat>
MQ-28 - Boeing, accessed on July 23, 2025, <https://www.boeing.com/defense/mq28>
MQ-28 Ghost Bats Controlled From E-7 Wedgetail In Loyal Wingman Test - The War Zone, accessed on July 23, 2025, <https://www.twz.com/air/mq-28-ghost-bats-controlled-from-e-7-wedgetail-in-loyal-wingman-test>
MQ-28A Ghost Bat Milestone - YouTube, accessed on July 23, 2025, <https://www.youtube.com/watch?v=2C_a-plgzFo>
Tactical UAVs - Kratos Defense, accessed on July 23, 2025, <https://www.kratosdefense.com/systems-and-platforms/unmanned-systems/aerial/tactical-uavs>
Kratos XQ-58 Valkyrie - Wikipedia, accessed on July 23, 2025, <https://en.wikipedia.org/wiki/Kratos_XQ-58_Valkyrie>
XQ-58 Valkyrie Heading To European Market With Kratos-Airbus Team-Up - The War Zone, accessed on July 23, 2025, <https://www.twz.com/air/xq-58-valkyrie-heading-to-european-market-with-kratos-airbus-team-up>
The Army's Robotic Combat Vehicle (RCV) Program - Congress.gov, accessed on July 23, 2025, <https://www.congress.gov/crs_external_products/IF/PDF/IF11876/IF11876.14.pdf>
Is the Army's Robotic Combat Vehicle Program Dead? So Much for Robot Tanks, accessed on July 23, 2025, <https://www.military.com/off-duty/autos/armys-robotic-combat-vehicle-program-dead-so-much-robot-tanks.html>
The Army's Robotic Combat Vehicle (RCV) Program - Congress.gov, accessed on July 23, 2025, <https://www.congress.gov/crs-product/IF11876>
RACER: Robotic Autonomy in Complex Environments with Resiliency - DARPA, accessed on July 23, 2025, <https://www.darpa.mil/research/programs/robotic-autonomy-in-complex-environments-with-resiliency>
RACER Speeds Into a Second Phase With Robotic Fleet Expansion ..., accessed on July 23, 2025, <https://www.darpa.mil/news/2024/racer-second-phase>
GXV-T: Ground X-Vehicle Technologies - DARPA, accessed on July 23, 2025, <https://www.darpa.mil/research/programs/ground-x-vehicle-technologies>
Phalanx CIWS - Wikipedia, accessed on July 23, 2025, <https://en.wikipedia.org/wiki/Phalanx_CIWS>
MK 15 - Phalanx Close-In Weapon System (CIWS) - Navy.mil, accessed on July 23, 2025, <https://www.navy.mil/resources/fact-files/display-factfiles/article/2167831/mk-15-phalanx-close-in-weapon-system-ciws/>
USA 20 mm Phalanx Close-in Weapon System (CIWS) - NavWeaps, accessed on July 23, 2025, <http://www.navweaps.com/Weapons/WNUS_Phalanx.php>
Despite delays, Boeing charts new course with delivery of Orca ..., accessed on July 23, 2025, <https://www.naval-technology.com/news/despite-delays-boeing-charts-new-course-with-delivery-of-orca-xluuv-to-us/>
JUST IN: Navy's First 'Extra' Large Unmanned Sub to Go Underwater 'Very Soon', accessed on July 23, 2025, <https://www.nationaldefensemagazine.org/articles/2023/1/30/just-in-navys-first-extra-large-unmanned-sub-to-go-underwater-very-soon>
Manta Ray | Northrop Grumman, accessed on July 23, 2025, <https://www.northropgrumman.com/what-we-do/mission-solutions/sensors/manta-ray>
Unveiling the Future: Iron Dome's Autonomous Revolution for ..., accessed on July 23, 2025, <https://certificates.acn.edu.au/iron-dome-autonomous>
Iron Dome - Wikipedia, accessed on July 23, 2025, <https://en.wikipedia.org/wiki/Iron_Dome>
A Defense for Guardian Robots: Are Defensive Autonomous Weapons Systems Justifiable?, accessed on July 23, 2025, <https://journals.law.harvard.edu/ilj/2024/02/a-defense-for-guardian-robots-are-defensive-autonomous-weapons-systems-justifiable/>
System, accessed on July 23, 2025, <https://uploads.mwp.mprod.getusinfo.com/uploads/sites/25/2021/07/CRAM-Brief-with-Notes-For-Posting.pdf>
Counter Rockets, Artillery and Mortars (C-RAM) - NATO Integrated Air & Missile Defence Centre of Excellence - iamd-coe.org, accessed on July 23, 2025, <https://iamd-coe.org/focus-areas/counter-rockets-artillery-and-mortars-cram/>
Countries upgrading Counter Rocket, Artillery, and Mortar systems to counter threats like drones, helicopters, fixed-wing aircraft and cruise missiles, accessed on July 23, 2025, <https://idstch.com/geopolitics/countries-upgrading-counter-rocket-artillery-and-mortar-systems-to-counter-threats-like-drones-helicopters-fixed-wing-aircraft-and-cruise-missiles/>
The Integration Of AI-Empowered Autonomous Weapon Systems In European Defence, accessed on July 23, 2025, <https://tdhj.org/blog/post/ai-autonomous-weapons-europe/>
The Algorithmic Battlefield: How AI is Redefining Military Might | by Ajay Verma - Medium, accessed on July 23, 2025, <https://medium.com/@ajayverma23/the-algorithmic-battlefield-how-ai-is-redefining-military-might-5d3fb3e9c590>
Lethal Autonomous Weapons Systems & International Law: Growing Momentum Towards a New International Treaty | ASIL, accessed on July 23, 2025, <https://www.asil.org/insights/volume/29/issue/1>
(PDF) DEEP REINFORCEMENT LEARNING IN UNMANNED ..., accessed on July 23, 2025, <https://www.researchgate.net/publication/387868468_DEEP_REINFORCEMENT_LEARNING_IN_UNMANNED_COMBAT_VEHICLES>
Modular Reinforcement Learning for Autonomous UAV Flight Control - MDPI, accessed on July 23, 2025, <https://www.mdpi.com/2504-446X/7/7/418>
The Army looks to pave way for autonomous vehicles with new AI research - FedScoop, accessed on July 23, 2025, <https://fedscoop.com/ai-research-army-ground-vehicles-reinforcement-learning/>
Military LiDAR Solutions for Defense Applications, accessed on July 23, 2025, <https://www.defenseadvancement.com/suppliers/military-lidar/>
Autonomous Systems: The Essential Guide to Using LiDAR, accessed on July 23, 2025, <https://www.computer.org/publications/tech-news/trends/lidar-in-autonomous-systems/>
Facilitating autonomous and semi-autonomous defense operations ..., accessed on July 23, 2025, <https://militaryembedded.com/unmanned/sensors/facilitating-autonomous-and-semi-autonomous-defense-operations>
Innovation Crossover Preliminary Research Report DoD Technologies – Sensor-Data Fusion - NavSea, accessed on July 23, 2025, <https://www.navsea.navy.mil/Portals/103/Documents/NSWC_Crane/Innovation%20Crossover%202016/DoD%20Technologies%20-%20Sensor%20-%20Data%20Fusion%20Final.pdf?ver=2016-10-07-111745-577>
CJADC2 interoperability: AI-/ML-based sensor fusion at the edge, accessed on July 23, 2025, <https://militaryembedded.com/ai/machine-learning/cjadc2-interoperability-ai-ml-based-sensor-fusion-at-the-edge>
Navigating GPS-Denied Environments: Solutions and Challenges, accessed on July 23, 2025, <https://www.gnssjamming.com/post/gps-denied-environments>
OMNInav: A Breakthrough in GPS-Denied Navigation for UAS - OKSI, accessed on July 23, 2025, <https://oksi.ai/omninav-gps-denied-navigation/>
GNSS-Denied Navigation Kit, accessed on July 23, 2025, <https://www.uavnavigation.com/products/navigation-systems/gnss-denied-navigation-kit>
Drone Wars: Developments in Drone Swarm Technology - Defense ..., accessed on July 23, 2025, <https://dsm.forecastinternational.com/2025/01/21/drone-wars-developments-in-drone-swarm-technology/>
AI-driven drones: a new challenge to conventional military superiority - - IARI, accessed on July 23, 2025, <https://iari.site/2025/07/20/ai-driven-drones-a-new-challenge-to-conventional-military-superiority/>
Swarm Clouds on the Horizon? Exploring the Future of Drone Swarm Proliferation - Modern War Institute, accessed on July 23, 2025, <https://mwi.westpoint.edu/swarm-clouds-on-the-horizon-exploring-the-future-of-drone-swarm-proliferation/>
SWARM: Pioneering The Future of Autonomous Drone Operations and Electronic Warfare, accessed on July 23, 2025, <https://www.cyberdefensemagazine.com/swarm-pioneering-the-future-of-autonomous-drone-operations-and-electronic-warfare/>
UAV swarm communication and control architectures: a review, accessed on July 23, 2025, <https://cdnsciencepub.com/doi/10.1139/juvs-2018-0009>
How Drone Swarm Technology is Used in Emergency Communication Networks, accessed on July 23, 2025, <https://www.winssolutions.org/drone-swarm-emergency-communication-networks/>
Drone Swarm Technology | Swarm Communications | UAV Swarm Control, accessed on July 23, 2025, <https://www.unmannedsystemstechnology.com/expo/drone-swarm-technology/>
U.S. Army To Explore ISR Drone Swarms This Year | AFCEA ..., accessed on July 23, 2025, <https://www.afcea.org/signal-media/intelligence/us-army-explore-isr-drone-swarms-year>
Project Convergence Capstone 4 - DVIDS, accessed on July 23, 2025, <https://www.dvidshub.net/feature/Capstone>
U.S. Navy Developing Drone Super Swarms |, accessed on July 23, 2025, <https://www.thedroningcompany.com/blog/u-s-navy-developing-drone-super-swarms>
Record-breaking drone show in Chongqing, China features 11787 drones - Reddit, accessed on July 23, 2025, <https://www.reddit.com/r/aviation/comments/1m730sm/recordbreaking_drone_show_in_chongqing_china/>
China Is Hard At Work Developing Swarms Of Small Drones With Big Military Applications, accessed on July 23, 2025, <https://www.twz.com/17698/chinas-is-hard-at-work-developing-swarms-of-small-drones-on-multiple-levels>
Full article: The Impact of AI on Strategic Stability is What States Make of It: Comparing US and Russian Discourses, accessed on July 23, 2025, <https://www.tandfonline.com/doi/full/10.1080/25751654.2023.2205552>
A legal perspective: Autonomous weapon systems under international humanitarian law - ICRC, accessed on July 23, 2025, <https://www.icrc.org/sites/default/files/document/file_list/autonomous_weapon_systems_under_international_humanitarian_law.pdf>
Aegis Combat System | Lockheed Martin, accessed on July 23, 2025, <https://www.lockheedmartin.com/en-us/products/aegis-combat-system.html>
AEGIS Weapon System > United States Navy > Displayy-FactFiles, accessed on July 23, 2025, <https://www.navy.mil/Resources/Fact-Files/Display-FactFiles/Article/2166739/aegis-weapon-system/>
Aegis Combat System - Wikipedia, accessed on July 23, 2025, <https://en.wikipedia.org/wiki/Aegis_Combat_System>
The Legal and Moral Problems of Autonomous Strike Aircraft | CSBA, accessed on July 23, 2025, <https://csbaonline.org/about/news/the-legal-and-moral-problems-of-autonomous-strike-aircraft>
In the Loop? Armed Robots and the Future of War - Brookings Institution, accessed on July 23, 2025, <https://www.brookings.edu/articles/in-the-loop-armed-robots-and-the-future-of-war/>
MIM-104 Patriot - Wikipedia, accessed on July 23, 2025, <https://en.wikipedia.org/wiki/MIM-104_Patriot>
Report to Congress on Patriot Missile Systems to Ukraine - USNI News, accessed on July 23, 2025, <https://news.usni.org/2025/07/15/report-to-congress-on-patriot-missile-systems-to-ukraine>
Ukraine-Russia war: What are Patriot missile systems—the defence system Kyiv will receive in US military aid - Times of India, accessed on July 23, 2025, <https://timesofindia.indiatimes.com/world/us/ukraine-russia-war-what-are-patriot-missile-systemsthe-defence-system-kyiv-will-receive-in-us-military-aid/articleshow/122555988.cms>
Meaningful Human Control as an Exceptional Concept - EU Non-Proliferation and Disarmament Consortium, accessed on July 23, 2025, <https://www.nonproliferation.eu/wp-content/uploads/2022/01/KakkoMeaningfulHumanControl2022-1.pdf>
Reentering the Loop - Lieber Institute - West Point, accessed on July 23, 2025, <https://lieber.westpoint.edu/reentering-the-loop/>
Meaningful Human Control over Autonomous Systems: A Philosophical Account - PMC, accessed on July 23, 2025, <https://pmc.ncbi.nlm.nih.gov/articles/PMC7806098/>
Full article: Imagining Meaningful Human Control: Autonomous Weapons and the (De-) Legitimisation of Future Warfare - Taylor & Francis Online, accessed on July 23, 2025, <https://www.tandfonline.com/doi/full/10.1080/13600826.2023.2233004>
Meaningful Human Control of Autonomous Weapon Systems | FCAS Forum, accessed on July 23, 2025, <https://www.fcas-forum.eu/publications/Meaningful-Human-Control-of-Autonomous-Weapon-Systems-Eklund.pdf>
What is Meaningful Human Control, Anyway? Cracking the Code on Autonomous Weapons and Human Judgment - Modern War Institute, accessed on July 23, 2025, <https://mwi.westpoint.edu/what-is-meaningful-human-control-anyway-cracking-the-code-on-autonomous-weapons-and-human-judgment/>
A MEANINGFUL FLOOR FOR “MEANINGFUL HUMAN CONTROL” Rebecca Crootof *, accessed on July 23, 2025, <https://sites.temple.edu/ticlj/files/2017/02/30.1.Crootof-TICLJ.pdf>
A Hazard to Human Rights: Autonomous Weapons Systems and Digital Decision-Making, accessed on July 23, 2025, <https://www.hrw.org/report/2025/04/28/hazard-human-rights/autonomous-weapons-systems-and-digital-decision-making>
Lethal Autonomous Weapon Systems (LAWS): Accountability, Collateral Damage, and the Inadequacies of International Law - Temple iLIT, accessed on July 23, 2025, <https://law.temple.edu/ilit/lethal-autonomous-weapon-systems-laws-accountability-collateral-damage-and-the-inadequacies-of-international-law/>
Mind the Gap: The Lack of Accountability for Killer Robots | HRW, accessed on July 23, 2025, <https://www.hrw.org/report/2015/04/09/mind-gap/lack-accountability-killer-robots>
The Interpretation and Application of International Humanitarian Law in Relation to Lethal Autonomous Weapon Systems - UNIDIR, accessed on July 23, 2025, <https://unidir.org/publication/the-interpretation-and-application-of-international-humanitarian-law-in-relation-to-lethal-autonomous-weapon-systems/>
Existing International Humanitarian Law applicable to Lethal Autonomous Weapon Systems, accessed on July 23, 2025, <https://docs-library.unoda.org/Convention_on_Certain_Conventional_Weapons_-Group_of_Governmental_Experts_on_Lethal_Autonomous_Weapons_Systems_(2024)/CCW_GGE1_2024_CRP.3.pdf>
Convention on Certain Conventional Weapons -Group of ..., accessed on July 23, 2025, <https://meetings.unoda.org/ccw/convention-on-certain-conventional-weapons-group-of-governmental-experts-on-lethal-autonomous-weapons-systems-2025>
Stopping Killer Robots: Country Positions on Banning Fully Autonomous Weapons and Retaining Human Control | HRW, accessed on July 23, 2025, <https://www.hrw.org/report/2020/08/10/stopping-killer-robots/country-positions-banning-fully-autonomous-weapons-and>
Russian great power identity in the debate on “killer robots” - Contemporary Security Policy, accessed on July 23, 2025, <http://contemporarysecuritypolicy.org/russian-great-power-identity-in-the-debate-on-killer-robots/>
Russian Federation - Automated Decision Research, accessed on July 23, 2025, <https://automatedresearch.org/news/state_position/russia/>
UK sets out its position on autonomous weapons | Automated Decision Research, accessed on July 23, 2025, <https://automatedresearch.org/news/uk-publishes-its-defence-artificial-intelligence-strategy-addresses-autonomous-weapons-systems/>
UNITED KINGDOM Input to UN Secretary-General's Report on ..., accessed on July 23, 2025, <https://docs-library.unoda.org/General_Assembly_First_Committee_-Seventy-Ninth_session_(2024)/78-241-UK-EN.pdf>
European Parliament Passes Resolution Supporting a Ban on Killer Robots, accessed on July 23, 2025, <https://futureoflife.org/ai/european-parliament-passes-resolution-supporting-a-ban-on-killer-robots/>
International Security and Lethal Autonomous Weapons | EEAS, accessed on July 23, 2025, <https://www.eeas.europa.eu/eeas/international-security-and-lethal-autonomous-weapons_en>
ICRC Position on Autonomous Weapon Systems, accessed on July 23, 2025, <https://www.icrc.org/en/download/file/166330/icrc_position_on_aws_and_background_paper.pdf>
Stop Killer Robots – Less Autonomy, More humanity., accessed on July 23, 2025, <https://www.stopkillerrobots.org/>
AI Arms Races: Implications for Global Stability - The Science Brigade Publishers, accessed on July 23, 2025, <https://thesciencebrigade.com/jcir/article/view/144>
Beyond a Human “In the Loop”: Strategic Stability and Artificial Intelligence, accessed on July 23, 2025, <https://www.armscontrol.org/issue-briefs/2024-011/beyond-the-loop>
Algorithmic Stability: How AI Could Shape the Future of Deterrence - CSIS, accessed on July 23, 2025, <https://www.csis.org/analysis/algorithmic-stability-how-ai-could-shape-future-deterrence>
YL Blog # 90 – Leveling the Battlefield: AI-Enabled Technology in the Hands of Non-State Actors - Pacific Forum, accessed on July 23, 2025, <https://pacforum.org/publications/yl-blog-90-leveling-the-battlefield-ai-enabled-technology-in-the-hands-of-non-state-actors/>
Non state actors can now create lethal autonomous weapons from civilian products, accessed on July 23, 2025, <https://www.weforum.org/stories/2022/05/regulate-non-state-use-arms/>
Autonomous Weapons Systems Proliferation Poses Risks to Human Rights and International Security | OpenReview, accessed on July 23, 2025, <https://openreview.net/forum?id=RX2G6P6wik>
