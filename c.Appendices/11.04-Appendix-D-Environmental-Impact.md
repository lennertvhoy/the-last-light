
Appendix D: The Environmental Footprint of Artificial Intelligence

Introduction: The Unseen Costs of a Digital Revolution

The rapid ascent of artificial intelligence represents a pivotal moment in technological history, promising to redefine industries, accelerate scientific discovery, and reshape human interaction. Yet, this digital revolution is not an ethereal phenomenon occurring in an abstract "cloud." It is a profoundly physical process, underwritten by a global network of massive, energy-hungry data centers and an intricate supply chain that consumes vast quantities of electricity, water, and raw materials.1 The immense computational power required to train and deploy sophisticated AI models gives rise to a significant and often-overlooked environmental footprint, creating a central paradox for the modern era: the pursuit of digital intelligence is inextricably linked to a growing, tangible demand on the planet's finite resources.
The scale of this challenge is staggering and continues to grow at an exponential rate. As of 2022, data centers and the data transmission networks that connect them were already responsible for an estimated 2-3% of global electricity consumption and approximately 1% of energy-related greenhouse gas (GHG) emissions.2 The proliferation of generative AI is the primary catalyst for future growth, with some projections indicating that the electricity demand from data centers in the United States alone could surge from 4% of the national total in 2023 to as high as 12% by 2030.3 This explosive demand is already straining electrical grids, contributing to the delayed retirement of fossil-fuel power plants, and intensifying competition for water in arid regions.1
To fully comprehend the environmental implications of AI, a comprehensive, multi-faceted analysis is required. This appendix provides a detailed examination of AI's environmental footprint, moving from the fundamental metrics of computation to the real-world impacts on energy, carbon emissions, water resources, and hardware lifecycles. It begins by deconstructing the concept of computational demand, explaining the metrics used to quantify the immense scale of modern AI models. It then explores the physical infrastructure—the data centers—that house this computation, analyzing their energy consumption and the metrics used to gauge their efficiency. From there, the analysis broadens to encompass the full carbon footprint, including the crucial distinction between training and inference, the decisive role of the local power grid, and the hidden "embodied" carbon within the hardware itself. The investigation also uncovers AI's often-invisible but critical thirst for water, a resource essential for cooling the engines of the digital age. Finally, this appendix charts a path forward, outlining a suite of mitigation strategies and the emerging paradigm of "Green AI" that aim to reconcile the drive for innovation with the imperative of environmental sustainability.

1. The Engine of AI: Quantifying Computational Demand

At the heart of artificial intelligence lies computation, or "compute"—an abstract term for the raw processing power required to execute the billions of mathematical operations that allow a model to learn from data and generate responses. To grasp the environmental impact of AI, one must first understand how this computational demand is measured and the astronomical scale it has reached in modern systems. This section demystifies the language of compute, providing a foundational framework for the analysis that follows.

1.1. The Language of Compute: Understanding FLOPS

The fundamental unit for quantifying computational workload is the floating-point operation, or FLOP.7 A floating-point operation is a single mathematical calculation involving real numbers with decimal points, such as addition, subtraction, multiplication, or division.8 The rate at which a processor can perform these calculations is measured in
FLOPS, or floating-point operations per second. This metric serves as a primary benchmark for comparing the raw processing power of different computer systems, from personal laptops to the world's most powerful supercomputers.8
In the context of AI, the term "FLOPs" is often used in two distinct ways, which can cause confusion. While it can refer to the rate of operations per second, it more commonly quantifies the total number of floating-point operations required to perform a specific task, such as a single "forward pass" of a neural network to generate one prediction.11 This usage provides a hardware-agnostic measure of a model's computational complexity. For clarity, this text will use "FLOPs" to refer to the rate (operations per second) and explicitly state "total FLOPs" or "FLOP" when referring to the count of operations for a given task, a convention adopted in some technical literature to avoid ambiguity.12 The numbers involved are often so immense that they are expressed using standard prefixes: GigaFLOPs (GFLOPs, or billions of operations), TeraFLOPs (TFLOPs, or trillions), and PetaFLOPs (PFLOPs, or quadrillions).7
However, not all FLOPs are created equal. A nuanced understanding requires differentiating between several types:
Precision: The precision of a floating-point number refers to the number of bits used to store it. Double-precision (FP64) uses 64 bits and is the standard for high-precision scientific computing, such as in the TOP500 supercomputer rankings.10
Single-precision (FP32) uses 32 bits. To improve speed and reduce energy consumption, AI workloads often use mixed-precision formats, which combine 32-bit operations with lower-precision formats like 16-bit (FP16 or bfloat16) or even 8-bit integers (INT8) for certain calculations without a significant loss in model accuracy.10
Theoretical vs. Measured: It is crucial to distinguish between Peak FLOPS and Sustained FLOPS.8 Peak FLOPS represents the theoretical maximum number of operations a processor can perform per second under ideal conditions, as specified by the manufacturer. Sustained FLOPS, in contrast, is the actual performance achieved during a real-world application. This measured value is almost always lower than the theoretical peak due to practical constraints like memory bandwidth, data dependencies, and algorithmic inefficiencies.7
The significant gap between a hardware system's theoretical potential and its real-world performance is a major, often-overlooked source of inefficiency. This gap is quantified by a metric known as Model FLOPs Utilization (MFU), which is calculated as the ratio of the achieved (sustained) FLOPs to the theoretical peak FLOPS of the hardware 7:
MFU=Peak FLOPs/secAchieved FLOPs/sec​
In practice, MFU for large-scale AI training is often in the range of only 30% to 60%.7 This means that up to 70% of a processor's potential computational power—and by extension, its potential energy efficiency—can be lost due to system-level bottlenecks before any other inefficiencies, such as data center cooling, are even considered. Factors like memory access speeds, where the processor waits for data to arrive, and the specific architecture of the AI model can prevent the system from reaching its full arithmetic saturation.14 This inherent inefficiency, baked into the software-hardware interaction, is a foundational element of AI's overall energy consumption.

1.2. The Scaling Imperative: Compute Requirements of Modern Models

The defining trend in AI over the past decade has been one of exponential scaling. Researchers discovered that, for a class of models known as Transformers, performance improves predictably with increases in model size (the number of parameters) and the amount of data used for training. This has led to an arms race to build ever-larger models, demanding astronomical amounts of computation.
The computational cost of training a Transformer-based model can be estimated with a widely accepted formula 15:
Ctrain​≈6ND
Here, Ctrain​ is the total compute for training in FLOP, N is the number of parameters in the model, and D is the number of tokens (pieces of words) in the training dataset. The coefficient 6 arises from the fact that for every parameter in the model, a forward pass (to make a prediction) and a backward pass (to learn from the error) together require approximately 6 floating-point operations per token.15
In contrast, the cost of inference—using the trained model to generate a single new token—is significantly lower, estimated at approximately 1 to 2 FLOP per parameter.16 This simple comparison immediately clarifies why a single query to an AI model is computationally far cheaper than the initial training process. However, as will be explored later, the cumulative cost of billions of inference queries can quickly add up to rival or even surpass the one-time training cost.
This scaling imperative has pushed the computational requirements for state-of-the-art models to staggering levels. As of mid-2025, it is estimated that over 30 publicly announced AI models have been trained using more than 1025 total FLOP—a threshold first crossed by OpenAI's GPT-4 in 2023. Training a model at this scale costs tens of millions of dollars with current hardware.18
The following table, based on data from Epoch AI, provides estimated training compute for several prominent large language models, illustrating the immense scale of these undertakings. The "Confidence" level reflects the degree of public disclosure by the developers, highlighting a growing trend of opacity in the industry—a theme that will be revisited later in this appendix.
Table 1: Estimated Training Compute (FLOPs) for Major LLMs (2023-2025)

Model
Estimated Training Compute (FLOP)
Confidence
Justification for Estimate
Source
GPT-4
2.1×1025
Low-precision
Estimated using training hardware and duration.
18
Llama 3.1-405B
3.8×1025
High-precision
Estimated using parameter count and dataset size.
18
Gemini 1.0 Ultra
5.0×1025
Low-precision
Aggregation of benchmark imputation and hardware details.
18
Claude 3.5 Sonnet
3.6×1025
Low-precision
Imputed from benchmark scores and developer cost estimates.
18
Claude 3.7 Sonnet
3.4×1025
Low-precision
Based on developer cost estimates ("a few tens of millions").
18
Inflection-2
1.0×1025
High-precision
Directly reported by the developer.
18
Llama 4 Behemoth
5.2×1025
High-precision
Preliminary estimate based on parameters and dataset.
18
GPT-4o
3.8×1025
Low-precision
Imputed from benchmark scores.
18
Grok-2
3.0×1025
High-precision
Based on training time, hardware, and developer statements.
18
Claude Opus 4
1.5×1026
Speculative
Inferred from scaling beyond previous models.
18

Source: Adapted from Epoch AI, June 2025.18 Confidence levels (High, Low, Speculative) are assigned by Epoch AI based on the quality and directness of available information.

2. The Physical Infrastructure: Energy Consumption in Data Centers

The abstract world of computation, measured in quadrillions of FLOPs, is made real inside data centers—vast industrial facilities that convert electrical power into digital information. Understanding the energy dynamics of these buildings is the second critical step in assessing AI's environmental footprint. This section bridges the gap between computational demand and real-world electricity consumption, examining the soaring power needs of the AI industry and the primary metric used to evaluate the efficiency of the infrastructure that supports it.

2.1. From Compute to Kilowatt-Hours: The Soaring Demand for Power

The relentless growth in AI workloads translates directly into a massive and accelerating demand for electricity. Globally, data centers consumed an estimated 240-340 Terawatt-hours (TWh) in 2022, roughly 1-1.3% of global final electricity demand. The data transmission networks connecting them consumed a similar amount, between 260-360 TWh.4 While efficiency gains have historically tempered the growth in energy use, the recent explosion in generative AI is overwhelming these improvements.
AI is now the primary driver of new energy demand in the data center sector. The combined electricity consumption of major technology companies like Amazon, Microsoft, Google, and Meta—the key players in AI development—more than doubled between 2017 and 2021, reaching approximately 72 TWh.4 Projections for the coming years are even more dramatic. In the United States, data center electricity demand is forecast to grow at a compound annual rate of 23%, potentially reaching 1,050 TWh, or 12% of the nation's total electricity demand, by 2030.3 This surge is placing unprecedented strain on power grids, forcing utility companies to rapidly reassess their capacity planning and, in some cases, leading to the postponement of planned closures for fossil-fuel power plants, such as coal facilities in Kansas City and West Virginia, to meet the anticipated demand.1

2.2. Measuring Facility Efficiency: Power Usage Effectiveness (PUE)

In response to growing concerns about data center energy consumption, the industry, led by the consortium The Green Grid, developed and endorsed a standard metric called Power Usage Effectiveness (PUE) in 2007.19 PUE is designed to measure the energy efficiency of the data center
facility—that is, how much of the total energy consumed by the building goes directly to powering the IT equipment versus being lost to "overhead" functions like cooling, lighting, and power conversion.
The calculation is a simple ratio 19:
PUE=IT Equipment EnergyTotal Facility Energy​
Total Facility Energy is the total energy consumed by the data center, typically measured at the utility meter. It includes everything: servers, networking gear, cooling systems, lighting, security systems, and energy losses in uninterruptible power supplies (UPS) and power distribution units (PDUs).19
IT Equipment Energy is the portion of energy consumed exclusively by the computing hardware itself—the servers, storage arrays, and network switches that perform the actual work of processing and storing data.20
A PUE of 1.0 represents a theoretical ideal of perfect efficiency, where 100% of the energy entering the facility is used by the IT equipment with zero overhead.21 In reality, this is impossible to achieve. When PUE was introduced, the industry average was a highly inefficient 2.5, meaning for every 2.5 watts drawn from the grid, only 1 watt reached the IT equipment.19 The introduction of PUE spurred a successful industry-wide effort to improve infrastructure efficiency. As of 2021-2023, the global average PUE had fallen to around 1.57, a significant improvement.19
Leading hyperscale data center operators, who have invested heavily in optimized designs and advanced cooling, report even more impressive figures. As of the first quarter of 2025, Google reported a trailing twelve-month (TTM) fleet-wide average PUE of 1.09, meaning only 9% of its energy use is facility overhead.22
The table below presents recent PUE data from a selection of Google's global data centers. It illustrates not only the high efficiency achieved by state-of-the-art facilities but also the variability of the metric based on local climate and season.
Table 2: PUE Values for Representative Hyperscale Data Centers (2024-2025)
Data Center Location
Quarter
Quarterly PUE
Trailing 12-Month (TTM) PUE
Google Fleet-wide Average
Q1 2025
1.08
1.09
Central Ohio, USA (Lancaster)
Q1 2025
1.04
1.04
Hamina, Finland
Q4 2024
1.09
1.10
Dublin, Ireland
Q4 2024
1.08
1.08
Douglas County, Georgia, USA
Q3 2024
1.12
1.09
Storey County, Nevada, USA
Q3 2024
1.22
1.17
Singapore (2nd facility)
Q1 2025
1.14
1.15

Source: Adapted from Google Data Center Efficiency reports, July 2025.22 TTM PUE is a rolling average of the previous four quarters.

2.3. A Critical Examination of PUE's Limitations

Despite its widespread adoption and its success in driving down infrastructure waste, PUE is an incomplete and, at times, misleading metric for overall sustainability. Its limitations are critical to understanding the full environmental picture.
First and foremost, PUE provides a "veneer of efficiency" by focusing solely on the performance of the facility's infrastructure while ignoring the primary source of energy consumption: the IT equipment itself. A data center can boast a world-class PUE while its servers are running inefficient algorithms or are largely idle, consuming vast amounts of power to do little or no useful work.23 The metric's very success in focusing the industry on optimizing the PUE ratio has drawn attention away from the explosive growth in absolute energy consumption. A facility can proudly report an excellent PUE of 1.1 while its total power draw—and thus its environmental impact—doubles year over year to accommodate the insatiable demands of AI.
Second, PUE is blind to the source of energy. It makes no distinction between electricity generated from burning coal and electricity from solar or wind power. A data center in a coal-heavy region with a PUE of 1.5 has a profoundly different carbon footprint than a facility with the same PUE in a region with a clean grid, yet the metric treats them as equivalent.25
Third, PUE was originally intended for internal benchmarking—tracking a single facility's efficiency over time—not for direct, competitive comparisons between different data centers.27 Such comparisons can be highly misleading because PUE is heavily influenced by external factors like local climate, altitude, and data center design, which are beyond an operator's immediate control.24 A facility in a cool climate like Finland can more easily achieve a low PUE through "free cooling" than one in a hot, humid climate like Singapore, which must rely on more energy-intensive chillers.28
Finally, PUE can produce counter-intuitive results. As IT equipment becomes more energy-efficient, the PUE can paradoxically increase (i.e., get worse). This occurs because the IT energy, which is the denominator in the PUE formula (Total/IT), decreases. If the overhead energy remains constant, the ratio increases, making the facility appear less efficient even though the absolute energy consumption has gone down.24 This flaw demonstrates how an obsessive focus on the PUE metric can obscure, and even penalize, genuine progress in overall energy reduction.

3. From Energy to Emissions: A Multi-faceted Carbon Footprint

Converting raw electricity consumption into its ultimate climate impact—the carbon footprint—requires a more complex analysis. The total greenhouse gas emissions associated with an AI model depend not just on how much energy it uses, but on where that energy comes from and the hidden environmental costs embedded in the hardware it runs on. This section reveals that the carbon footprint of AI is a three-dimensional problem, determined by the nature of the computational workload, the carbon intensity of the local power grid, and the lifecycle emissions of the physical infrastructure.

3.1. The Great Debate: Training vs. Inference

For years, the public and academic discourse on AI's environmental impact centered on the enormous, one-time energy cost of training a large model. This intensive process, which can take weeks or months on thousands of specialized processors, generates a significant carbon footprint. Early, influential studies produced alarming comparisons, equating the emissions from training a single large AI model to the lifetime emissions of multiple cars or hundreds of transatlantic flights.1
However, a critical paradigm shift is underway, driven by more recent research and disclosures from major technology companies. While the training phase is undeniably energy-intensive, the focus is now expanding to include the inference phase—the continuous, operational use of a model to answer queries and perform tasks. Although a single inference consumes far less energy than the entire training run, the sheer volume of queries served by a popular model like ChatGPT can lead to a cumulative energy consumption that rivals, and often exceeds, the initial training cost.14
This shift is supported by compelling quantitative evidence from the industry's leading AI developers:
Google analysts have estimated that inference accounts for 60% of the total energy consumed by their generative AI systems, with training making up the remaining 40%.33
Meta has reported that inference processes can be responsible for up to 70% of its total AI-related power consumption.34
Amazon Web Services (AWS) has indicated that inference-related workloads can account for 80-90% of the demand for AI computing resources.34
Independent academic studies corroborate this trend, estimating that inference is responsible for 30-65% of an AI model's total lifecycle emissions, a share that is likely to grow as AI becomes more widely adopted.36
Furthermore, the energy cost of inference is not uniform; it is highly dependent on the specific task being performed. Generative tasks, such as creating text or images, are significantly more computationally expensive and thus cause far more emissions than classification tasks, like identifying objects in a photo or categorizing text.36 Within generative AI, image-related tasks have a considerably higher carbon footprint than non-image tasks. For example, one study found that image generation produced substantially higher emissions than any other task examined, adding a significant environmental concern to the ongoing debates around AI-generated art.36

3.2. The Grid's Decisive Role: The Impact of Carbon Intensity

The amount of carbon dioxide emitted per unit of energy consumed is not a global constant. It is a direct function of the local electricity grid's "carbon intensity," which reflects the mix of energy sources used for generation. A computation powered by a grid that relies heavily on coal or natural gas will have a much higher carbon footprint than the exact same computation performed in a region with abundant hydropower, nuclear, or renewable energy sources.4 This carbon intensity is typically measured in grams of carbon dioxide equivalent per kilowatt-hour (gCO2eq/kWh).
This factor is of paramount importance because data centers are not distributed uniformly across the globe. They are concentrated in specific geographic hubs, chosen for factors like connectivity, land availability, and favorable tax regimes. Major hubs include Northern Virginia in the United States (often called the "data center capital of the world"), Dublin in Ireland, and the city-state of Singapore.2 The immense concentration of data centers in these locations is placing enormous pressure on their local power grids and threatening their ability to meet climate targets. In response, some jurisdictions, including Dublin and Singapore, have been forced to implement temporary moratoria on the construction of new data centers to manage the strain on their energy infrastructure.2
The table below illustrates the dramatic variation in grid carbon intensity across these key hubs, demonstrating why the location of an AI workload is a critical determinant of its environmental impact.
Table 3: Comparative Grid Carbon Intensity (gCO2eq/kWh) for Key Data Center Hubs

Data Center Hub
Carbon Intensity (gCO2/kWh)
Year
Primary Energy Sources
Source
Virginia, USA
~269
2023
Natural Gas (35%), Nuclear (41%), Coal (20%)
38
Ireland (Dublin)
234 (demand) / 291 (generation)
2023
Natural Gas, Wind, Imports
40
Singapore
412
2023
Natural Gas (94.5%)
41
Global Average
~445
2024
Mix of Fossil Fuels, Nuclear, Renewables
42

Sources: U.S. Energy Information Administration (EIA) 38, Ireland's Climate Change Advisory Council 40, Singapore's Energy Market Authority 41, International Energy Agency (IEA).42 Note: Virginia's figure is converted from 594 lbs/MWh. Ireland's figure shows both demand-side intensity (which counts imports as zero-carbon) and higher generation-side intensity.
This data makes it clear that a kilowatt-hour of energy is not environmentally equal across the globe. An AI workload run in Singapore, for instance, will generate over 50% more carbon emissions than the same workload run in Virginia, simply due to the difference in their power grids.

3.3. Embodied Carbon: The Hidden Footprint of Hardware

The carbon footprint analysis is incomplete if it only considers the operational emissions from electricity consumption. A comprehensive accounting must also include the embodied carbon—the greenhouse gas emissions associated with the entire lifecycle of the physical hardware, from the mining of raw materials and manufacturing of components to transportation, and finally, disposal and recycling.43 This holistic approach is known as a
Life Cycle Assessment (LCA).44
Until recently, the embodied carbon of specialized AI hardware like GPUs and TPUs was a major blind spot in environmental analyses. This changed with a groundbreaking February 2025 study from Google, which published the first-of-its-kind, comprehensive LCA of its custom-designed Tensor Processing Units (TPUs).12 This research provided unprecedented insight into the full "cradle-to-grave" emissions of AI accelerators.
The key findings of the Google TPU study were:
Operational Emissions Dominate (For Now): For current generations of TPUs, operational electricity consumption is the largest contributor to lifetime emissions, accounting for over 70% of the total carbon footprint.45 This underscores the immediate importance of improving chip energy efficiency and decarbonizing the power grids that supply them.
Manufacturing Matters: While operational emissions are currently dominant, the embodied carbon from manufacturing is still a significant factor. Crucially, as electricity grids become cleaner and operational emissions decrease, the relative share of embodied carbon in the total lifecycle footprint will grow, making sustainable manufacturing an increasingly critical area of focus.45
A New Metric: Compute Carbon Intensity (CCI): To enable standardized, apples-to-apples comparisons of hardware sustainability across different generations and types of chips, the study introduced a new metric: Compute Carbon Intensity (CCI). It is defined as the total lifecycle carbon emissions per unit of computation 12:
CCI=ExaFLOPgrams of CO2​e​
A lower CCI score indicates a more carbon-efficient accelerator, meaning it generates fewer emissions for the same amount of computational work.
Generational Improvements: The study revealed dramatic improvements in carbon efficiency with each new generation of hardware. Google's 6th-generation TPU, Trillium (TPU v6e), offers a 3x improvement in CCI (i.e., it is three times more carbon-efficient) compared to the TPU v4i, which was released just a few years prior.43 This highlights the rapid pace of innovation in hardware efficiency, which is a powerful lever for mitigating AI's environmental impact.
The interconnectedness of these three dimensions—workload, location, and hardware—is multiplicative. An inefficient, generative inference task (workload) run in a data center on a high-carbon grid (location) using hardware with a large embodied carbon footprint (hardware) represents a worst-case environmental scenario. Conversely, true sustainability requires optimizing across all three dimensions simultaneously: developing efficient algorithms, running them on specialized hardware, and powering that hardware with clean energy in locations with low carbon intensity.

4. The Overlooked Resource: AI's Insatiable Thirst for Water

Beyond energy and carbon, there is another critical, often invisible, resource that underpins the AI industry: water. Data centers, the physical heart of AI, have an immense thirst, consuming billions of liters of freshwater primarily for cooling the powerful processors that generate enormous amounts of heat.6 This section illuminates AI's water footprint, a burgeoning environmental concern that current industry metrics fail to capture adequately.

4.1. Cooling the Cloud: Water's Role and the WUE Metric

The dense concentration of servers in a modern data center generates a tremendous thermal load. To prevent overheating and ensure reliable operation, this heat must be constantly dissipated. While some data centers use air-based cooling, many of the largest facilities rely on evaporative cooling systems, such as cooling towers, which are highly effective but consume large quantities of water.29 In these systems, water is evaporated to remove heat from the facility, a process analogous to how perspiration cools the human body.
To measure the water efficiency of these operations, The Green Grid introduced the Water Usage Effectiveness (WUE) metric. It is defined as the ratio of a data center's annual water consumption to the energy consumed by its IT equipment 47:
WUE=IT Equipment Energy (kWh)Annual Water Consumption (Liters)​
A lower WUE value signifies higher water efficiency. The average data center is estimated to have a WUE of 1.8 L/kWh, meaning it uses 1.8 liters of water for every kilowatt-hour of energy consumed by its servers and storage.47

4.2. Quantifying the Thirst: Water for Training and Inference

Recent research has begun to quantify AI's specific water footprint, and the figures are alarming. A groundbreaking 2023 study, "Making AI Less 'Thirsty'," provided the first detailed public estimates of the water consumed by large language models.50
Key findings from this and related research include:
Training Consumption: The training of OpenAI's GPT-3 model in Microsoft's U.S. data centers is estimated to have directly consumed 700,000 liters (approximately 185,000 gallons) of clean, on-site freshwater for cooling.48 When off-site water used for electricity generation is included, the total operational water footprint for training GPT-3 rises to an estimated
5.4 million liters.50
Inference Consumption: The water footprint extends to every user interaction. The same study estimates that a simple conversation with a model like ChatGPT, consisting of 10 to 50 questions and answers, can "drink" a 500ml bottle of water.6
Projected Global Demand: The cumulative impact is massive. Global AI demand is projected to drive 4.2 to 6.6 billion cubic meters (1.1 to 1.7 trillion gallons) of water withdrawal in 2027 alone—an amount greater than the total annual water withdrawal of countries like Denmark or half that of the United Kingdom.48
Rising Corporate Water Use: This trend is reflected in the sustainability reports of major tech companies. In a single year (2021-2022), Microsoft's water consumption increased by 34%, while Google's rose by 20%, with both companies largely attributing the surge to the demands of their growing AI operations.1
The water footprint of an AI model is not a fixed value; it varies dramatically depending on the geographic location of the data center. This spatial variability is driven by two main factors: the local climate, which dictates the cooling requirements, and the water intensity of the local power grid. The following table, based on data from the "Making AI Less 'Thirsty'" study, provides detailed estimates of the water footprint for training and using GPT-3 in different global locations, powerfully illustrating this variability.
Table 4: Estimated Water Consumption for LLM Training and Inference by Geographic Location
Data Center Location
Total Water for Training (million L)
Water per Inference (mL)

# of Inferences to Consume 500mL Water

U.S. Average
5.44
16.9
29.6
Arizona, USA
9.63
29.9
16.7
Virginia, USA
3.68
11.4
43.7
Iowa, USA
4.81
15.0
33.4
Ireland
2.29
7.1
70.4
Netherlands
5.13
15.9
31.4
Finland
6.56
20.4
24.5
India
6.34
19.7
25.4

Source: Adapted from Peng et al., "Making AI Less 'Thirsty': Uncovering and Addressing the Secret Water Footprint of AI Models," 2023.50 "Total Water for Training" and "Water per Inference" include both on-site (Scope 1) and off-site (Scope 2) operational water consumption.
This data reveals that training the same model in a water-stressed, hot location like Arizona consumes more than four times the water as training it in a cooler, more water-efficient location like Ireland. Similarly, a user in Ireland can ask more than four times as many questions as a user in Arizona before their interaction consumes the same 500ml of water. This underscores that "where" AI is run is a critical determinant of its water footprint.

4.3. Critiquing WUE: A Deceptively Simple Metric

Just as PUE provides an incomplete picture of energy sustainability, the WUE metric has significant limitations that mask the full scope of AI's impact on water resources.
The most significant flaw is the problem of "embedded water." WUE only accounts for the direct, on-site water consumption used for cooling the data center. It completely ignores the vast quantities of "indirect" or "off-site" water that are consumed to generate the electricity powering the facility.29 Power generation, especially from thermal sources like coal, natural gas, and nuclear, as well as some forms of hydropower, is a highly water-intensive process. By failing to include this off-site water footprint, WUE systematically underreports the true water impact of a data center's operations.
Another major critique is that WUE ignores the water source. The metric treats every liter of water equally, making no distinction between drawing scarce, highly treated potable water from a municipal supply and using more sustainable sources like non-potable river water or reclaimed "greywater" from other industrial processes.29 The ecological and societal cost of consuming one liter of drinking water in a drought-stricken region is far greater than that of using one liter of untreated river water in a water-rich area, but WUE is blind to this critical context.
Finally, there is often an inherent trade-off between water efficiency and energy efficiency. Data center operators must choose between different cooling technologies. Air-based cooling systems use more energy (resulting in a worse PUE) but consume little to no water (a perfect WUE of 0). Conversely, water-based evaporative cooling systems are more energy-efficient (a better PUE) but use significant amounts of water (a worse WUE).29 This creates a difficult dilemma for operators, forcing them to balance two competing environmental priorities. Optimizing for one metric can have unintended negative consequences for the other, making holistic sustainability a complex, multi-variable challenge that a single metric like WUE cannot resolve.

5. Charting a Sustainable Path: Mitigation Strategies and Green AI

Analyzing the scale of AI's environmental footprint is a necessary first step, but the ultimate goal is to mitigate it. A growing body of research and industry practice is focused on developing solutions that can reduce the resource intensity of AI without stifling innovation. These strategies span the entire technology stack, from the abstract mathematics of the algorithm and the design of the software, down to the physical silicon of the processors and the location of the data centers. This "full-stack" approach is essential, as optimizations at different layers are not merely additive but often multiplicative in their benefits.

5.1. Algorithmic and Software Innovations ("Software-First" Solutions)

The most fundamental way to reduce AI's environmental impact is to decrease the demand for computation at its source: the model itself. A suite of "software-first" techniques aims to make AI models more efficient, reducing their computational and memory requirements without a significant loss in performance.
Model Pruning and Quantization: These are two of the most effective model compression techniques. Pruning involves systematically identifying and removing redundant or unimportant connections (parameters) within a neural network, akin to trimming the dead branches from a tree. This reduces the model's size and the number of calculations required for each operation. Quantization involves reducing the numerical precision of the model's weights, for example, by converting 32-bit floating-point numbers to 8-bit integers (INT8). This significantly shrinks the model's memory footprint and allows for faster, more energy-efficient computation on compatible hardware.13 Model distillation has been shown to reduce model sizes by up to 90%, leading to a 50-60% reduction in inference energy consumption.53
Knowledge Distillation: This technique involves using a large, powerful "teacher" model to train a much smaller, more efficient "student" model. The student model learns to mimic the outputs and internal representations of the teacher, effectively transferring the larger model's capabilities into a more compact and less computationally expensive architecture.13
Efficient Architectures and Parameter-Efficient Fine-Tuning (PEFT): Researchers are increasingly focused on designing neural network architectures that are inherently more efficient, such as MobileNet and EfficientNet, which were created specifically for low-power devices.13 Alongside this,
PEFT techniques have become crucial for adapting large pre-trained models to new tasks. Instead of retraining the entire multi-billion parameter model (which is prohibitively expensive), methods like Low-Rank Adaptation (LoRA) "freeze" the original model and train only a tiny fraction of new, added parameters. This approach can achieve performance comparable to full fine-tuning while reducing the computational cost by orders of magnitude.13
Adaptive Inference: Not all queries require the same amount of computational effort. Adaptive inference techniques, such as "early exiting," allow a model to dynamically adjust its computation based on the complexity of the input. For a simple, straightforward query, the model might use a shortcut and produce an answer after processing through only a few of its layers. For a more complex query, it would engage the full depth of the network. This avoids wasting energy on unnecessary computations for easy tasks and has been shown to significantly reduce energy consumption during inference by as much as 20%.13

5.2. Hardware and Infrastructure Solutions

Complementing software optimizations are innovations in the physical hardware and infrastructure that power AI. These strategies focus on supplying the necessary computation more efficiently and minimizing the environmental impact of data center operations.
Energy-Efficient Hardware: The development of specialized processors is a cornerstone of sustainable AI. Chips like Google's Tensor Processing Units (TPUs), Apple's Neural Processing Units (NPUs), and the latest generations of GPUs from companies like NVIDIA are not general-purpose processors. They are specifically designed and optimized for the types of matrix multiplication and tensor operations that are the bread and butter of neural networks. This specialization allows them to perform AI-related computations far more efficiently and with lower power consumption than traditional CPUs.13
Carbon-Aware Scheduling: This is a powerful and increasingly popular strategy that leverages the geographic and temporal variability of grid carbon intensity. Instead of running a computationally intensive workload (especially a non-time-sensitive one like model training) at any time or place, carbon-aware scheduling systems intelligently shift the job to a data center location or a time of day when the local electricity grid has the highest proportion of renewable energy available. This directly minimizes the carbon emissions associated with the energy consumed, without changing the model or the hardware.13
Advanced Data Center Design: Beyond the standard PUE improvements, data centers are incorporating more advanced sustainability features. These include free cooling techniques that use ambient outside air or naturally cold water sources to cool the facility, eliminating the need for energy-intensive chillers.28 Another promising area is
waste heat reuse, where the considerable amount of low-grade heat exhausted by a data center is captured and used for other purposes, such as heating nearby residential or commercial buildings, turning a waste product into a valuable resource.26
Edge Computing: For many inference tasks, the computation does not need to happen in a massive, centralized cloud data center. Edge computing involves shifting the workload to the "edge" of the network, onto the local devices where the data is generated or used, such as smartphones, smart speakers, or sensors in a factory. Running AI inference on these smaller, highly optimized, low-power devices can result in remarkable energy savings, with some estimates suggesting a reduction of 100 to 1000 times in power consumption per operation compared to running the same task in the cloud.13

5.3. The Green AI Paradigm

The collection of strategies aimed at reducing AI's environmental cost is often referred to as Green AI. The Green Software Foundation and other researchers define Green AI as work that focuses on improving the efficiency and sustainability of AI systems throughout their lifecycle. This includes everything from designing more efficient algorithms and hardware to powering AI workloads with low-carbon energy sources.54
It is critically important to distinguish Green AI from the related but distinct concept of "AI for Green" (also known as AI for Sustainability). "AI for Green" refers to the application of AI as a tool to help solve environmental problems—for example, using AI to optimize the efficiency of a power grid, monitor deforestation from satellite imagery, or discover new materials for batteries.58 While these applications hold immense promise, focusing on them can risk "greenwashing," where the potential future environmental benefits of AI are used to distract from or justify the immediate and direct environmental costs of developing and running the technology itself. Green AI, in contrast, is about AI cleaning up its own environmental house, ensuring that the technology itself is developed and deployed as sustainably as possible.57

6. Conclusion: The Imperative of Transparency and Informed Choices

The journey from the abstract FLOP to the tangible impacts on global energy grids and water basins reveals a complex and rapidly evolving challenge. The environmental footprint of artificial intelligence is not a simple, single issue but a multi-dimensional problem that demands a holistic understanding and a concerted, multi-pronged response. As AI becomes more deeply integrated into the fabric of society, moving from a niche technology to a ubiquitous utility, the need for accountability, transparency, and sustainable practices becomes paramount.

6.1. Confronting Misinformation by Omission

A significant barrier to addressing AI's environmental impact is a pervasive lack of transparency from the industry's key players. A June 2025 analysis titled "Misinformation by Omission" highlights a deeply concerning trend: as AI models have become more powerful and commercially valuable, the industry has paradoxically become less transparent about its environmental costs.59 An analysis of notable AI models released between 2010 and early 2025 found that while transparency briefly improved around 2022, the period since the launch of ChatGPT has seen a dramatic reversal. By the first quarter of 2025, the majority of new, notable AI models fell into the "no disclosure" category, providing no public data on their energy consumption or carbon footprint.59
This opacity has created a vacuum filled with what the paper calls "misinformation by omission," where a few out-of-context or poorly sourced statistics become widely cited proxies for a much more complex reality. Two prominent examples include:
The "Five Cars" Claim: The oft-repeated statement that "training an AI model emits as much CO2 as five cars in their lifetimes" originates from a 2019 study. However, this figure was from a specific, non-representative case study of a particularly inefficient and computationally intensive research process (neural architecture search). The same study reported much lower emissions for standard model training. While this specific claim has been decontextualized, it is notable that the training of some of today's largest models, like Meta's Llama 3 family, can actually exceed this "five cars" estimate, underscoring the need for specific, model-by-model data rather than generalized tropes.59
The "10x a Google Search" Claim: The popular assertion that a ChatGPT query consumes ten times more energy than a traditional Google search can be traced back to a 2023 off-the-cuff remark, not a rigorous scientific study. The estimate for the Google search itself is based on outdated 2009 data. Yet, this unverified figure has been repeated in dozens of news articles, often without sourcing or qualification, shaping public perception with unreliable information.59
This lack of disclosure is not a passive oversight; it is an active barrier to accountability. It prevents researchers from conducting independent analysis, policymakers from crafting effective regulations, and customers from making environmentally informed choices about the AI services they use.

6.2. A Framework for Holistic Accountability

Addressing this challenge requires moving beyond any single metric. As this appendix has shown, metrics like PUE and WUE, while useful, are deeply flawed and provide an incomplete picture. True accountability requires a holistic framework that incorporates multiple metrics across the full lifecycle of an AI system. A comprehensive sustainability report for an AI model or service should include:
Energy Efficiency (PUE): To measure the efficiency of the data center infrastructure.
Water Efficiency (WUE): To measure on-site water use, but must be accompanied by data on water source (e.g., potable vs. reclaimed) and an acknowledgment of off-site embedded water.
Carbon Usage Effectiveness (CUE): A metric that measures the carbon emissions associated with data center energy consumption, directly incorporating the carbon intensity of the local grid.26
Compute Carbon Intensity (CCI): The new metric from Google's TPU study, which measures the lifecycle carbon efficiency of the hardware itself, including embodied carbon.43
Only by reporting on this full suite of metrics can a complete and honest picture of an AI system's environmental impact emerge. This must be coupled with a commitment to a "cradle-to-grave" Life Cycle Assessment (LCA) approach, which accounts for the environmental costs hidden in the global supply chains of hardware manufacturing and disposal, not just the more easily measured operational impacts.44

6.3. Recommendations for a Sustainable Future

The path toward a more sustainable AI ecosystem requires concerted action from all stakeholders.
For AI Developers and Organizations:
Commit to Radical Transparency: Measure and publicly disclose the energy consumption, carbon emissions (broken down by scope and including both training and inference), and water footprint (including source and volume) for all major models and services. This data should be included in model cards, research papers, and API documentation.51
Embrace Green AI Principles: Integrate environmental efficiency as a core design constraint from the very beginning of the model development lifecycle. Prioritize the use of efficient algorithms, model compression techniques, and specialized hardware.13
Leverage Procurement Power: When using third-party cloud services or APIs, incorporate environmental transparency and performance requirements into contracts and service-level agreements. Demand data from vendors and choose partners who prioritize sustainability.59
For Policymakers:
Mandate Standardized Reporting: Develop and implement clear, mandatory reporting frameworks for the environmental impacts of AI. These could build on existing regulations, such as Europe's Corporate Sustainability Reporting Directive (CSRD), but with specific requirements tailored to the AI value chain.59
Incentivize Sustainability: Create policy incentives, such as tax breaks or carbon credits, that reward the development and adoption of verifiably "Green AI" technologies, energy-efficient hardware, and carbon-aware computing practices.13
Fund Public Research: Support independent, public research into more efficient, transparent, and sustainable AI systems to provide a counterbalance to commercially driven, proprietary development.
For End-Users:
Cultivate Awareness: Recognize that digital interactions have a physical cost. Be mindful of the environmental footprint associated with frequent or computationally intensive use of generative AI services.48
Advocate for Change: As consumers and citizens, demand greater transparency from the technology companies that provide AI services. Support companies and platforms that lead on environmental reporting and performance.
Artificial intelligence is a transformative technology with the potential to bring about immense good. However, its current trajectory of exponential growth in resource consumption is unsustainable. By demystifying its environmental costs, demanding transparency, and embracing a holistic approach to mitigation, we can work to ensure that the pursuit of artificial intelligence does not come at an unacceptable cost to the natural world.
Works cited
Environmental impact of artificial intelligence - Wikipedia, accessed on July 23, 2025, <https://en.wikipedia.org/wiki/Environmental_impact_of_artificial_intelligence>
Growing data volumes drive need for ICT energy innovation - The World Economic Forum, accessed on July 23, 2025, <https://www.weforum.org/stories/2024/05/data-growth-drives-ict-energy-innovation/>
How data centers and the energy sector can sate AI's hunger for power - McKinsey, accessed on July 23, 2025, <https://www.mckinsey.com/industries/private-capital/our-insights/how-data-centers-and-the-energy-sector-can-sate-ais-hunger-for-power>
Data centres & networks - IEA, accessed on July 23, 2025, <https://www.iea.org/energy-system/buildings/data-centres-and-data-transmission-networks>
Data Center Energy Needs Could Upend Power Grids and Threaten the Climate | Article, accessed on July 23, 2025, <https://www.eesi.org/articles/view/data-center-energy-needs-are-upending-power-grids-and-threatening-the-climate>
AI water consumption: Generative AI's unsustainable thirst - The Future of Commerce, accessed on July 23, 2025, <https://www.the-future-of-commerce.com/2023/10/10/ai-water-consumption/>
FLOPs in LLM Training: The Ultimate Guide | by Pratish Dewangan | Jul, 2025 | Medium, accessed on July 23, 2025, <https://medium.com/@dpratishraj7991/flops-in-llm-training-the-ultimate-guide-fce22071ad48>
The Importance of FLOPS and its Impact on Your PC's Speed and ..., accessed on July 23, 2025, <https://www.lenovo.com/us/en/glossary/flops/>
Flops - Lark, accessed on July 23, 2025, <https://www.larksuite.com/en_us/topics/ai-glossary/flops>
FLOPS (Floating Point Operations Per Second) — Klu, accessed on July 23, 2025, <https://klu.ai/glossary/flops>
FLOPs: Machine Learning Model Computational Complexity - Ultralytics, accessed on July 23, 2025, <https://www.ultralytics.com/glossary/flops>
Life-Cycle Emissions of AI Hardware: A Cradle-To-Grave ... - arXiv, accessed on July 23, 2025, <https://arxiv.org/pdf/2502.01671v1.pdf?ref=aquietlittlerebellion.com>
How can we optimize AI and ML algorithms to reduce energy consumption and improve sustainability in computing? | ResearchGate, accessed on July 23, 2025, <https://www.researchgate.net/post/How_can_we_optimize_AI_and_ML_algorithms_to_reduce_energy_consumption_and_improve_sustainability_in_computing>
Quantifying the Energy Consumption and Carbon Emissions of LLM Inference via Simulations - arXiv, accessed on July 23, 2025, <https://arxiv.org/html/2507.11417v1>
The FLOPs Calculus of Language Model Training | by Dzmitry Bahdanau - Medium, accessed on July 23, 2025, <https://medium.com/@dzmitrybahdanau/the-flops-calculus-of-language-model-training-3b19c1f025e4>
Large language model - Wikipedia, accessed on July 23, 2025, <https://en.wikipedia.org/wiki/Large_language_model>
Optimize for inference too, not just training FLOPs - MatX, accessed on July 23, 2025, <https://matx.com/research/lifetime_llm_cost>
Over 30 AI models have been trained at the scale of GPT-4 | Epoch AI, accessed on July 23, 2025, <https://epoch.ai/data-insights/models-over-1e25-flop>
What is Power Usage Effectiveness (PUE)? - Digital Realty, accessed on July 23, 2025, <https://www.digitalrealty.com/resources/articles/what-is-power-usage-effectiveness>
What Is Power Usage Effectiveness (PUE) in the Data Center ..., accessed on July 23, 2025, <https://blog.purestorage.com/purely-educational/what-is-power-usage-effectiveness-pue-in-the-data-center/>
Understanding Power Usage Effectiveness (PUE) in Data Center - Komprise, accessed on July 23, 2025, <https://www.komprise.com/glossary_terms/power-usage-effectiveness-pue/>
Power usage effectiveness – Google Data Centers, accessed on July 23, 2025, <https://datacenters.google/efficiency>
Power usage effectiveness in data centers: Overloaded and underachieving - ResearchGate, accessed on July 23, 2025, <https://www.researchgate.net/publication/303847575_Power_usage_effectiveness_in_data_centers_Overloaded_and_underachieving>
PUE in 2024: What It Is and What It Is Not, accessed on July 23, 2025, <https://blog.stulz-usa.com/pue-2024>
The Importance of Power Usage Effectiveness in a Datacenter, accessed on July 23, 2025, <https://www.trgdatacenters.com/resource/the-importance-of-power-usage-effectiveness-in-a-datacenter/>
How Does Power Usage Effectiveness Work? - Energy → Sustainability Directory, accessed on July 23, 2025, <https://energy.sustainability-directory.com/question/how-does-power-usage-effectiveness-work/>
REHVA Journal Analysis of performance metrics for data center efficiency – should the Power Utilization Effectiveness PUE still be used as the main indicator? (Part 1), accessed on July 23, 2025, <https://www.rehva.eu/rehva-journal/chapter/analysis-of-performance-metrics-for-data-center-efficiency-should-the-power-utilization-effectiveness-pue-still-be-used-as-the-main-indicator-part-1>
PUE: Power usage effectiveness | Flexential, accessed on July 23, 2025, <https://www.flexential.com/resources/brochure/power-usage-effectiveness>
What Is Water Usage Effectiveness (WUE) in Data Centers ..., accessed on July 23, 2025, <https://blog.equinix.com/blog/2024/11/13/what-is-water-usage-effectiveness-wue-in-data-centers/>
Energy-Efficient Training and Inference in Large Language Models: Optimizing Computational and Energy Costs - ResearchGate, accessed on July 23, 2025, <https://www.researchgate.net/publication/392908333_Energy-Efficient_Training_and_Inference_in_Large_Language_Models_Optimizing_Computational_and_Energy_Costs>
Towards Sustainable NLP: Insights from Benchmarking Inference Energy in Large Language Models - arXiv, accessed on July 23, 2025, <https://arxiv.org/html/2502.05610v1>
Measuring and Improving the Energy Efficiency of Large Language Models Inference, accessed on July 23, 2025, <https://www.researchgate.net/publication/381199506_Measuring_and_Improving_the_Energy_Efficiency_of_Large_Language_Models_Inference>
AI's Environmental Impact: Making an Informed Choice - Marmelab, accessed on July 23, 2025, <https://marmelab.com/blog/2025/03/19/ai-carbon-footprint.html>
The Energy Cost of Reasoning: Analyzing Energy Usage in LLMs ..., accessed on July 23, 2025, <https://arxiv.org/pdf/2505.14733>
The Energy Cost of Reasoning: Analyzing Energy Usage in LLMs with Test-time Compute, accessed on July 23, 2025, <https://arxiv.org/html/2505.14733v1>
Emissions from Artificial Intelligence (AI) use — Register Dynamics ..., accessed on July 23, 2025, <https://www.register-dynamics.co.uk/blog/emissions-from-artificial-intelligence-ai-use>
AI's Environmental Impact: Calculated and Explained - Arbor.eco, accessed on July 23, 2025, <https://www.arbor.eco/blog/ai-environmental-impact>
Virginia Electricity Profile 2023 - U.S. Energy Information ..., accessed on July 23, 2025, <https://www.eia.gov/electricity/state/virginia/>
State of Virginia Energy Sector Risk Profile, accessed on July 23, 2025, <https://www.energy.gov/sites/prod/files/2016/09/f33/VA_Energy%20Sector%20Risk%20Profile.pdf>
Annual Review 2024: Electricity - Climate Change Advisory Council, accessed on July 23, 2025, <https://www.climatecouncil.ie/councilpublications/annualreviewandreport/AR2024-Electricity-final.pdf>
EMA | SES Chapter 2: Energy Transformation, accessed on July 23, 2025, <https://www.ema.gov.sg/resources/singapore-energy-statistics/chapter2>
Emissions – Electricity 2025 – Analysis - IEA, accessed on July 23, 2025, <https://www.iea.org/reports/electricity-2025/emissions>
arxiv.org, accessed on July 23, 2025, <https://arxiv.org/html/2502.01671v1>
Google Cloud measures its climate impact through LCA, accessed on July 23, 2025, <https://cloud.google.com/blog/topics/sustainability/google-cloud-measures-its-climate-impact-through-life-cycle-assessment>
TPUs improved carbon-efficiency of AI workloads by 3x | Google Cloud Blog, accessed on July 23, 2025, <https://cloud.google.com/blog/topics/sustainability/tpus-improved-carbon-efficiency-of-ai-workloads-by-3x>
Life-Cycle Emissions of AI Hardware: A Cradle-To-Grave Approach and Generational Trends | AI Research Paper Details - AIModels.fyi, accessed on July 23, 2025, <https://www.aimodels.fyi/papers/arxiv/life-cycle-emissions-ai-hardware-cradle-to>
What Is Water Usage Effectiveness (WUE)? - Sunbird DCIM, accessed on July 23, 2025, <https://www.sunbirddcim.com/glossary/water-usage-effectiveness-wue>
The Often Overlooked Water Footprint of AI Models | by Julia Barnett, accessed on July 23, 2025, <https://generative-ai-newsroom.com/the-often-overlooked-water-footprint-of-ai-models-46991e3094b6>
The Significance of the Water Usage Effectiveness Measure in Data Center Sustainability, accessed on July 23, 2025, <https://www.nlyte.com/blog/the-significance-of-the-water-usage-effectiveness-measure-in-data-center-sustainability/>
Making AI Less 'Thirsty': Uncovering and Addressing the ... - arXiv, accessed on July 23, 2025, <https://arxiv.org/pdf/2304.03271>
Water Is the New CO2 - sustAIn, accessed on July 23, 2025, <https://sustain.algorithmwatch.org/en/water-is-the-new-co2/>
19 Practical Ways To Reduce AI's Environmental Impact - Forbes, accessed on July 23, 2025, <https://www.forbes.com/councils/forbestechcouncil/2025/05/21/19-practical-ways-to-reduce-ais-environmental-impact/>
Investigating Energy Efficiency and Performance Trade-offs in LLM Inference Across Tasks and DVFS Settings - arXiv, accessed on July 23, 2025, <https://arxiv.org/pdf/2501.08219>?
Top 3 Green AI Methods Advancing AI-enabled Sustainability Use Cases | by René Bostic, accessed on July 23, 2025, <https://medium.com/@renebostic/top-3-green-ai-methods-advancing-ai-enabled-sustainability-use-cases-f2b0d806cc6d>
Carbon Emissions in the Tailpipe of Generative AI - Harvard Data Science Review, accessed on July 23, 2025, <https://hdsr.mitpress.mit.edu/pub/fscsqwx4>
AI's Climate Crisis: Are We Burning the Planet to Feed Our Digital Brains? – INDEED, accessed on July 23, 2025, <https://www.indeed-innovation.com/the-mensch/ais-climate-crisis-are-we-burning-the-planet-to-feed-our-digital-brains/>
Green AI Position Paper | GSF - Green Software Foundation, accessed on July 23, 2025, <https://greensoftware.foundation/articles/green-ai-position-paper/>
AI and climate change – Energy and AI – Analysis - IEA, accessed on July 23, 2025, <https://www.iea.org/reports/energy-and-ai/ai-and-climate-change>
Misinformation by Omission: The Need for More ... - arXiv, accessed on July 23, 2025, <http://arxiv.org/pdf/2506.15572>
Misinformation by Omission: The Need for More Environmental Transparency in AI - arXiv, accessed on July 23, 2025, <https://arxiv.org/html/2506.15572v1>
