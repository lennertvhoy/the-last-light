# Bijlage I: Autonome Wapen Systemen: De Derde Revolutie in Oorlogvoering

1.0 Inleiding: Een Nieuw Paradigma van Conflict

1.1 De Dageraad van Algoritmische Oorlogvoering

De aard van oorlogvoering ondergaat een transformatie die zo diepgaand is als die veroorzaakt door de uitvinding van buskruit en de komst van nucleaire wapens.1 Deze hedendaagse verschuiving wordt gedreven door de rijping van kunstmatige intelligentie (AI) en robotica, wat leidt tot een nieuwe klasse van militaire technologie: Autonome Wapen Systemen (AWS). Deze systemen vertegenwoordigen een fundamentele afwijking van eerdere militaire innovaties door aspecten van dodelijke besluitvorming van menselijke soldaten en commandanten naar machines te delegeren.3 In wezen zijn AWS militaire platforms die, eenmaal geactiveerd, onafhankelijk missies kunnen uitvoeren—waaronder het zoeken naar, identificeren, volgen en in sommige gevallen, het aanvallen van doelen—zonder directe menselijke tussenkomst.4
De integratie van AI in wapen systemen maakt het mogelijk om militaire operaties uit te voeren met een snelheid, schaal en complexiteit die de grenzen van menselijke cognitie en reactietijd overschrijden.3 Deze algoritmische capaciteit belooft aanzienlijke militaire voordelen, zoals de mogelijkheid om te opereren in omgevingen zonder communicatie, het verminderen van slachtoffers door menselijke strijders uit gevaarlijke missies te verwijderen, en het functioneren als een "krachtvermenigvuldiger" door het mogelijk te maken dat minder personeel een groter aantal middelen beheert.2 Echter, dezezelfde capaciteit introduceert ongekende strategische risico's. Het vooruitzicht van machines met de macht en discretie om mensenlevens te nemen zonder directe menselijke betrokkenheid roept diepgaande ethische vragen op, creëert complexe juridische uitdagingen met betrekking tot aansprakelijkheid, en bedreigt de wereldwijde veiligheid door het potentieel voor onopzettelijke en snelle escalatie van conflicten.3

1.2 Het Spectrum van Autonomie

Het is cruciaal om te begrijpen dat autonomie in wapen systemen geen monolithisch of binair concept is. In plaats van een eenvoudige schakel van "door mensen gecontroleerd" naar "door machines gecontroleerd," bestaat autonomie op een spectrum dat wordt gedefinieerd door de aard en de mate van menselijke betrokkenheid in het besluitvormingsproces.6 Dit spectrum varieert van semi-autonome systemen, zoals "fire and forget" raketten die zichzelf naar een door mensen geselecteerd doel leiden, tot zeer autonome defensieve systemen die sneller kunnen reageren op binnenkomende bedreigingen dan een menselijke operator, tot de theoretische en zeer betwiste categorie van volledig autonome systemen die onafhankelijk een volledige dodelijke missie van begin tot eind kunnen uitvoeren.6
De discussie rond AWS wordt vaak vertroebeld door sensationele beelden van "moordrobots," een term die, hoewel evocatief, niet de genuanceerde technische en operationele realiteiten van deze systemen vastlegt.3 Een preciezere begrip vereist een kader voor het classificeren van systemen op basis van hun controle-architectuur—de specifieke relatie tussen de menselijke operator en de functies van de machine. Deze bijlage zal een gedetailleerde technische en strategische analyse van deze systemen bieden, verdergaand dan simplistische tropen om de huidige staat van autonome militaire technologie, de mogelijk makende technologieën die de evolutie aandrijven, en de kritische juridische, ethische en geopolitieke dilemma's die het presenteert aan de internationale gemeenschap te analyseren.

2.0 Autonomie in Wapen Systemen Definiëren

De basis van elke rigoureuze analyse van autonome oorlogvoering is een duidelijke en precieze lexicon. Echter, de internationale gemeenschap heeft nog geen consensus bereikt over een universele definitie voor deze systemen, een factor die diplomatieke inspanningen om regelgeving vast te stellen aanzienlijk compliceert.6 Dit gebrek aan een gemeenschappelijke definitie is niet slechts een academische omissie, maar een centraal kenmerk van het geopolitieke landschap, aangezien verschillende definities strategisch kunnen worden gebruikt om de ontwikkeling van bepaalde technologieën te beperken of toe te staan.

2.1 De Terminologie Verduidelijken

Voor de doeleinden van deze analyse is het nuttig om onderscheid te maken tussen twee belangrijke termen:
Autonome Wapen Systemen (AWS): Dit is een brede categorie die elk militair systeem omvat dat, eenmaal geactiveerd, onafhankelijk toegewezen missies kan uitvoeren of specifieke taken kan uitvoeren zonder menselijke tussenkomst.4 Dit kan niet-dodelijke functies omvatten zoals inlichtingen, surveillance en verkenning (ISR), navigatie in complexe omgevingen, of logistieke ondersteuning.
Dodelijke Autonome Wapen Systemen (LAWS): Dit is een specifieke en meer controversiële subset van AWS. LAWS worden gedefinieerd als wapen systemen die sensor suites en computeralgoritmen gebruiken om onafhankelijk doelen te zoeken, identificeren, selecteren en aan te vallen met dodelijke kracht zonder handmatige menselijke controle van het systeem.6 Deze systemen, soms door critici aangeduid als "slachtrobots," zijn geprogrammeerd om een specifiek "doelprofiel" te doden en, eenmaal ingezet, gebruiken ze AI om alles te vinden en te elimineren dat overeenkomt met dat profiel op basis van sensor data alleen.3 Het is deze categorie van wapens die centraal staat in het wereldwijde debat.
De definitional ambiguïteit is een kritische component van internationale strategie. Bijvoorbeeld, China heeft publiekelijk een verbod op LAWS gesteund, maar heeft een uiterst smalle definitie voorgesteld die criteria omvat zoals de "onmogelijkheden van beëindiging" en het vermogen om "autonoom te leren en zijn functies en mogelijkheden uit te breiden voorbij menselijke verwachtingen".12 Een dergelijke definitie beschrijft een hypothetisch, zeer geavanceerd toekomstig systeem dat momenteel niet bestaat, waardoor een breed scala aan zeer autonome systemen wordt uitgesloten van enige potentiële verbod. Deze aanpak stelt een natie in staat om ondersteunend te lijken voor wapenbeheersing terwijl ze tegelijkertijd de ontwikkeling van geavanceerde AWS nastreeft die buiten haar eigen beperkende definitie vallen. Deze semantische manoeuvre benadrukt dat de discussie over definities op zich een strategische inspanning is om de toekomstige juridische en operationele omgeving voor autonome oorlogvoering vorm te geven.

2.2 Het U.S. Department of Defense Kader (DoDD 3000.09)

In de afwezigheid van een internationale consensus is het meest invloedrijke en gedetailleerde beleidskader dat autonome wapens reguleert de U.S. Department of Defense (DoD) Richtlijn 3000.09, "Autonomie in Wapen Systemen," voor het laatst bijgewerkt in januari 2023.6 Deze richtlijn biedt de definities en beleidslijnen die de ontwikkeling en inzet van de VS begeleiden.
Volgens DoDD 3000.09 is een LAWS een "wapensysteem dat, eenmaal geactiveerd, doelen kan selecteren en aanvallen zonder verdere tussenkomst van een menselijke operator".6 Het centrale principe van de richtlijn is echter de verplichting dat alle autonome en semi-autonome wapen systemen "ontworpen moeten zijn om commandanten en operators in staat te stellen passende niveaus van menselijke beoordeling over het gebruik van geweld uit te oefenen".6
De term "passend" is opzettelijk flexibel, erkent dat het noodzakelijke niveau van menselijke beoordeling kan variëren op basis van de context van de missie, de mogelijkheden van het wapen systeem, en de operationele omgeving.6 Belangrijk is dat de richtlijn verduidelijkt dat "menselijke beoordeling over het gebruik van geweld" niet strikt handmatige menselijke "controle" over het vuursysteem vereist. In plaats daarvan impliceert het bredere menselijke betrokkenheid bij de beslissingen over hoe, wanneer, waar en waarom het wapen zal worden ingezet. Dit omvat het waarborgen dat het gebruik ervan voldoet aan het oorlogsrecht, toepasselijke verdragen, wapenveiligheidsregels, en regels voor engagement (ROE).6
Om ervoor te zorgen dat deze standaard wordt gehaald, stelt DoDD 3000.09 een rigoureus beoordelings- en testproces vast. Systemen moeten bewezen worden om:
Functioneren zoals verwacht in realistische operationele omgevingen tegen adaptieve tegenstanders.6
Engagementen binnen een vooraf gedefinieerde tijdsperiode en geografisch gebied te voltooien, in overeenstemming met de intentie van de commandant.6
Voldoende robuust te zijn om de waarschijnlijkheid en gevolgen van storingen te minimaliseren.6
Een volledige herbeoordeling en hercertificering te ondergaan als het gedrag van het systeem verandert als gevolg van machine learning of andere updates.6

2.3 Controle Architecturen: De Mens-Machine Relatie

Het spectrum van autonomie wordt het beste begrepen door zijn controle architecturen, die de functionele relatie tussen de menselijke operator en de besluitvormingslus van het wapen systeem definiëren. Deze architecturen worden voornamelijk onderscheiden door de rol die de mens speelt in de uiteindelijke beslissing om dodelijke kracht toe te passen.
Human-in-the-Loop (HITL): In een HITL-systeem kan de machine veel autonome functies uitvoeren, zoals het zoeken naar, detecteren en volgen van potentiële doelen. Echter, een menselijke operator is een essentieel en actief onderdeel van de besluitvormingslus en moet een laatste, bevestigende opdracht geven om het gebruik van dodelijke kracht te autoriseren.6 Deze architectuur wordt ook wel semi-autonoom genoemd en is kenmerkend voor de meeste momenteel ingezette gewapende onbemande systemen, zoals de MQ-9 Reaper-drone, evenals veel precisiegemodificeerde munitie.14 De machine biedt besluitvormingsondersteuning, maar de mens maakt de uiteindelijke dodelijke beslissing.
Human-on-the-Loop (HOTL): In een HOTL-systeem is de machine in staat om autonoom doelen te selecteren en aan te vallen op basis van zijn programmering en sensordata. De menselijke operator fungeert in een toezichthoudende rol, waarbij hij de operaties van het systeem monitort met de mogelijkheid om in te grijpen en zijn beslissingen te overrulen, waardoor hij effectief een veto-recht heeft.6 Dit model is gebruikelijk in defensieve systemen waar de snelheid van de bedreiging—zoals een binnenkomende raket of granaat—te snel is voor een mens om een volledige besluitvormingscyclus te voltooien. In deze gevallen staat menselijke inactiviteit het systeem toe om zijn vooraf geautoriseerde dodelijke actie uit te voeren.14
Human-out-of-the-Loop (HOOTL): Een HOOTL-systeem is een werkelijk autonoom wapen. Eenmaal geactiveerd, kan het doelen selecteren en aanvallen zonder verdere menselijke tussenkomst, autorisatie of toezicht.6 De menselijke rol is beperkt tot het programmeren van de initiële missieparameters, regels voor engagement, en doelprofielen vóór inzet. Na lancering maakt de machine alle daaropvolgende beslissingen, inclusief de uiteindelijke bepaling om dodelijke kracht te gebruiken.8 Dit is de architectuur die een LAWS in de striktste zin definieert en is de primaire focus van internationale oproepen tot verbod, aangezien het de dodelijke beslissing volledig aan een algoritme delegeert.3
Controle Niveau
Definitie
Menselijke Rol
Systeem Autonomie Niveau
Belangrijk Operationeel Nuance
Voorbeeld Systemen
Human-in-the-Loop (HITL)
Het systeem vereist een directe opdracht van een mens om dodelijke kracht toe te passen.
Actieve Besluitvormer
Laag-Medium (Besluitvormingsondersteuning)
Menselijke actie is vereist voor dodelijke kracht.
Afstand bestuurde drones (bijv. MQ-9 Reaper), veel loitering munitie.
Human-on-the-Loop (HOTL)
Het systeem kan autonoom dodelijke kracht toepassen, maar een mens kan de actie overrulen.
Toezichthouder / Veto Macht
Hoog (Toezichte Autonomie)
Menselijke inactiviteit staat dodelijke kracht toe.
Defensieve systemen (bijv. Phalanx CIWS, Iron Dome), sommige loitering munitie.
Human-out-of-the-Loop (HOOTL)
Het systeem kan dodelijke kracht toepassen zonder enige real-time menselijke input of toezicht.
Missieplanner / Programmeur
Volledig (Onbeheerde Autonomie)
Mens heeft geen real-time rol in dodelijke kracht beslissingen.
Hypothetische toekomstige offensieve LAWS (bijv. "Slachtrobots"), sommige antivoertuigmijnen.

Tabel 1: Spectrum van Menselijke Controle Architecturen. Deze tabel biedt een vergelijkend overzicht van de drie primaire controlemodellen, waarbij de kritische operationele, juridische en ethische onderscheidingen worden verduidelijkt die de mens-machine relatie in wapen systemen definiëren.

3.0 Huidige en Opkomende Systemen: Een Multi-Domein Overzicht

De theoretische constructies van autonome oorlogvoering materialiseren snel in tastbare militaire hardware in alle operationele domeinen. Van de luchten boven Oekraïne tot de diepten van de Stille Oceaan worden systemen met toenemende niveaus van autonomie ontwikkeld, getest en ingezet. Dit gedeelte biedt een overzicht van belangrijke huidige en opkomende autonome systemen in de lucht, op land en op zee, en illustreert de praktische toepassing van de hierboven gedefinieerde concepten. Een opmerkelijke trend is de verschuiving in de rol van autonomie van voornamelijk ondersteunende "dull, dirty, and dangerous" missies, zoals langdurige surveillance, naar een actieve deelnemer in de "detect, decide, and destroy" sequentie van de kill chain.2 Deze evolutie van een passieve sensor naar een actieve schutter is de centrale dynamiek die de ontwikkeling van moderne AWS aandrijft.

3.1 Lucht systemen: Van Attritable Drones tot "Loyal Wingmen"

Het luchtdomein is het meest zichtbare en dynamische theater voor de vooruitgang van autonome technologieën, gestimuleerd door zowel high-end door de staat geleide programma's als snelle, door het slagveld gedreven innovatie.

3.1.1 Loitering Munitions ("Suicide Drones")

Loitering munitions zijn een hybride van een kruisraket en een drone. Ze kunnen worden gelanceerd zonder een specifiek doel te hebben en kunnen "loiter" boven een slagveld voor een langere periode, waarbij ze hun onboard sensoren gebruiken om autonoom te zoeken naar, detecteren en classificeren van doelen die overeenkomen met een vooraf geprogrammeerd profiel. Zodra een doel is geïdentificeerd, valt de munitie aan door er tegenaan te crashen en zijn oorlogskop te detoneren.10 Terwijl veel systemen een human-in-the-loop behouden voor de uiteindelijke aanval autorisatie, vertegenwoordigt hun vermogen om autonoom naar doelen te jagen een significante stap in operationele autonomie.
De Russische invasie van Oekraïne in 2022 heeft gediend als een smeltkroes voor loitering munitie technologie, die de tactische effectiviteit heeft aangetoond en snelle evolutie heeft aangewakkerd.16
Belangrijke Systemen in Oekraïne: Oekraïense strijdkrachten hebben op grote schaal gebruik gemaakt van door de VS geleverde systemen zoals de AeroVironment Switchblade (een klein, rugzak-draagbaar systeem) en de Phoenix Ghost.4 Rusland heeft zijn binnenlands geproduceerde ZALA Lancet en door Iran geleverde drones zoals de Shahed-136 ingezet.17
Low-Cost Innovatie: Het conflict heeft ook geleid tot de proliferatie van geïmproviseerde "FPV loitering munitions," waarbij commerciële first-person-view racen drones zijn aangepast om kleine explosieve ladingen zoals RPG-oorlogsheads of granaten te vervoeren. Deze goedkope systemen, vaak gefinancierd door vrijwilligersgroepen en geproduceerd in duizenden per maand, hebben bewezen zeer effectief te zijn tegen gepantserde voertuigen en personeel, wat een krachtige vorm van asymmetrische oorlogvoering aantoont.17
Volgende Generatie Systemen: In erkenning van het belang van deze capaciteit investeren landen zoals Frankrijk in meer geavanceerde platforms. De MATARIS-familie van loitering munitions, ontwikkeld door KNDS, omvat systemen zoals de vaste vleugel MV-25 Oskar (al ingezet in Oekraïne) en de quadcopter MX-10 Damocles. Deze systemen beschikken over geavanceerde mogelijkheden zoals storingsbestendige datalink en de mogelijkheid om te navigeren in GNSS-ontkende omgevingen, terwijl ze expliciet een menselijke operator in de lus houden voor het laatste aanval commando, waardoor een aanval tot het moment van impact kan worden afgebroken.18

3.1.2 Samenwerkende Gevechtsvliegtuigen (CCAs)

CCAs vertegenwoordigen de volgende grote evolutie in luchtgevechten, waarbij ze verder gaan dan enkele onbemande platforms naar teams van bemande en onbemande vliegtuigen. Vaak aangeduid als "loyal wingmen," zijn CCAs grote, hoogpresterende, semi-autonome UCAV's die zijn ontworpen om naast en ter ondersteuning van bemande gevechtsvliegtuigen zoals de F-35 en de toekomstige Next-Generation Air Dominance (NGAD) jager te vliegen.20 De visie van de U.S. Air Force is om een vloot van ten minste 1.000 CCAs aan te schaffen, waarbij twee worden gekoppeld aan elk van zijn 500 geavanceerde jagers, om massa aan zijn strijdkracht toe te voegen tegen een fractie van de kosten van extra bemande vliegtuigen.21 CCAs worden verwacht een verscheidenheid aan missies uit te voeren, waaronder ISR, elektronische oorlogsvoering, en het vervoeren van extra munitie om doelen aan te vallen op aanwijzing van de bemande jachtpiloot.20
Boeing MQ-28 Ghost Bat: Ontwikkeld in samenwerking met de Royal Australian Air Force, is de Ghost Bat een fundamenteel programma voor de ontwikkeling van CCA. Het is een stealthy, jachtachtige UCAV die is ontworpen om als een krachtvermenigvuldiger te fungeren. Vliegtests hebben zijn vermogen aangetoond om samen te werken met bemande middelen, zoals een E-7 Wedgetail luchtwaarschuwings- en controlevliegtuig, om missies uit te voeren zoals het uitbreiden van de sensorbereik en het bieden van een defensieve bescherming voor het hogere waarde bemande platform.23
Kratos XQ-58A Valkyrie: De Valkyrie is een belangrijk platform in de verkenning van "attritable" vliegtuigen door het Amerikaanse leger—systemen die goedkoop genoeg zijn om in risicovolle of verloren omgevingen te worden ingezet zonder catastrofale strategische gevolgen. Het is een hoog-subsonische, langeafstand UCAV die kan worden gelanceerd vanuit een railsysteem zonder een landingsbaan.27 De U.S. Air Force en Marine Corps testen het uitgebreid voor verschillende rollen, waaronder als communicatiepoort en in een elektronische aanval configuratie.28 Terwijl het formele CCA-programma van de luchtmacht vooruitgang heeft geboekt met contracten aan General Atomics voor de YFQ-42A en Anduril voor de YFQ-44A, is de ontwikkeling van de Valkyrie instrumenteel geweest in het bewijzen van de operationele concepten.22

3.2 Grondsystemen: De Dageraad van het Robotic Battlefield

De ontwikkeling van autonome grondsystemen is uitdagender gebleken dan in de lucht vanwege de complexiteit en onvoorspelbaarheid van terrestrische terreinen. Desondanks zijn er aanzienlijke onderzoeks- en ontwikkelingsinspanningen gaande om Robotic Combat Vehicles (RCVs) in te zetten die verkenning kunnen uitvoeren, vuursteun kunnen bieden en obstakels kunnen doorbreken, waardoor het risico voor menselijke soldaten wordt verminderd.

3.2.1 Het RCV Programma van het Amerikaanse Leger

Het RCV-programma van het Amerikaanse leger is een belangrijke, zij het turbulente, inspanning om autonomie in zijn grondtroepen te integreren. De initiële visie was voor een familie van voertuigen in lichte, middelgrote en zware klassen.30 Echter, het programma heeft aanzienlijke tegenwind ondervonden. Tegen 2023 was de inspanning beperkt tot de focus op de RCV-Light variant.31
In een belangrijke ontwikkeling in mei 2025 kondigde het leger aan dat het het RCV-programma in zijn huidige structuur stopzette.32 Deze beslissing was geen afwijzing van de behoefte aan robot voertuigen, maar eerder een fundamentele herbeoordeling van de acquisitiestrategie. De legerleiding citeerde zorgen over hoge kosten (bijna $3 miljoen per voertuig), het risico om aan een enkele leverancier gebonden te zijn, en, het belangrijkste, de erkenning dat de kern autonomie software en off-road navigatiecapaciteiten nog niet volwassen genoeg waren voor een grootschalig productieprogramma.30 Het leger is van plan de inspanning opnieuw open te stellen voor een breder consortium van leveranciers om zich te concentreren op het ontwikkelen van robuustere en kosteneffectievere software voordat een definitief voertuigplatform wordt geselecteerd.32

3.2.2 DARPA's Fundamenteel Onderzoek

De technische uitdagingen die door de pauze van het RCV-programma zijn benadrukt, worden rechtstreeks aangepakt door fundamenteel onderzoek bij het Defense Advanced Research Projects Agency (DARPA).
RACER (Robotic Autonomy in Complex Environments with Resiliency): Het RACER-programma richt zich volledig op het moeilijkste probleem voor grondautonomie: hoge snelheid, off-road navigatie in ongestructureerde, militaire relevante omgevingen.33 Het doel is om platform-onafhankelijke software-algoritmen te ontwikkelen die een onbemand grondvoertuig (UGV) in staat stellen om zich over complex terrein te verplaatsen met snelheden die vergelijkbaar zijn met die van een menselijke bestuurder, een capaciteit die ver boven die van commerciële zelfrijdende auto's ligt die opereren in sterk gestructureerde wegnetwerken.34 Het programma test zijn algoritmen op meerdere voertuigtypes, waaronder 12-ton tracked voertuigen die vergelijkbaar zijn in grootte met toekomstige RCV's.34
GXV-T (Ground X-Vehicle Technologies): Dit programma heeft als doel het traditionele paradigma van het ontwerp van gepantserde voertuigen te verstoren, dat overlevingskansen gelijkstelt aan zware bepantsering. Het doel van GXV-T is om de mobiliteit en overlevingskansen van voertuigen te verbeteren door andere middelen, zoals wendbaarheid en reductie van het signatuur.35 De ambitieuze technische doelen omvatten het verminderen van de grootte en het gewicht van voertuigen met 50%, het verhogen van de snelheid met 100%, en het ontwikkelen van concepten voor "overleving door wendbaarheid," zoals autonoom vermijden van binnenkomende bedreigingen of actief herpositioneren van bepantsering om een projectiel in real-time te verslaan.35

3.3 Maritieme en Onderzeese Systemen: Autonomie op Zee en in de Diepte

Maritieme strijdkrachten maken steeds meer gebruik van autonomie voor missies variërend van oppervlaktebescherming tot langdurige onderzeese surveillance, waarbij ze profiteren van de minder drukke maritieme omgeving.

3.3.1 Oppervlakteverdediging

Phalanx Close-In Weapon System (CIWS): Een alomtegenwoordig kenmerk op oorlogsschepen van de Amerikaanse marine en bondgenoten, de Phalanx is een autonoom wapen systeem dat fungeert als de laatste verdedigingslinie tegen anti-scheepsraketten, vliegtuigen en kleine boten.36 Het geïntegreerde radar- en vuursysteem stelt het in staat om autonoom te zoeken naar, detecteren, volgen, aanvallen en kill assessment uit te voeren op binnenkomende bedreigingen met een hoge vuursnelheid.37 De Block 1B-upgrade voegt een Forward-Looking Infrared (FLIR) sensor toe, die zijn vermogen om kleine, manoeuvrerende oppervlaktevaartuigen en laagvliegende bedreigingen in littorale omgevingen aan te vallen aanzienlijk verbetert.36 De Phalanx is een klassiek voorbeeld van een human-on-the-loop systeem, dat automatisch opereert vanwege extreme tijdsdruk, maar onder toezicht van de bemanning van het schip.

3.3.2 Extra-Grote Onbemande Onderzeese Vaartuigen (XLUUVs)

XLUUVs vertegenwoordigen een nieuwe grens in onderzeese oorlogvoering, voorgesteld als grote, langdurige autonome onderzeeërs die in staat zijn om missies weken of maanden uit te voeren zonder menselijke tussenkomst.
Boeing Orca: De eerste XLUUV van de Amerikaanse marine, de Orca is gebaseerd op Boeing's eerdere Echo Voyager prototype.39 Het is een modulaire, 50-ton diesel-elektrische onderzeeër met een grote laadruimte, ontworpen voor missies zoals covert mijnen leggen, anti-onderzeebooroorlogvoering, en onderzeese surveillance.39 Het programma heeft aanzienlijke uitdagingen ondervonden, met meldingen dat het drie jaar achter op schema ligt en 64% boven budget is.39 Ondanks deze tegenslagen heeft Boeing in december 2023 het eerste Orca-testvoertuig aan de marine geleverd, wat een belangrijke mijlpaal markeert in de ontwikkeling van deze capaciteit.39
Northrop Grumman Manta Ray: Een door DARPA gefinancierd programma, Manta Ray heeft als doel een nieuwe klasse van UUV te ontwikkelen die in staat is tot langdurige, langeafstandmissies in oceanen waar mensen niet kunnen komen.41 Belangrijke innovaties omvatten een zeer modulaire ontwerp dat het voertuig in standaardcontainers kan laten verzenden en in het veld kan worden geassembleerd, en de mogelijkheid om aan de zeebodem te verankeren en in een laag-energie hibernatiestatus te gaan om energie te besparen en zijn operationele persistentie te verlengen.41

3.4 Defensieve Interceptiesystemen: Hoge Snelheid, Geautomatiseerde Bescherming

Sommige van de meest volwassen en wijdverspreide autonome systemen zijn defensief van aard. Hun autonomie is een directe reactie op de operationele noodzaak om bedreigingen tegen te gaan, zoals raketten en mortieren, waarvan de vliegtijden te kort zijn voor een mens om effectief de hele engagementcyclus te voltooien. Deze systemen opereren op een human-on-the-loop basis, waarbij menselijke commandanten de regels voor engagement vaststellen, maar het systeem de interceptie autonoom uitvoert.
Israël's Iron Dome: Dit Counter-Rocket, Artillery, and Mortar (C-RAM) systeem is een van de meest succesvolle luchtverdedigingssystemen ter wereld.42 Ontwikkeld door Rafael Advanced Defense Systems, gebruikt het een geavanceerde radar om binnenkomende kortere raketten en granaten te detecteren en te volgen.43 Het gevechtsmanagement- en controlesysteem (BMC) maakt gebruik van geavanceerde algoritmen, recent verbeterd met AI, om de baan van het projectiel en het verwachte impactpunt te berekenen.44 Cruciaal is dat het systeem is geprogrammeerd om alleen die projectielen aan te vallen die een bedreiging vormen voor aangewezen bevolkte gebieden of kritieke infrastructuur, waardoor dure interceptors worden bespaard.43 Deze autonome prioritering en engagementcapaciteit heeft de Iron Dome in staat gesteld een succespercentage te behalen dat naar verluidt meer dan 90% is.42
Land-Based Phalanx Weapon System (LPWS / C-RAM): Dit systeem past de maritieme Phalanx CIWS aan voor landgebaseerde puntverdediging van vooruitgeschoven bases en andere kritieke locaties.38 Het systeem netwerkt het Phalanx-wapen met grondgebaseerde radar, zoals de AN/TPQ-36 Firefinder, die binnenkomende mortier- en raketvuur detecteert.38 Wanneer een bedreiging wordt gedetecteerd, biedt het systeem een waarschuwing aan personeel en kan het autonoom het projectiel in de lucht aanvallen en vernietigen met hoog-explosieve granaten.38 Het hoge niveau van automatisering is essentieel om binnen het secondenlange engagementvenster te reageren dat typisch is voor deze bedreigingen.46
De wijdverspreide inzet en het succes van deze systemen illustreren een cruciaal punt in het debat over autonomie: in bepaalde goed gedefinieerde, defensieve scenario's is een hoog niveau van autonomie niet alleen geaccepteerd, maar wordt het als essentieel beschouwd voor effectieve bescherming.

4.0 De Technologische Voorhoede: Kern Enablers van Autonomie

De proliferatie van autonome systemen in militaire domeinen is niet het resultaat van een enkele doorbraak, maar eerder de convergentie van verschillende belangrijke technologische stromen. Vooruitgang in kunstmatige intelligentie, sensortechnologie en netwerken zijn de fundamentele pijlers waarop moderne AWS zijn gebouwd. Het begrijpen van deze kern enablers is essentieel om zowel de mogelijkheden als de beperkingen van huidige en toekomstige autonome wapens te waarderen.

4.1 Kunstmatige Intelligentie: De "Hersenen" van de Machine

Kunstmatige intelligentie is de centrale enabling technologie voor AWS, die de "hersenen" biedt die een machine in staat stelt om zijn omgeving waar te nemen, beslissingen te nemen en actie te ondernemen zonder directe menselijke controle.1 Hoewel AI geen vereiste is voor alle autonome functies, breidt de integratie ervan de mogelijkheden van een systeem dramatisch uit, waardoor het kan overgaan van eenvoudige vooraf geprogrammeerde acties naar adaptieve, data-gedreven gedragingen.10

4.1.1 Computer Vision en Doelherkenning

De meest kritische AI-functie voor elk wapen systeem is het vermogen om een doel correct te identificeren. Computer vision, een gebied van AI dat computers traint om de visuele wereld te interpreteren en begrijpen, staat centraal in deze capaciteit.48 In een AWS-context analyseren algoritmen enorme stromen data van elektro-optische, infrarood en andere sensoren om drie belangrijke taken uit te voeren:
Detectie: Het identificeren van een object van belang binnen het gezichtsveld van de sensor.
Classificatie: Bepalen wat het object is (bijv. een tank, een vrachtwagen, een persoon).
Tracking: Het volgen van de beweging van het object in de tijd.49
Deze technologie wordt al gebruikt in een besluitvormingsondersteunende rol in systemen zoals loitering munitions, waar AI-gestuurde doelherkenning een menselijke operator helpt bij het identificeren en bevestigen van een doel voordat een aanval.4 De belangrijkste juridische en ethische uitdaging ontstaat wanneer deze functie volledig geautomatiseerd is. Het vermogen van een algoritme om betrouwbaar te onderscheiden tussen een strijdende met een wapen en een burger met een landbouwgereedschap, of tussen een actieve vijandelijke soldaat en iemand die zich overgeeft (hors de combat), vereist een niveau van contextueel begrip en genuanceerde beoordeling dat een diepgaande technische hindernis blijft.49

4.1.2 Besluitvormingsalgoritmen en Versterkend Leren

Naast eenvoudige herkenning is de volgende grens voor militaire AI tactische besluitvorming. Dit houdt in dat systemen niet alleen moeten zien, maar ook een koers van actie moeten beslissen. Een belangrijk onderzoeksgebied is Deep Reinforcement Learning (DRL), een type machine learning waarbij een AI "agent" leert om een doel te bereiken in een complexe, onzekere omgeving.51
In DRL leert de agent door middel van trial and error. Het interacteert met een gesimuleerde omgeving, onderneemt acties en ontvangt feedback in de vorm van "beloningen" of "straffen." Over miljoenen iteraties leert het neurale netwerk van de agent een beleid—een strategie voor het in kaart brengen van situaties naar acties—dat zijn cumulatieve beloning maximaliseert.51 Deze aanpak stelt een systeem in staat om complexe, adaptieve gedragingen te ontwikkelen voor taken zoals autonome navigatie, obstakelvermijding en zelfs gevechtsbetrokkenheid, zonder expliciet te worden geprogrammeerd voor elke mogelijke noodsituatie.51 Dit vermogen om te leren en zich aan te passen is wat toekomstige AWS een beslissende voorsprong kan geven in dynamische slagveldcondities, maar het is ook een bron van aanzienlijke bezorgdheid vanwege de inherente onvoorspelbaarheid van opkomende gedragingen.

4.2 Waarneming en Perceptie: Het Zien en Begrijpen van het Slagveld

De intelligentie van een autonoom systeem is slechts zo goed als de data die het ontvangt. Het vermogen om een rijk, nauwkeurig, real-time model van de operationele omgeving te bouwen is een vereiste voor enige zinvolle autonome actie.

4.2.1 Geavanceerde Sensor Suites en Fusie

Moderne militaire platforms zijn uitgerust met een diverse array van sensoren, waaronder hoog-resolutie elektro-optische (EO) camera's, infrarood (IR) sensoren voor het detecteren van warmtehandtekeningen, radar voor het volgen van objecten door weer en obscuranten, en LiDAR (Light Detection and Ranging) voor het creëren van nauwkeurige 3D-kaarten van de omgeving.11
Echter, de kritische enabling technologie is niet de individuele sensoren maar sensor fusie. Dit is het proces waarbij AI-algoritmen intelligent de datastromen van meerdere, verschillende sensoren combineren om een enkel, verenigd operationeel beeld te produceren dat nauwkeuriger, completer en betrouwbaarder is dan de informatie van een enkele sensor alleen.56 Bijvoorbeeld, sensor fusie kan een radartrack correleren met een IR-handtekening en een EO-afbeelding om met hoge zekerheid te bevestigen dat een gedetecteerd object een vijandelijke tank is en geen civiele bus, zelfs in rommelige of ongunstige omstandigheden.58 Dit vermogen om een robuuste perceptie van de realiteit te creëren is fundamenteel voor autonome targeting en navigatie.

4.2.2 Navigatie in Betwiste Omgevingen

Een primaire drijfveer voor militaire autonomie is de noodzaak om effectief te opereren in omgevingen waar tegenstanders actief zullen proberen de command- en controleverbindingen te verstoren, inclusief door het verstoren of spoofen van het Global Navigation Satellite System (GNSS), zoals GPS.4 Bijgevolg is een cruciale capaciteit voor AWS het vermogen om nauwkeurig te navigeren in deze "GNSS-ontkende" omgevingen. Belangrijke technologieën die worden ontwikkeld om deze uitdaging aan te pakken, omvatten:
Inertial Navigation Systems (INS): Deze systemen gebruiken versnellingsmeters en gyroscopen om de positie van een voertuig ten opzichte van een bekend startpunt te volgen. Hoewel zelfvoorzienend, zijn ze gevoelig voor drift in de tijd.59
Visueel-gebaseerde Navigatie: Deze technieken gebruiken camera's en computer vision-algoritmen om te navigeren. Visuele Inertial Odometry (VIO) combineert cameradata met INS-gegevens om drift te corrigeren.60
Simultaneous Localization and Mapping (SLAM) stelt een systeem in staat om een kaart van een onbekende omgeving te bouwen terwijl het tegelijkertijd zijn eigen locatie binnen die kaart bijhoudt.60 Deze technologieën stellen een drone of UGV in staat om te navigeren door te verwijzen naar herkenningspunten en kenmerken in zijn directe omgeving, net zoals een mens dat doet, wat veerkracht biedt tegen GNSS-onderbreking.18

4.3 Zwermintelligentie: De Kracht van het Collectief

Droneswermen vertegenwoordigen een paradigmaverschuiving in onbemande systemen, waarbij ze overgaan van de werking van enkele, hoogwaarde platforms naar het gecoördineerd gebruik van vele, vaak goedkope en attritable, agenten om een collectief doel te bereiken.5 De militaire bruikbaarheid van zwermen ligt in hun vermogen om vijandelijke verdedigingen te satureren, veerkrachtige en redundante waarneming over een groot gebied te bieden, en complexe, multi-aspect aanvallen uit te voeren die onmogelijk te coördineren zijn met alleen menselijke piloten.63

4.3.1 Gedecentraliseerde Controle en Communicatie

Een echte zwerm wordt onderscheiden van een eenvoudige groep drones door zijn controle-architectuur. In plaats van dat elke drone individueel wordt gecontroleerd door een centraal commandostation, communiceren zwermleden rechtstreeks met elkaar in een gedecentraliseerd, ad-hoc netwerk.62 Ze maken gebruik van "zwermintelligentie" algoritmen, vaak geïnspireerd door biologische systemen zoals mierenkolonies of vogelzwermen, om collectieve beslissingen te nemen en hun acties te coördineren op basis van een gedeeld begrip van de missie en de omgeving.62 Deze gedecentraliseerde structuur maakt de zwerm zeer veerkrachtig; het verlies van individuele eenheden compromitteert de missie niet, aangezien de resterende agenten het netwerk dynamisch kunnen herconfigureren en hun gedrag kunnen aanpassen.65 Dit vereist robuuste, storingsbestendige en zelfherstellende communicatieprotocollen, vaak vormend wat bekend staat als een Flying Ad-Hoc Network (FANET).67

4.3.2 Belangrijke Internationale Programma's

Het strategische potentieel van zwermtechnologie heeft geleid tot aanzienlijke investeringen van grote militaire machten.
Verenigde Staten: In augustus 2023 kondigde het Pentagon het Replicator-initiatief aan, een belangrijke strategische inspanning om duizenden kleine, slimme en goedkope autonome systemen in alle domeinen binnen 18-24 maanden in te zetten. Het expliciete doel is om "attritable massa" te gebruiken om het numerieke voordeel van potentiële tegenstanders zoals China tegen te gaan.62 Dit initiatief wordt ondersteund door uitgebreide experimenten in oefeningen zoals het Project Convergence en Vanguard 24 van het leger, die zwerm ISR en teaming capaciteiten testen.69 De U.S. Navy is ook bezig met een "Super Swarm" project om methodologieën te ontwikkelen voor het overweldigen van vijandelijke verdedigingen met grote aantallen kleine drones.71
China: China heeft zijn bekwaamheid in dronecoördinatie gedemonstreerd door middel van enorme publieke lichtshows, waarvan er een meer dan 11.000 drones in formatie had.72 Militair gezien ontwikkelt het geavanceerde zwermcapaciteiten, benadrukt door de onthulling van de Jiu Tian "moederschip", een groot UAV dat is ontworpen om kleinere zwermen drones diep in betwiste luchtgebieden te dragen en in te zetten.62
Andere Naties: De ontwikkeling is wijdverspreid. Het Verenigd Koninkrijk ontwikkelt een veilige architectuur voor Mixed Multi-Domain Swarms (MMDS) van lucht-, land- en zeewagens.62
Duitsland's KITU 2-programma integreert AI-gestuurde zwermgedragingen voor multi-UAV coördinatie in GPS-ontkende omstandigheden.62
Zweden heeft software onthuld die in staat is om tot 100 UAS tegelijkertijd te controleren.62
Turkije ontwikkelt sinds 2020 zwermtechnologie voor zijn Kargu-2 loitering munitie, met de mogelijkheid om in zwermen van maximaal 20 drones te opereren.62
Land/Blok
Programmanaam/Iniciatief
Domein
Verklaring Doel
Verenigde Staten
Replicator-initiatief / Samenwerkende Gevechtsvliegtuigen (CCA)
Multi-Domein / Lucht
Massale attritable autonomie; "Loyal wingman" voor jagers.
China
Jiu Tian Moederschip
Lucht
Langdurige inzet van kleinere dronezwermen.
Verenigd Koninkrijk
Progeny Maritime Research Framework (MMDS)
Multi-Domein
Veilige architectuur voor gemengde lucht-, land- en zeewormen.
Duitsland
KITU 2
Lucht
AI-gestuurde zwermgedragingen en coördinatie in GPS-ontkende omgevingen.
Frankrijk
Larinae / Colibri
Lucht
Ontwikkeling van geavanceerde, netwerkgebaseerde loitering munitie.
Turkije
Kargu-2 Zwerm
Lucht
Gecoördineerde precisieaanvallen met zwermen van maximaal 20 loitering munitie.

Tabel 2: Belangrijke Internationale Autonome Wapenprogramma's (c. 2025). Deze tabel biedt een vergelijkend overzicht van belangrijke wereldwijde inspanningen in de ontwikkeling van geavanceerde autonome systemen, waarbij de competitieve aard van AWS-ontwikkeling en nationale aandachtsgebieden worden benadrukt.
De kerntechnologieën die autonomie mogelijk maken, onthullen een fundamentele spanning in het hart van de ontwikkeling van AWS. Terwijl het doel is om intelligente, adaptieve en veerkrachtige systemen te creëren, introduceert de aard van geavanceerde AI onvoorspelbaarheid. Machine learning-modellen, vooral die getraind via DRL, worden vaak beschreven als "broos".74 Hun gedrag is afgeleid van complexe interacties tussen hun algoritmen en een dynamische omgeving, waardoor het uiterst moeilijk is om hun acties in nieuwe, real-world instellingen die verschillen van hun trainingsdata te voorspellen of te garanderen.3 Dit creëert een directe conflict tussen militaire en juridische vereisten. Voor een wapen om legaal te zijn onder het Internationaal Humanitair Recht (IHL), moeten de effecten voorspelbaar en controleerbaar zijn.75 Voor datzelfde wapen om militair effectief te zijn tegen een intelligente, adaptieve tegenstander, moet het mogelijk onvoorspelbaar zijn om een tactisch voordeel te behouden.3 Deze "broosheid" van AI is niet slechts een technische bug die moet worden verholpen, maar een fundamentele eigenschap van huidige machine learning-paradigma's, die een diepe uitdaging vormen voor de premisse van wettelijke autonome oorlogvoering.

5.0 Het Menselijke Element: Controle, Beoordeling en Vertrouwen

Naarmate machines meer functies op het slagveld overnemen, wordt de rol van de menselijke operator niet geëlimineerd maar getransformeerd. De discussie over autonome wapens is fundamenteel een discussie over de juiste aard van de mens-machine relatie in de context van dodelijke kracht. Terwijl concepten zoals "human-in-the-loop" een nuttige taxonomie bieden, onthult praktische ervaring met sterk geautomatiseerde systemen aanzienlijke complexiteiten en cognitieve uitdagingen die de effectiviteit van menselijke toezicht in hoge-tempo, hoge-stakes omgevingen ter discussie stellen.

5.1 Het Spectrum van Menselijke Controle in de Praktijk

Case studies van bestaande, sterk geautomatiseerde militaire systemen bieden cruciale lessen over de uitdagingen van mens-machine teaming en het fenomeen van "automatiseringsbias"—de neiging van mensen om te veel te vertrouwen op en kritiekloos de output van een geautomatiseerd systeem te accepteren.

5.1.1 Case Study: Het Aegis Combat System

Het Aegis Combat System is een geavanceerd, geïntegreerd maritiem wapen systeem dat het hele luchtverdedigingsproces automatiseert van detectie tot kill.76 De krachtige AN/SPY-1 radar en geavanceerde computersystemen kunnen meer dan 100 doelen tegelijkertijd volgen en raketten begeleiden om ze te onderscheppen.78 Terwijl het systeem meerdere modi van werking heeft, is het ontworpen om te opereren met een hoge mate van automatisering om saturatie-aanvallen tegen te gaan.79
De tragische neergang van Iran Air Flight 655 door de Aegis-uitgeruste kruiser USS Vincennes in 1988 is een essentieel case study in de gevaren van mens-machine interactie onder stress.78 Het officiële onderzoek vond dat het Aegis-systeem correct functioneerde en het vliegtuig volgde als een civiele luchtvaartmaatschappij op een normale vluchtpad. Echter, de menselijke bemanning in het gevechtsinformatiecentrum, die opereerde onder immense psychologische druk in een vijandige omgeving, interpreteerde de gegevens van het systeem verkeerd. Ze rapporteerden aan de kapitein dat het vliegtuig daalde en versnelde alsof het op een aanvalspatroon was, ondanks dat het display van het systeem toonde dat het steeg.78 De bemanning vertrouwde hun vooraf bedachte scenario van een aanval meer dan de ruwe gegevens die door de machine werden gepresenteerd, wat leidde tot de verkeerde identificatie van de luchtvaartmaatschappij als een vijandelijke F-14 jager en het neerschieten ervan.80 Dit voorval illustreert scherp dat simpelweg een mens "in de lus" hebben geen veilige of correcte uitkomst garandeert, vooral niet wanneer cognitieve biases en een slecht ontworpen mens-machine interface leiden tot catastrofale beoordelingsfouten.

5.1.2 Case Study: Het Patriot Missile System

De MIM-104 Patriot is het premier lucht- en raketverdedigingsysteem van het Amerikaanse leger, dat in staat is om vliegtuigen, kruisraketten en ballistische raketten aan te vallen.81 Net als Aegis is het een "detectie-tot-kill" systeem, met een enkele radar die alle zoek-, volg- en engagementfuncties uitvoert.81 Vanwege de extreem korte engagementtijden, vooral tegen ballistische raketten, opereert het systeem met een hoge mate van automatisering. Een batterij lanceerders wordt beheerd door een bemanning van slechts drie soldaten in het Engagement Control Station (ECS), die toezicht houden op de werking van het systeem.82
Tijdens de invasie van Irak in 2003 was het Patriot-systeem betrokken bij twee fratricide-incidenten, waarbij een Britse Tornado en een Amerikaanse Marine F/A-18 Hornet werden neergeschoten.80 In deze gevallen misclassificeerden de algoritmen van het systeem de vriendelijke vliegtuigen als vijandelijke anti-radiatieraketten. De menselijke operators, die gedwongen waren om split-second beslissingen te nemen op basis van de aanbevelingen van het systeem, bevestigden de engagementen.80 Deze incidenten benadrukken de immense moeilijkheid van het uitoefenen van effectieve supervisie (het HOTL-model) in een snel bewegende, complexe strijdomgeving waar de "mist van oorlog" zowel mensen als machines kan leiden tot fatale fouten.
Deze gevallen onthullen een kritische paradox: hoe geavanceerder, complexer en betrouwbaarder een autonoom systeem wordt, hoe moeilijker het kan zijn voor een mens om betekenisvolle controle over het uit te oefenen. De snelheid die het systeem effectief maakt, kan de besluitvormingstijd zo samendrukken dat menselijke tussenkomst onpraktisch wordt.3 De ondoorzichtigheid van complexe AI-algoritmen—vaak aangeduid als "zwarte dozen"—betekent dat een menselijke toezichthouder misschien de aanbeveling van een systeem ziet, maar niet in staat is om de redenering erachter te begrijpen, waardoor het moeilijk wordt om deze uit te dagen.84 Ten slotte, naarmate een systeem zijn betrouwbaarheid in de loop van de tijd bewijst, ontwikkelen menselijke operators onvermijdelijk automatiseringsbias, worden ze complacent en minder geneigd om het oordeel van de machine in twijfel te trekken, zelfs wanneer hun eigen intuïtie of andere gegevensbronnen suggereren dat er iets mis is.48 Dit creëert een gevaarlijke feedbacklus waarbij het verhogen van de autonomie van een systeem om de prestaties te verbeteren paradoxaal genoeg de voorwaarden kan ondermijnen die nodig zijn voor effectieve menselijke toezicht.

5.2 De Zoektocht naar "Betekenisvolle Menselijke Controle" (MHC)

Als reactie op de uitdagingen die toenemende autonomie met zich meebrengt, is het concept van "Betekenisvolle Menselijke Controle" (MHC) de centrale focus geworden van internationale diplomatieke en maatschappelijke inspanningen om LAWS te reguleren.86 Het principe stelt dat mensen, niet machines, uiteindelijk de controle moeten behouden over, en dus moreel verantwoordelijk zijn voor, alle beslissingen om dodelijke kracht te gebruiken.86
Echter, MHC is een politiek en juridisch concept, geen technische specificatie, en het mist een universeel overeengekomen definitie.84 Deze ambiguïteit is de belangrijkste breuklijn in het internationale debat:
Voorstanders van een Verbod: Groepen zoals de Campaign to Stop Killer Robots en veel staten beweren dat MHC vereist dat een mens voldoende contextuele informatie heeft en de praktische mogelijkheid om een weloverwogen, geval-voor-geval beslissing te nemen voordat elke enkele toepassing van geweld plaatsvindt.89 Onder deze interpretatie zouden systemen die autonoom doelen kunnen selecteren en aanvallen zonder dergelijke specifieke, real-time menselijke autorisatie verboden zijn.
Belangrijke Militaire Mogendheden: Staten die actief AWS ontwikkelen, zoals de Verenigde Staten, vermijden de term MHC ten gunste van meer flexibele taal. Het Amerikaanse beleid roept bijvoorbeeld op tot "passende niveaus van menselijke beoordeling".6 Deze formulering staat een contextafhankelijke benadering toe waarbij de mate van directe menselijke controle kan variëren. Het impliceert dat in bepaalde sterk beperkte en voorspelbare scenario's—zoals de terminale verdediging van een schip tegen een binnenkomende zeeschuimraket—het "passend" kan zijn om directe controle aan de machine over te dragen, mits een mens de overkoepelende regels voor engagement heeft vastgesteld.
Deze fundamentele onenigheid over de vraag of menselijke controle direct en absoluut moet zijn voor elke engagement (MHC) of kan worden gezien als toezichthoudend en contextafhankelijk ("passende beoordeling") blijft de kernobstakel voor het bereiken van een internationale consensus over de regulering van LAWS.

6.0 Het Wereldwijde Dilemma: Ethische, Juridische en Strategische Gevolgen

De snelle vooruitgang van autonome wapentechnologie presenteert de internationale gemeenschap met een reeks diepgaande en onderling verbonden dilemma's. Deze uitdagingen strekken zich uit voorbij het slagveld en raken aan fundamentele principes van recht, ethiek en wereldwijde strategische stabiliteit. Het niet aanpakken ervan brengt niet alleen een toekomst van onvoorspelbare en geautomatiseerde conflicten met zich mee, maar ook de erosie van lang bestaande normen die het gebruik van geweld reguleren.

6.1 De Aansprakelijkheidskloof

Een van de meest urgente juridische en ethische problemen die door LAWS worden opgeworpen, is de "aansprakelijkheidskloof".91 Wanneer een volledig autonoom wapen onrechtmatig een burger doodt of beschermd eigendom vernietigt, is het onduidelijk wie juridisch verantwoordelijk kan worden gehouden voor de actie.
De Machine: Een autonoom systeem zelf kan niet aansprakelijk worden gesteld. Het is een machine, geen moreel agent, en mist de juridische status en het concept van mens rea (criminele opzet) die nodig zijn voor juridische schuld.93
De Operator/Commandant: Het strafrechtelijk verantwoordelijk houden van de menselijke commandant of operator is ook vol uitdagingen. Volgens de doctrine van command responsibility is een superieur alleen aansprakelijk als hij wist of had moeten weten dat een ondergeschikte (in dit geval de machine) een misdaad zou plegen en niet heeft voorkomen.93 Als de AWS op een onvoorspelbare manier handelt die niet te voorzien was voor de commandant op het moment van inzet—een belangrijke zorg met AI-systemen die leren—wordt het bijna onmogelijk om de noodzakelijke standaard van opzet of nalatigheid voor strafrechtelijke aansprakelijkheid vast te stellen.3
De Programmeur/Fabrikant: Aansprakelijkheid toewijzen aan de softwareontwikkelaars of fabrikanten van het wapen ondervindt aanzienlijke juridische hindernissen. In veel rechtsgebieden zijn militaire aannemers beschermd door doctrines van soevereine immuniteit. Bovendien zou het bewijzen dat een specifieke regel code of ontwerpkeuze de directe en foutieve oorzaak was van een onrechtmatige daad te midden van miljoenen regels code en complexe omgevingsinteracties een immense technische en juridische uitdaging zijn.93
Dit potentieel voor een "aansprakelijkheidsvacuüm" is een ernstige zorg. Het creëert een situatie waarin oorlogsmisdaden kunnen worden gepleegd zonder dat iemand—noch machine, soldaat, noch bedrijf—juridisch verantwoordelijk wordt gehouden, wat het hele kader van internationale rechtvaardigheid en afschrikking ondermijnt.92

6.2 Naleving van het Internationaal Humanitair Recht (IHL)

Het is een algemeen aanvaard principe dat alle nieuwe wapens, inclusief AWS, in staat moeten zijn om te worden gebruikt in overeenstemming met het Internationaal Humanitair Recht (IHL), ook wel bekend als de wetten van gewapende conflicten.75 Echter, de kernprincipes van IHL zijn gebaseerd op genuanceerde, contextafhankelijke menselijke beoordeling, wat een fundamentele uitdaging vormt voor een algoritmisch systeem.
Onderscheid: Dit principe vereist dat strijders onderscheid maken tussen militaire doelwitten en burgers of burgerobjecten, en aanvallen alleen op de eersten richten.95 Een AWS zou dit onderscheid moeten maken op basis van sensordata en vooraf geprogrammeerde doelprofielen. Het is zeer twijfelachtig of een algoritme betrouwbaar kan onderscheiden tussen een strijdende en een burger die er vergelijkbaar uitziet (bijv. een boer met een gereedschap versus een soldaat met een geweer), of de overgave van een vijandelijke soldaat kan herkennen (hors de combat), een daad die vaak wordt gecommuniceerd door middel van subtiele gebaren en context.44
Proportionaliteit: Deze regel verbiedt aanvallen waarbij het verwachte incidentele verlies van burgerlevens of schade aan burgerlijke eigendommen buitensporig zou zijn in verhouding tot het concrete en directe militaire voordeel dat wordt verwacht.95 Dit is geen eenvoudige wiskundige berekening; het is een subjectieve, waarde-gedreven beoordeling die vereist dat niet-vergelijkbare factoren worden gewogen. Het is onduidelijk hoe een machine zou kunnen worden geprogrammeerd om zo'n diep menselijke ethische beoordeling te maken in de hitte van de strijd.50
Voorzorg: Dit principe vereist dat strijders alle haalbare voorzorgsmaatregelen nemen om burgerlijk letsel te vermijden of te minimaliseren. Dit omvat het verifiëren van doelen, het kiezen van geschikte wapens, en het annuleren van een aanval als blijkt dat het doel geen militair doelwit is of de aanval buitensporig zou zijn.95 Dit vereist een hoog niveau van real-time situationeel bewustzijn en het vermogen om een laatste, ethisch geïnformeerde beoordelingsbeslissing te nemen, capaciteiten die kenmerkend zijn voor menselijke cognitie, niet voor machineverwerking.50

6.3 Het Geopolitieke Landschap: Een Gebroken Consensus

De internationale gemeenschap is diep verdeeld over hoe de uitdagingen van LAWS aan te pakken. Diplomatieke inspanningen, voornamelijk gecentreerd op de Verenigde Naties Conventie over Bepaalde Conventionele Wapens (CCW) Groep van Overheidsdeskundigen (GGE) in Genève, zijn gekenmerkt door een impasse, grotendeels vanwege de consensus-gebaseerde aard van het forum dat een enkele staat in staat stelt om vooruitgang te blokkeren.96 De belangrijkste posities van belangrijke actoren zijn als volgt:

Land/Blok
Standpunt over Juridisch Bindend Instrument
Belangrijk Concept voor Menselijk Toezicht
Belangrijk Beleidsdocument/Verklaring
Verenigde Staten
Verzet zich tegen een preventief verbod; stelt dat bestaand IHL voldoende is.
"Passende niveaus van menselijke beoordeling"
DoD Richtlijn 3000.09 6
China
Steunt een verbod op gebruik maar niet op ontwikkeling; promoot een zeer smalle definitie.
"Mensencontrole over het hele proces"
GGE Positiepapieren 12
Rusland
Verzet zich tegen elk nieuw juridisch bindend instrument.
"Soevereine discretie van Staten"
Verklaringen op UNGA/GGE 98
Verenigd Koninkrijk
Steunt regulering om menselijke controle te waarborgen; steunt geen totaal verbod.
"Context-geschikte menselijke betrokkenheid"
Defence AI Strategy 100
Europese Unie
Steunt regulering om "betekenisvolle menselijke controle" en aansprakelijkheid te waarborgen.
"Betekenisvolle menselijke controle"
EEAS Verklaringen / EP Resoluties 102

Tabel 3: Vergelijkende Houdingen van Belangrijke Mogendheden over LAWS Regulatie. Deze tabel samenvat de uiteenlopende posities van belangrijke wereldactoren, waarbij de kernverschillen worden geïllustreerd die de internationale reguleringsinspanningen hebben stilgelegd.
In tegenstelling tot de posities van deze grote militaire machten, pleit een grote coalitie van staten, met name uit de Non-Gezinde Beweging en Latijns-Amerika, evenals internationale organisaties zoals het Internationale Rode Kruis (ICRC) en maatschappelijke groepen zoals de Campaign to Stop Killer Robots, voor de dringende onderhandeling van een nieuw juridisch bindend internationaal verdrag. Ze stellen doorgaans een tweelaagse aanpak voor: het verbieden van systemen die inherent onvoorspelbaar zijn of die mensen rechtstreeks als doelwit hebben, en het strikt reguleren van alle andere AWS om ervoor te zorgen dat betekenisvolle menselijke controle altijd wordt gehandhaafd.97

6.4 Strategische Stabiliteit en de Proliferatiedreiging

Naast de juridische en ethische dimensies, vormt de ontwikkeling van AWS ernstige risico's voor de wereldwijde strategische stabiliteit.
Risico van een Nieuwe AI-Wapenwedloop: De competitieve achtervolging van autonome capaciteiten door grote machten zoals de VS, China en Rusland voedt een nieuwe AI-wapenwedloop.74 Deze dynamiek creëert intense druk om deze systemen snel te ontwikkelen en in te zetten om niet in een strategisch nadeel te komen, wat mogelijk de drempel voor conflicten verlaagd en snelheid boven veiligheid en ethische overwegingen prioriteert.107 De introductie van AI-gestuurde oorlogvoering, die opereert op machinesnelheden, kan ook leiden tot snelle, ongecontroleerde escalatie in een crisis—de zogenaamde "flash wars"—nu gebeurtenissen zich te snel ontvouwen voor menselijke diplomaten of commandanten om te de-escaleren.3
Het Gevaar van Proliferatie: Misschien is de meest insidieuze langetermijndreiging proliferatie. In tegenstelling tot nucleaire wapens, die enorme industriële infrastructuur en zeldzame materialen vereisen, zijn de kerntechnologieën voor veel vormen van AWS dual-use, relatief goedkoop en wijd beschikbaar. Geavanceerde AI-software is vaak open-source, en commerciële drones kunnen voor duizenden dollars worden gekocht, niet miljarden.109 Dit verlaagt dramatisch de toetredingsdrempel, waardoor het haalbaar wordt voor kleinere staten, en meer verontrustend, niet-statelijke actoren zoals terroristische groepen en transnationale criminele organisaties, om autonome systemen te verwerven en te wapenen. Dit zou het slagveld op gevaarlijke manieren kunnen nivelleren, nieuwe asymmetrische bedreigingen creëren en de conventionele militaire superioriteit ondermijnen die lange tijd een hoeksteen van internationale stabiliteit is geweest.3

7.0 Conclusie: Navigeren naar de Toekomst van Oorlogvoering

De ontwikkeling van Autonome Wapen Systemen is geen verre sciencefiction mogelijkheid; het is een hedendaagse realiteit die actief het technologische en strategische landschap van moderne conflicten hervormt. Van het wijdverspreide gebruik van loitering munitions en FPV drones in Oekraïne tot de geavanceerde ontwikkeling van samenwerkende gevechtsvliegtuigen en extra-grote onbemande onderzeese vaartuigen door grote machten, versnelt de delegatie van slagveldfuncties naar machines in alle domeinen.
De technologische vectoren die deze revolutie aandrijven zijn duidelijk: de toenemende verfijning van AI voor perceptie en besluitvorming; de operationele noodzaak om te functioneren in omgevingen zonder communicatie; en de strategische aantrekkingskracht van het inzetten van attritable, zwermsystemen om massa te creëren en tegenstanders te overweldigen. Deze technologieën beloven militaire operaties sneller, preciezer en mogelijk minder kostbaar te maken in termen van menselijke slachtoffers aan de zijde van de gebruiker.
Echter, deze bijlage heeft gedetailleerd hoe deze potentiële voordelen worden overschaduwd door diepgaande en onopgeloste uitdagingen. De kerntechnologieën van machine learning, hoewel krachtig, zijn ook inherent onvoorspelbaar, wat een fundamentele spanning creëert tussen militaire effectiviteit en de juridische vereiste voor voorspelbare en controleerbare kracht. De operationele realiteiten van mens-machine teaming, zoals blijkt uit decennia van ervaring met sterk geautomatiseerde systemen zoals Aegis en Patriot, tonen aan dat menselijke toezicht feilbaar is en onderhevig aan cognitieve biases die kunnen leiden tot catastrofale mislukkingen.
Uiteindelijk zijn de meest kritische uitdagingen die door AWS worden opgeworpen niet technisch, maar diep geworteld in ethiek, recht en strategie. De internationale gemeenschap blijft verdeeld, niet in staat om zelfs maar een gemeenschappelijke definitie voor deze systemen overeen te komen, laat staan een kader voor hun regulering. De onopgeloste vragen over hoe betekenisvolle menselijke controle over het gebruik van dodelijke kracht te waarborgen, hoe de juridische aansprakelijkheidskloof te dichten wanneer autonome systemen fouten maken, en hoe strategische stabiliteit te behouden in een tijdperk van AI-gestuurde wapenwedlopen en wijdverspreide proliferatie zijn van het grootste belang. Navigeren naar deze toekomst vereist urgente en substantiële internationale dialoog. Het niet aanpakken van deze fundamentele dilemma's brengt het risico met zich mee van een toekomst van geautomatiseerd conflict die gevaarlijk onvoorspelbaar, ethisch beladen en potentieel catastrofaal voor de wereldwijde veiligheid is.
Werken geciteerd
Educating about Autonomous Weapons - Future of Life Institute, geraadpleegd op 23 juli 2025, <https://futureoflife.org/project/autonomous-weapons-systems/>
Pros and Cons of Autonomous Weapons Systems - Army University Press, geraadpleegd op 23 juli 2025, <https://www.armyupress.army.mil/Journals/Military-Review/English-Edition-Archives/May-June-2017/Pros-and-Cons-of-Autonomous-Weapons-Systems/>
Autonomous Weapons Systems: Homepage, geraadpleegd op 23 juli 2025, <https://autonomousweapons.org/>
What are Autonomous Weapon Systems? - Belfer Center, geraadpleegd op 23 juli 2025, <https://www.belfercenter.org/what-are-autonomous-weapon-systems>
Artificial Intelligence in the Military: How AI Is Reshaping the Future of War - TS2 Space, geraadpleegd op 23 juli 2025, <https://ts2.tech/en/artificial-intelligence-in-the-military-how-ai-is-reshaping-the-future-of-war/>
Defense Primer: U.S. Policy on Lethal Autonomous Weapon ..., geraadpleegd op 23 juli 2025, <https://www.congress.gov/crs-product/IF11150>
Human-Machine Interaction and Human Agency in the Military Domain - Centre for International Governance Innovation (CIGI), geraadpleegd op 23 juli 2025, <https://www.cigionline.org/documents/3094/PB_no.193.pdf>
Lethal autonomous weapon - Wikipedia, geraadpleegd op 23 juli 2025, <https://en.wikipedia.org/wiki/Lethal_autonomous_weapon>
Lethal autonomous weapons (LAWs) | EBSCO Research Starters, geraadpleegd op 23 juli 2025, <https://www.ebsco.com/research-starters/social-sciences-and-humanities/lethal-autonomous-weapons-laws>
Lethal Autonomous Weapon Systems (LAWS) – UNODA, geraadpleegd op 23 juli 2025, <https://disarmament.unoda.org/the-convention-on-certain-conventional-weapons/background-on-laws-in-the-ccw/>
<www.congress.gov>, geraadpleegd op 23 juli 2025, <https://www.congress.gov/crs-product/IF11150#:~:text=Lethal%20autonomous%20weapon%20systems%20(LAWS,human%20control%20of%20the%20system>.
Weaponised Artificial Intelligence and Chinese Practices of Human ..., geraadpleegd op 23 juli 2025, <https://academic.oup.com/cjip/article/16/1/106/6976053>
Legal aspects of the development of weapon systems with artificial intelligence in 2025, geraadpleegd op 23 juli 2025, <https://www.arws.cz/news-at-arrows/legal-aspects-of-the-development-of-weapon-systems-with-artificial-intelligence-in-2025>
Offensive Autonomous Weapons: Should We Be Worried? - Michigan Journal of International Law, geraadpleegd op 23 juli 2025, <https://www.mjilonline.org/offensive-autonomous-weapons-should-we-be-worried/>
Human-in-the-loop - Wikipedia, geraadpleegd op 23 juli 2025, <https://en.wikipedia.org/wiki/Human-in-the-loop>
Loitering Munitions and the Future of Modern Artillery - IDGA.org, geraadpleegd op 23 juli 2025, <https://www.idga.org/land/articles/loitering-munitions-and-the-future-of-modern-artillery>
Loitering munition - Wikipedia, geraadpleegd op 23 juli 2025, <https://en.wikipedia.org/wiki/Loitering_munition>
KNDS's Mataris loitering munitions finding contracts from French ..., geraadpleegd op 23 juli 2025, <https://breakingdefense.com/2025/06/knds-mataris-loitering-munitions-finding-contracts-from-french-government/>
MATARIS: The First French Range of Loitering Munitions - ASDNews, geraadpleegd op 23 juli 2025, <https://www.asdnews.com/news/defense/2025/06/17/mataris-first-french-range-loitering-munitions>
U.S. Air Force Collaborative Combat Aircraft (CCA) | Congress.gov ..., geraadpleegd op 23 juli 2025, <https://www.congress.gov/crs-product/IF12740>
Tracking 2024 Updates to the Air Force's Collaborative Combat Aircraft - IDGA.org, geraadpleegd op 23 juli 2025, <https://www.idga.org/aviation/articles/2024-updates-to-air-force-collaborative-combat-aircraft-cca>
The US Air Force's New Drones Are a Game Changer - The National Interest, geraadpleegd op 23 juli 2025, <https://nationalinterest.org/blog/buzz/the-us-air-forces-new-drones-are-a-game-changer>
MQ-28 Ghost Bat - Boeing Australia, geraadpleegd op 23 juli 2025, <https://www.boeing.com.au/products-services/defence-space-security/ghost-bat>
MQ-28 - Boeing, geraadpleegd op 23 juli 2025, <https://www.boeing.com/defense/mq28>
MQ-28 Ghost Bats Controlled From E-7 Wedgetail In Loyal Wingman Test - The War Zone, geraadpleegd op 23 juli 2025, <https://www.twz.com/air/mq-28-ghost-bats-controlled-from-e-7-wedgetail-in-loyal-wingman-test>
MQ-28A Ghost Bat Milestone - YouTube, geraadpleegd op 23 juli 2025, <https://www.youtube.com/watch?v=2C_a-plgzFo>
Tactical UAVs - Kratos Defense, geraadpleegd op 23 juli 2025, <https://www.kratosdefense.com/systems-and-platforms/unmanned-systems/aerial/tactical-uavs>
Kratos XQ-58 Valkyrie - Wikipedia, geraadpleegd op 23 juli 2025, <https://en.wikipedia.org/wiki/Kratos_XQ-58_Valkyrie>
XQ-58 Valkyrie Heading To European Market With Kratos-Airbus Team-Up - The War Zone, geraadpleegd op 23 juli 2025, <https://www.twz.com/air/xq-58-valkyrie-heading-to-european-market-with-kratos-airbus-team-up>
The Army's Robotic Combat Vehicle (RCV) Program - Congress.gov, geraadpleegd op 23 juli 2025, <https://www.congress.gov/crs_external_products/IF/PDF/IF11876/IF11876.14.pdf>
Is the Army's Robotic Combat Vehicle Program Dead? So Much for Robot Tanks, geraadpleegd op 23 juli 2025, <https://www.military.com/off-duty/autos/armys-robotic-combat-vehicle-program-dead-so-much-robot-tanks.html>
The Army's Robotic Combat Vehicle (RCV) Program - Congress.gov, geraadpleegd op 23 juli 2025, <https://www.congress.gov/crs-product/IF11876>
RACER: Robotic Autonomy in Complex Environments with Resiliency - DARPA, geraadpleegd op 23 juli 2025, <https://www.darpa.mil/research/programs/robotic-autonomy-in-complex-environments-with-resiliency>
RACER Speeds Into a Second Phase With Robotic Fleet Expansion ..., geraadpleegd op 23 juli 2025, <https://www.darpa.mil/news/2024/racer-second-phase>
GXV-T: Ground X-Vehicle Technologies - DARPA, geraadpleegd op 23 juli 2025, <https://www.darpa.mil/research/programs/ground-x-vehicle-technologies>
Phalanx CIWS - Wikipedia, geraadpleegd op 23 juli 2025, <https://en.wikipedia.org/wiki/Phalanx_CIWS>
MK 15 - Phalanx Close-In Weapon System (CIWS) - Navy.mil, geraadpleegd op 23 juli 2025, <https://www.navy.mil/resources/fact-files/display-factfiles/article/2167831/mk-15-phalanx-close-in-weapon-system-ciws/>
USA 20 mm Phalanx Close-in Weapon System (CIWS) - NavWeaps, geraadpleegd op 23 juli 2025, <http://www.navweaps.com/Weapons/WNUS_Phalanx.php>
Despite delays, Boeing charts new course with delivery of Orca ..., geraadpleegd op 23 juli 2025, <https://www.naval-technology.com/news/despite-delays-boeing-charts-new-course-with-delivery-of-orca-xluuv-to-us/>
JUST IN: Navy's First 'Extra' Large Unmanned Sub to Go Underwater 'Very Soon', geraadpleegd op 23 juli 2025, <https://www.nationaldefensemagazine.org/articles/2023/1/30/just-in-navys-first-extra-large-unmanned-sub-to-go-underwater-very-soon>
Manta Ray | Northrop Grumman, geraadpleegd op 23 juli 2025, <https://www.northropgrumman.com/what-we-do/mission-solutions/sensors/manta-ray>
Unveiling the Future: Iron Dome's Autonomous Revolution for ..., geraadpleegd op 23 juli 2025, <https://certificates.acn.edu.au/iron-dome-autonomous>
Iron Dome - Wikipedia, geraadpleegd op 23 juli 2025, <https://en.wikipedia.org/wiki/Iron_Dome>
A Defense for Guardian Robots: Are Defensive Autonomous Weapons Systems Justifiable?, geraadpleegd op 23 juli 2025, <https://journals.law.harvard.edu/ilj/2024/02/a-defense-for-guardian-robots-are-defensive-autonomous-weapons-systems-justifiable/>
System, geraadpleegd op 23 juli 2025, <https://uploads.mwp.mprod.getusinfo.com/uploads/sites/25/2021/07/CRAM-Brief-with-Notes-For-Posting.pdf>
Counter Rockets, Artillery and Mortars (C-RAM) - NATO Integrated Air & Missile Defence Centre of Excellence - iamd-coe.org, geraadpleegd op 23 juli 2025, <https://iamd-coe.org/focus-areas/counter-rockets-artillery-and-mortars-cram/>
Countries upgrading Counter Rocket, Artillery, and Mortar systems to counter threats like drones, helicopters, fixed-wing aircraft and cruise missiles, geraadpleegd op 23 juli 2025, <https://idstch.com/geopolitics/countries-upgrading-counter-rocket-artillery-and-mortar-systems-to-counter-threats-like-drones-helicopters-fixed-wing-aircraft-and-cruise-missiles/>
The Integration Of AI-Empowered Autonomous Weapon Systems In European Defence, geraadpleegd op 23 juli 2025, <https://tdhj.org/blog/post/ai-autonomous-weapons-europe/>
The Algorithmic Battlefield: How AI is Redefining Military Might | by Ajay Verma - Medium, geraadpleegd op 23 juli 2025, <https://medium.com/@ajayverma23/the-algorithmic-battlefield-how-ai-is-redefining-military-might-5d3fb3e9c590>
Lethal Autonomous Weapons Systems & International Law: Growing Momentum Towards a New International Treaty | ASIL, geraadpleegd op 23 juli 2025, <https://www.asil.org/insights/volume/29/issue/1>
(PDF) DEEP REINFORCEMENT LEARNING IN UNMANNED ..., geraadpleegd op 23 juli 2025, <https://www.researchgate.net/publication/387868468_DEEP_REINFORCEMENT_LEARNING_IN_UNMANNED_COMBAT_VEHICLES>
Modular Reinforcement Learning for Autonomous UAV Flight Control - MDPI, geraadpleegd op 23 juli 2025, <https://www.mdpi.com/2504-446X/7/7/418>
The Army looks to pave way for autonomous vehicles with new AI research - FedScoop, geraadpleegd op 23 juli 2025, <https://fedscoop.com/ai-research-army-ground-vehicles-reinforcement-learning/>
Military LiDAR Solutions for Defense Applications, geraadpleegd op 23 juli 2025, <https://www.defenseadvancement.com/suppliers/military-lidar/>
Autonomous Systems: The Essential Guide to Using LiDAR, geraadpleegd op 23 juli 2025, <https://www.computer.org/publications/tech-news/trends/lidar-in-autonomous-systems/>
Facilitating autonomous and semi-autonomous defense operations ..., geraadpleegd op 23 juli 2025, <https://militaryembedded.com/unmanned/sensors/facilitating-autonomous-and-semi-autonomous-defense-operations>
Innovation Crossover Preliminary Research Report DoD Technologies – Sensor-Data Fusion - NavSea, geraadpleegd op 23 juli 2025, <https://www.navsea.navy.mil/Portals/103/Documents/NSWC_Crane/Innovation%20Crossover%202016/DoD%20Technologies%20-%20Sensor%20-%20Data%20Fusion%20Final.pdf?ver=2016-10-07-111745-577>
CJADC2 interoperability: AI-/ML-based sensor fusion at the edge, geraadpleegd op 23 juli 2025, <https://militaryembedded.com/ai/machine-learning/cjadc2-interoperability-ai-ml-based-sensor-fusion-at-the-edge>
Navigating GPS-Denied Environments: Solutions and Challenges, geraadpleegd op 23 juli 2025, <https://www.gnssjamming.com/post/gps-denied-environments>
OMNInav: A Breakthrough in GPS-Denied Navigation for UAS - OKSI, geraadpleegd op 23 juli 2025, <https://oksi.ai/omninav-gps-denied-navigation/>
GNSS

---
*Vertaald door AI. Controleer de originele Engelse versie bij twijfel.*