# Bijlage L: Het Pleidooi voor Tool AI — Een Gegronde Perspectief op Kunstmatige Intelligentie

Inleiding: Navigeren door de Kloof Tussen Hype en Realiteit

De publieke discussie rondom kunstmatige intelligentie (AI) is vaak een studie in extremen. Aan de ene kant staat een verhaal van aanstaande, transformerende verandering, bevolkt door concepten als Kunstmatige Algemene Intelligentie (AGI), de "Singularity" en existentiële risico's (x-risico). Dit perspectief, gevoed door speculatieve filosofie en media-amplificatie, portretteert AI vaak als een dreigende kunstmatige levensvorm, een opvolgende intelligentie die de mensheid obsoleet of uitgestorven zou kunnen maken. Aan de andere kant staat een meer pragmatisch, op wetenschap gebaseerd perspectief, dat is geworteld in de realiteiten van engineering, cognitieve wetenschap en economische toepassing. Dit is het perspectief van "Tool AI."
Het Tool AI-kader ontkent de kracht of het potentieel van kunstmatige intelligentie niet. In plaats daarvan herformuleert het het. Vanuit dit standpunt is AI geen embryonale bewustzijn, maar de nieuwste en meest geavanceerde categorie van gereedschap die door de mensheid is ontwikkeld. Het doel is niet om menselijke geesten te repliceren, maar om menselijke capaciteiten te vergroten, specifieke, goed gedefinieerde problemen op te lossen en te dienen als een krachtige motor voor industriële en wetenschappelijke vooruitgang. Deze bijlage biedt een overzicht van de belangrijkste voorstanders van dit gegronde perspectief, die verenigd zijn in hun scepsis over de hype rondom AGI en de bijbehorende existentiële angsten.
De vier hier geprofileerde figuren—Yann LeCun, Andrew Ng, Melanie Mitchell en Rodney Brooks—zijn geen Luddieten of technologie-ontkenners. Ze behoren feitelijk tot de wereldwijde pioniers en beoefenaars op het gebied van machine learning, robotica en cognitieve wetenschap. Hun collectieve scepsis is geen afwijzing van de belofte van AI, maar een rigoureuze kritiek op de richting van de hype en een oproep tot een nuchtere, wetenschappelijk onderbouwde benadering van de ontwikkeling en inzet ervan. Ze stellen dat de meest significante uitdagingen en kansen met AI niet te vinden zijn in sciencefiction-scenario's, maar in de onmiddellijke, tastbare problemen van het bouwen van systemen die betrouwbaar, begrijpelijk en werkelijk nuttig zijn. Hun argumenten, hieronder in detail onderzocht, zijn essentieel voor elke "denkende mens" die de kloof tussen de hype en de realiteit van kunstmatige intelligentie probeert te overbruggen, een keuze die centraal staat in de thesis van dit boek.1

Sectie 1: Yann LeCun: De Ingenieurszaak voor Wereldmodellen

Als laureaat van de Turing Award en Chief AI Scientist bij Meta, neemt Yann LeCun een centrale positie in het AI-landschap in. Zijn scepsis is niet die van een buitenstaander, maar van een hoofdarchitect die de heersende blauwdrukken voor AGI fundamenteel gebrekkig vindt. LeCun's kritiek is diep technisch, gericht op de beperkingen van de modellen die de huidige AI-boom hebben aangedreven, en hij biedt een gedetailleerde, alternatieve visie voor het bereiken van menselijke intelligentie.

1.1 De Onvoldoendeheid van Taal-Alleen Modellen

LeCun's kernargument is dat Grote Taalmodellen (LLM's), ondanks hun linguïstische bekwaamheid, zijn gebouwd op een fundament van zand. Hij stelt dat systemen die uitsluitend op tekst zijn getraind nooit ware intelligentie kunnen bereiken, omdat het probleem niet bij de AI ligt, maar bij de "beperkte aard van taal" zelf.2 Taal, zo stellen hij en co-auteur Jacob Browning, is een inherent "laag-bandbreedte" medium voor het overbrengen van informatie.2 Het is vol ambiguïteiten—homoniemen, voornaamwoorden en contextuele afhankelijkheden—die mensen moeiteloos oplossen met behulp van een enorme, gedeelde en cruciaal niet-linguïstische kennis van hoe de wereld werkt.2
Huidige LLM's zijn getraind om "de lege plekken in te vullen" of "één woord na het andere te produceren" op basis van statistische patronen in hun enorme tekstuele trainingsdata.3 Deze methodologie, hoewel krachtig voor het genereren van plausibele taal, leidt tot wat LeCun een "oppervlakkig begrip" noemt.2 Een LLM kan leren om een concept linguïstisch uit te leggen, maar kan het niet noodzakelijkerwijs praktisch gebruiken; bijvoorbeeld, het kan de stappen van lange delingen beschrijven zonder de berekening daadwerkelijk te kunnen uitvoeren, of beledigende woorden opsommen en deze vervolgens ongevoelig gebruiken.2 Deze disconnectie is de hoofdoorzaak van hun onbetrouwbaarheid. Ze zijn vatbaar voor "hallucinaties"—nauwkeuriger gezegd confabulaties—omdat ze geen echte redeneer- of planningscapaciteiten bezitten; ze genereren simpelweg statistisch waarschijnlijke reeksen tokens.3
LeCun benadrukt dat dit geen probleem is dat kan worden opgelost door simpelweg de huidige modellen op te schalen. Hij stelt dat autoregressieve taalmodellen niet zullen opschalen naar menselijke intelligentie en dat er een "nieuw paradigma" vereist is.4 Om de informatieve armoede van tekst te illustreren, contrasteert hij de verwerkingssnelheid van de menselijke hersenen voor taal (ongeveer 12 bytes per seconde) met de bandbreedte van sensorische input van observatie en interactie (ongeveer 20 megabytes per seconde).3 Dit enorme verschil suggereert dat ware intelligentie is gebouwd op een veel rijkere, hogere-bandbreedte datastroom dan taal alleen kan bieden.

1.2 Een Pad naar Autonome Machine-intelligentie

Als reactie op de beperkingen van LLM's heeft LeCun een uitgebreide alternatieve visie gearticuleerd in zijn position paper uit 2022, "Een Pad naar Autonome Machine-intelligentie".5 Het document behandelt de centrale vraag: "Hoe kunnen machines net zo efficiënt leren als mensen en dieren?".5 Hij merkt op dat een adolescent in ongeveer 20 uur oefenen kan leren autorijden, een prestatie van leerefficiëntie die vele malen groter is dan die van huidige machine learning-systemen, die een immense hoeveelheid pogingen vereisen om zelfs zeldzame situaties te dekken.6
De sleutel tot deze efficiëntie, hypotheseert LeCun, is het aangeboren vermogen van mensen en dieren om "wereldmodellen" te leren—interne, voorspellende modellen van hoe de wereld werkt.5 Deze modellen stellen een agent in staat om concepten zoals objectpermanentie, zwaartekracht en de basiswetten van de natuurkunde te begrijpen door observatie, lang voordat ze door taal worden geleerd.6 Om machines met deze capaciteit te bouwen, stelt LeCun een modulaire, volledig differentieerbare cognitieve architectuur voor.6
Een centraal onderdeel van deze architectuur is de Joint Embedding Predictive Architecture (JEPA).4 In tegenstelling tot generatieve modellen die proberen elke pixel in het volgende frame van een video te voorspellen—een ongelooflijk complexe en vaak verspilde taak—leert JEPA abstracte representaties van de wereld te creëren en maakt vervolgens voorspellingen binnen die abstracte representatieruimte.4 Door dit te doen, kan het model irrelevante details negeren (zoals het ritselen van bladeren aan een boom) en zich concentreren op het voorspellen van de essentiële, hoog-niveau gevolgen van acties, wat de basis vormt voor effectieve redenering en planning.7
Dit architecturale voorstel wordt vergezeld door een reeks radicale aanbevelingen voor het veld. LeCun pleit voor het verlaten van generatieve modellen ten gunste van joint-embedding architecturen zoals JEPA, het verlaten van probabilistische modellen voor meer flexibele op energie gebaseerde modellen, en, het meest controversieel, het verlaten van reinforcement learning (RL) als primaire trainingsmethode.10 Hij stelt dat RL extreem inefficiënt is en alleen als secundair hulpmiddel moet worden gebruikt om het wereldmodel of de intrinsieke kostenfunctie van de agent te verfijnen wanneer zijn plannen niet overeenkomen met de realiteit.10

1.3 Herformuleren van "AGI" en het Afstemprobleem

LeCun's publieke uitspraken over AGI en AI-veiligheid worden vaak als tegenstrijdig of afwijzend gezien, maar ze weerspiegelen een diepgeworteld onenigheid met de terminologie en framing die door de "AI doomer" gemeenschap worden gebruikt.11 Hij is beroemd om te stellen dat "er zoiets als AGI niet bestaat" terwijl hij tegelijkertijd erkent dat machines "uiteindelijk de menselijke intelligentie in alle domeinen zullen overtreffen".11 Dit is geen logische inconsistentie, maar een terminologische en filosofische. Hij verwerpt de term "AGI" omdat hij gelooft dat deze een gebrekkige, antropomorfe visie op een enkele, bewuste, monolithische entiteit bevordert. Hij vindt de term slecht gedefinieerd en zelfs "krankzinnig," en geeft de voorkeur aan meer precieze beschrijvingen zoals "menselijke-niveau AI".12
Ondanks zijn afwijzing van het AGI-narratief, engageert LeCun zich actief met de onderliggende veiligheidszorgen, waarbij hij de kwestie kadert als: "Hoe het afstemprobleem op te lossen?".11 Zoals gedetailleerd in Bijlage B, betreft dit probleem de immense technische moeilijkheid om menselijke waarden aan een machine te specificeren (Buitenste Afstemming) en ervoor te zorgen dat de machine die doelen robuust aanneemt (Binnenste Afstemming). Zijn voorgestelde oplossing is echter niet gebaseerd op formele verificatie of wiskundige bewijzen van correctheid, die hij als onpraktisch beschouwt. In plaats daarvan is zijn benadering een engineeringbenadering. De architectuur die hij voorstelt, is ontworpen om "veilig bij ontwerp" te zijn.11 Het wordt gedreven door een reeks intrinsieke doelstellingen die zijn gecodeerd in een "kosten" module, die het niveau van ongemak voor een agent berekent. Het hele planningsproces van de agent is gewijd aan het vinden van reeksen van acties die deze kosten minimaliseren. Door deze doelstellingsfunctie op de juiste manier te ontwerpen, stelt LeCun, kunnen we AI-systemen bouwen die inherent stuurbaar, controleerbaar en niet-confronterend zijn.
Critici beweren dat deze benadering naïef is en een "massale mislukking in verbeelding" weerspiegelt met betrekking tot complexere risicomodellen.11 Zijn vergelijking van het afstemmen van AI met het afstemmen van mensen en regeringen—door middel van wetten en sociale normen—wordt als bijzonder zwak gezien, gezien de frequente en flagrant falen van afstemming in menselijke samenlevingen.11 Dit benadrukt een potentieel blinde vlek in zijn kader, dat zich richt op engineeringcontrole terwijl het mogelijk opkomende, strategische risico's onderschat die buiten de vooraf gedefinieerde kostenfunctie vallen.

1.4 De Open-Source Imperatief

Een hoeksteen van LeCun's visie voor een veilige en voordelige AI-toekomst is zijn onwrikbare pleidooi voor open-source ontwikkeling. Hij stelt dat de fundamentele platforms waarop toekomstige AI-assistenten zullen worden gebouwd "open source en breed beschikbaar" moeten zijn.13 Zijn redenatie is zowel democratisch als praktisch: geen enkel bedrijf, vooral niet een dat is gevestigd aan de Amerikaanse Westkust of in China, kan een fundamenteel model bouwen dat adequaat de volledige spectrum van de wereldtalen, culturen en waardensystemen begrijpt en weerspiegelt.3
Deze houding is ook, ongetwijfeld, een strategische voor Meta, die het bedrijf positioneert als een kampioen van openheid in een veld dat steeds meer wordt gedomineerd door gesloten, propriëtaire modellen van concurrenten zoals Google en OpenAI. Sommige waarnemers hebben dit gepresenteerd als een zakelijke tactiek, waardoor Meta "alle verwarrende AI-veiligheidshumbug" kan vermijden en de ontwikkeling kan versnellen.12 Echter, LeCun's verklaarde rationale is consistent gericht op de overtuiging dat een gedecentraliseerde, collaboratieve aanpak de enige manier is om AI te creëren die de hele mensheid dient.
Dit perspectief onthult een andere opvatting van AI-veiligheid zelf. In plaats van een technisch probleem dat eenmaal door een enkel team van onderzoekers in een lab moet worden opgelost, wordt veiligheid een doorlopend, gedistribueerd proces dat wordt beheerd door een wereldwijde gemeenschap. Door diverse groepen in staat te stellen om open modellen te inspecteren, te bekritiseren en te verfijnen, wordt het risico verminderd dat een enkele, krachtige en niet-afgestemde AI een smalle set waarden op de wereld oplegt. Deze visie op veiligheid is inherent politiek en economisch, geworteld in democratisering en de preventie van geconcentreerde macht, een scherp contrast met de gecentraliseerde, technische afstemmingsaanpak die door velen in de x-risico gemeenschap wordt geprefereerd. LeCun's doel is om een toekomst te voorkomen waarin onze interactie met de digitale wereld wordt gemedieerd door systemen die worden gecontroleerd door een "handvol bedrijven".13

Sectie 2: Andrew Ng: Het Economische Pragmatisten Handboek

Andrew Ng, een medeoprichter van Google Brain en Coursera, en oprichter van Landing AI, brengt het verheven gesprek over kunstmatige intelligentie terug naar de aarde. Zijn perspectief is dat van een economische pragmatist, een opvoeder en een ondernemer die AI niet ziet als een filosofische puzzel, maar als een transformerende economische kracht. Voor Ng is de hele discussie over AGI en existentiële risico's een gevaarlijke en zelfzuchtige afleiding van het echte werk: AI toepassen om tastbare waarde te creëren en de onmiddellijke maatschappelijke gevolgen ervan aan te pakken.

2.1 "AI is de Nieuwe Elektriciteit"

De sleutel tot het begrijpen van Andrew Ng's hele wereldbeeld is zijn centrale analogie: "AI is de nieuwe elektriciteit".14 Voor het eerst gearticuleerd in keynotes en lezingen rond 2017, herformuleert deze metafoor AI van een mysterieuze, sentiente kracht naar een vertrouwd, utilitair concept.14 Ng stelt dat net zoals de elektrificatie van de samenleving 100 jaar geleden elke belangrijke industrie fundamenteel transformeerde—van productie en transport tot gezondheidszorg en landbouw—AI nu op het punt staat een even alomtegenwoordige en revolutionaire impact te hebben.16
De kern van de analogie is het idee dat AI een General-Purpose Technology (GPT) is. De kracht ligt niet in het potentieel voor bewustzijn, maar in de brede toepasbaarheid. Net als elektriciteit is AI een in wezen neutraal hulpmiddel; de waarde ervan wordt pas ontgrendeld door de toepassing ervan om talloze specifieke problemen in elke denkbare sector op te lossen.18 Deze framing verschuift onmiddellijk de focus van de AI-inspanning. Het doel is niet langer om een enkele, goddelijke "AGI" te bouwen, maar om miljoenen ontwikkelaars en ondernemers in staat te stellen duizenden waardevolle, AI-gestuurde toepassingen te bouwen die specifieke processen verbeteren en economische waarde creëren.15 Deze analogie is een strategisch hulpmiddel dat is ontworpen om AI te demystificeren voor bedrijfsleiders buiten de technologie-industrie. Het communiceert dat men geen elektriciteitscentrale (een fundamenteel model) hoeft te bouwen om van de technologie te profiteren; men hoeft alleen maar te leren hoe men de elektriciteit (de AI-tools) kan gebruiken om de bestaande machines effectiever te laten draaien. Dit democratiseert het concept van AI, waarbij de locus van innovatie verschuift van de weinige elite-laboratoria die modellen bouwen naar de vele domeinexperts die echte wereldproblemen oplossen.

2.2 Deconstructie van de AGI Hype

Ng is een van de meest directe en vocale critici van wat hij ziet als een gefabriceerde hypecyclus rond AGI. Hij stelt herhaaldelijk en botweg dat "AGI te veel is opgeblazen" en verwerpt beweringen dat een enkel nieuw AI-model massale werkloosheid zal veroorzaken of hele industrieën zal uitroeien als "gewoon niet waar" en "ridicuul".18
Cruciaal is dat hij stelt dat dit niet simpelweg een geval van overenthousiasme is, maar een opzettelijk, economisch gemotiveerd narratief. Hij beweert expliciet dat deze "hype-narratieven" strategisch worden gebruikt door sommige technologiebedrijven om "geld te werven of machtiger te lijken dan ze daadwerkelijk zijn".18 Dit biedt een insiderkritiek op een specifieke feedbacklus binnen het Silicon Valley-ecosysteem, waar grote verhalen van exponentiële verstoring worden beloond met enorme durfkapitaalinvesteringen en media-aandacht, wat een zelfversterkende cyclus van hype creëert. Een online commentator merkte dit patroon scherp op: "Het was 'AGI SNEL AGI SNEL AGI SNEL' gedurende jaren om hype op te bouwen en VC-fondsen te genereren, toen stuitten ze op een interne muur en realiseerden ze zich dat ze waarschijnlijk geen AGI zullen bereiken, nu VC-groepen en gemiddelde gebruikers de beperkingen van deze technologie beginnen te herkennen... technologiebedrijven zeggen 'AGI was te veel opgeblazen'".21 Dit illustreert perfect de dynamiek die Ng bekritiseert, en waarschuwt het bredere publiek en de bedrijfswereld om niet verstrikt te raken in een narratiefbubbel die wordt aangedreven door de unieke financiële prikkels van de tech-VC-wereld.

2.3 De Real-World Imperatief: Van Modelbouw naar Toepassing

Direct voortvloeiend uit zijn kritiek op de hype is Ng's kernboodschap: de echte kracht in het AI-tijdperk ligt in toepassing, niet alleen in creatie. Hij stelt dat "de echte game-changer... niet zal zijn wie de slimste machine bouwt, maar wie leert bestaande tools effectief te gebruiken".18 In zijn visie zullen de meest krachtige mensen in de komende decennia degenen zijn die weten hoe ze AI kunnen gebruiken om praktische problemen op te lossen, niet noodzakelijk degenen die nieuwe modellen vanaf nul kunnen bouwen.19
Hij adviseert ondernemers en ontwikkelaars consequent om zich te concentreren op het oplossen van echte wereldbehoeften in sectoren zoals gezondheidszorg en onderwijs in plaats van te jagen op "speculatieve doorbraken" die misschien nooit materialiseren.19 Zijn recente werk en keynotes hebben zich gericht op het bevorderen van "agentic AI-workflows", praktische ontwerppatronen—zoals reflectie, gereedschapsgebruik en planning—die bestaande modellen benutten om complexe zakelijke problemen op te lossen, van documentanalyse tot visuele inspectie in de productie.20 Deze focus op de toepassingslaag is het bepalende kenmerk van zijn werk met bedrijven zoals Landing AI en DeepLearning.AI, die zich inzetten om bedrijven en individuen te helpen AI-tools vandaag te gebruiken.22

2.4 Identificeren van de Werkelijke Risico's: Banenverlies boven Dodelijke Robots

Ng is diep sceptisch over speculatieve, langetermijnrisico's, en contrasteert deze scherp met de tastbare, kortetermijnmaatschappelijke uitdagingen die AI met zich meebrengt. Hij is beroemd om zijn afwijzing van angsten voor "kwade AI-dodende robots," en vergelijkt dergelijke angsten met "zorgen over overbevolking op de planeet Mars".16 Hij ziet "geen duidelijke weg hoe AI sentient kan worden" en stelt dat als het ooit zo is, het honderden of duizenden jaren kan duren.16
Meer puntig stelt hij dat deze "kwade AI-hype" dient als een handige rookgordijn, een manier om "een veel ernstiger probleem, namelijk banenverlies, te verdoezelen".16 Ng gelooft dat "AI-software in directe concurrentie zal zijn met veel mensen voor banen," en dat dit een probleem is dat de technologie-industrie moet "onder ogen zien".16 In plaats van hypothetische toekomstige risico's te debatteren, stelt hij dat de samenleving nu moet handelen om deze dreigende economische verstoring aan te pakken. Hij trekt een parallel met hoe de automatisering van de landbouw leidde tot de ontwikkeling van het moderne K-12 en universiteitssysteem, en roept op tot een fundamentele heroverweging van onderwijs en de creatie van een robuust sociaal vangnet. Hij stelt voor dat overheden de werklozen moeten helpen door de structuur en middelen te bieden om te studeren en zich om te scholen, zodat ze opnieuw kunnen toetreden tot een arbeidsmarkt die door AI is hervormd.16

Sectie 3: Melanie Mitchell: Het Voorzichtige Verhaal van de Cognitieve Wetenschapper

Melanie Mitchell, een professor aan het Santa Fe Institute, biedt een perspectief dat geworteld is in de cognitieve wetenschap en een diepe waardering voor de diepgaande complexiteit van menselijke intelligentie. Haar scepsis gaat niet primair over economische prikkels of engineeringarchitecturen, maar over de fundamentele kloof tussen wat AI-systemen kunnen doen en wat ze kunnen begrijpen. Ze waarschuwt dat het grootste gevaar dat we onder ogen zien niet afkomstig is van kunstmatige superintelligentie, maar van een verkeerd vertrouwen in de mogelijkheden van diep "domme" machines.

3.1 De Spook van "Kunstmatige Domheid"

Mitchell's centrale argument is dat als het gaat om zorgen op korte termijn, "superintelligentie ver beneden op de lijst zou moeten staan. In feite is het tegenovergestelde van superintelligentie het echte probleem".24 De sleutelkwestie is de inherente "broosheid" van zelfs de meest bekwame AI-systemen.24 Deze systemen excelleren in patroonherkenning binnen de smalle grenzen van hun trainingsdata, maar kunnen falen op onverwachte en onzinnige manieren wanneer ze worden geconfronteerd met situaties die zelfs maar iets afwijken van wat ze eerder hebben gezien.24
Deze broosheid leidt tot wat zij en anderen "kunstmatige domheid" hebben genoemd: subtiele, onvoorspelbare mislukkingen die een complete afwezigheid van gezond verstand verraden.27 Ze geeft talloze voorbeelden: een zelfrijdende auto die een voetganger in een ongebruikelijke houding niet herkent; een state-of-the-art visiesysteem dat leert het concept "dier" te associëren met de "onscherpe groene achtergrond" die gebruikelijk is in zijn trainingsfoto's in plaats van met het dier zelf; of een deep reinforcement learning-agent die is getraind om het spel Breakout te spelen en, na het spel te hebben beheerst, volledig faalt wanneer de paddle met slechts een paar pixels omhoog wordt verplaatst omdat het nooit het concept van een paddle als object heeft geleerd.29 Dit standpunt wordt memorabel samengevat in een citaat dat ze vaak aanhaalt van AI-onderzoeker Pedro Domingos: "Mensen maken zich zorgen dat computers te slim worden en de wereld overnemen, maar het echte probleem is dat ze te dom zijn en de wereld al hebben overgenomen".25

3.2 De Menselijke Tendens om te Overschatten

Het gevaar van kunstmatige domheid wordt vergroot door een overeenkomstige tekortkoming in de menselijke psychologie: onze aangeboren neiging om de mogelijkheden van AI te overschatten. Mitchell waarschuwt dat "het meest zorgwekkende aspect van AI-systemen op korte termijn is dat we ze te veel autonomie zullen geven zonder volledig bewust te zijn van hun beperkingen en kwetsbaarheden".24 Dit gebeurt omdat we instinctief "AI-systemen anthropomorfiseren," menselijke kwaliteiten van begrip, intentie en betrouwbaarheid op hen projecteren waar die niet bestaan.24 De vloeiende taal van een LLM of de supermenselijke vaardigheid van een spelende AI verleidt ons om te geloven dat het systeem een algemene competentie bezit die het eenvoudigweg niet heeft.
Dit creëert een gevaarlijke sociotechnische mislukkingsmodus. Het risico is niet alleen dat de AI broos is (een technisch probleem), maar dat onze gebrekkige menselijke psychologie ons ertoe leidt deze broze systemen in risicovolle omgevingen zoals geneeskunde, financiën en transport in te zetten, hen veel meer te vertrouwen dan hun werkelijke mogelijkheden rechtvaardigen. De catastrofe, in dit perspectief, wordt niet veroorzaakt door een kwaadaardige superintelligentie, maar door een verkeerd vertrouwen in een oppervlakkig competente maar fundamenteel onintelligente tool.
Mitchell plaatst ook de huidige golf van enthousiasme binnen de historische "boom- en bustcyclus" van het veld, gekenmerkt door afwisselende "AI Lente" van immense optimisme en financiering, gevolgd door "AI Winter" van teleurstelling en budgetcuts wanneer grote beloften niet worden waargemaakt.28 Ze herinnert zich dat ze tijdens de AI-winter van de jaren '90 werd geadviseerd om zelfs de term "kunstmatige intelligentie" niet te gebruiken in haar sollicitaties, een scherp contrast met de huidige omgeving waarin de term alomtegenwoordig is.30 Dit historische perspectief dient als een cruciale realiteitscheck op huidige claims, wat suggereert dat de huidige hype misschien slechts een andere piek is voor een onvermijdelijke daling van desillusie.

3.3 De Barrière van Betekenis

In het hart van Mitchell's kritiek ligt haar concept van de "barrière van betekenis".27 Dit is haar verklaring voor waarom AI-systemen zo broos en dom zijn. Putten uit het werk van filosoof Gian-Carlo Rota, stelt ze dat zelfs de meest geavanceerde AI deze barrière nog niet heeft doorbroken; dat wil zeggen, de systemen "begrijpen de situaties die ze tegenkomen niet op een betekenisvolle, menselijke manier".32 Ze kunnen taal verwerken zonder deze te begrijpen, en beelden herkennen zonder hun betekenis te begrijpen.27
Dit gebrek aan begrip is het meest evident in hun diepe tekortkoming aan gezond verstand—de enorme, intuïtieve kennis over de fysieke en sociale wereld die mensen gebruiken om bijna elke situatie te navigeren.28 Dit tekort wordt blootgelegd door hun slechte prestaties op linguïstische puzzels zoals de Winograd Schema Challenge, die vereist dat een voornaamwoord wordt gedisambiguëerd op basis van wereldkennis (bijv. "De trofee paste niet in de bruine koffer omdat deze te groot was." Naar wat verwijst "het"?). De moeilijkheid die AI heeft met zo'n eenvoudige taak leidde onderzoeker Oren Etzioni tot de opmerking: "Wanneer AI niet kan bepalen waar 'het' naar verwijst in een zin, is het moeilijk te geloven dat het de wereld zal overnemen".27 Voor Mitchell is dit gebrek aan oprechte, gegronde begrip de grootste hindernis voor het bereiken van robuuste, betrouwbare en betrouwbare AI.

3.4 De Weg Vooruit Door Analogie en Abstractie

Mitchell's voorgestelde weg vooruit is niet gericht op een specifieke architectuur, maar op het cultiveren van de kern cognitieve vaardigheden die zij als fundamenteel voor menselijke intelligentie beschouwt. Ze stelt dat de sleutel tot het overwinnen van de barrière van betekenis ligt in het ontwikkelen van AI die robuuste abstracties kan maken en vloeibare analogieën kan vormen.36 Het is deze vaardigheid om de abstracte essentie van een situatie te zien en deze te koppelen aan nieuwe, verschillende situaties die ware generalisatie en kennisoverdracht mogelijk maakt—een kenmerk van menselijk leren en een kritieke zwakte van de huidige AI.37
Ze suggereert dat AI, om deze diepgaande, flexibele begrip te verwerven, misschien meer moet leren zoals een menselijk kind. Dit wijst op de noodzaak van belichaming en ontwikkelingsleren, waarbij een AI-systeem, misschien gehuisvest in een robot, direct de fysieke en sociale wereld kan ervaren en ermee kan interageren.28 Dit sluit aan bij het denken van Rodney Brooks, wat suggereert dat intelligentie niet kan worden gescheiden van fysieke ervaring. Het doel is om verder te gaan dan systemen die leren van statische datasets naar systemen die leren door actieve, belichaamde verkenning, waardoor de rijke, gegronde, gezond verstand basis wordt opgebouwd die vereist is voor waar begrip.

Sectie 4: Rodney Brooks: De Robotica's Gronding in de Realiteit

Rodney Brooks, voormalig directeur van het MIT Computer Science and Artificial Intelligence Laboratory en medeoprichter van iRobot, is de intellectuele basis van de moderne AI-sceptische traditie. Meer dan vier decennia heeft hij een consistente en invloedrijke campagne gevoerd tegen het idee van ontlichaamde intelligentie. Zijn filosofie, gesmeed in de praktische uitdagingen van robotica, biedt een krachtige en blijvende argumentatie dat ware intelligentie niet kan worden gescheiden van fysieke interactie met de echte wereld.

4.1 Intelligentie Zonder Representatie: De Fundamentele Kritiek

Brooks's meest fundamentele bijdrage kwam in de late jaren '80 en vroege jaren '90, toen het dominante paradigma in AI de symbolensysteemhypothese was. Deze klassieke benadering decompositieerde intelligentie in een reeks abstracte, functionele modules: perceptie zou een symbolisch model van de wereld creëren, een centrale redeneerengine zou plannen op basis van dat model, en een actuator-module zou het plan uitvoeren.39 Brooks betoogde dat deze hele benadering "fundamenteel gebrekkig" en biologisch onwaarschijnlijk was.39
In zijn baanbrekende paper uit 1990, "Olifanten Spelen Geen Schaak," betoogde hij dat AI-onderzoek te veel gericht was op de "expert" gedragingen van een kleine menselijke elite (zoals schaken) terwijl het het veel fundamentelere en moeilijkere probleem van basismobiliteit en overleving negeerde dat alle dieren beheersen.40 Hij stelde een alternatief voor op basis van de fysieke grondingshypothese: het idee dat de representaties van een systeem direct moeten worden gegrond in de fysieke wereld door middel van perceptie en actie.41 Het meest elegante en efficiënte model van de wereld, stelde hij beroemd, is "de wereld is zijn eigen beste model".39
Hij bracht deze filosofie in de praktijk met zijn subsumptiearchitectuur.41 Dit was een bottom-up, gelaagd systeem dat het centrale planningsmodel verliet. In plaats daarvan was het opgebouwd uit eenvoudige, reactieve, gedrag-genererende modules. Een robot's laagste laag zou een eenvoudig gedrag kunnen zijn: "als een sensor een obstakel detecteert, draai weg." Een hogere laag zou een ander gedrag kunnen toevoegen: "zwerf willekeurig." Deze hogere laag zou de lagere kunnen "subsumeren", bijvoorbeeld door het zwerfg gedrag te onderdrukken wanneer een obstakel werd gedetecteerd.42 Brooks toonde aan dat complexe, schijnbaar doelgerichte gedragingen—zoals een robot die een kamer verkent terwijl hij objecten vermijdt—kunnen voortkomen uit de interactie van deze eenvoudige, onafhankelijke en fysiek gegronde modules, allemaal zonder een centrale, symbolische representatie van de kamer.42

4.2 Van Symbolische AI naar "Meesterlijke Bullshitters"

Brooks's decennialange kritiek vindt nieuwe leven en relevantie in het tijdperk van LLM's. Hij ziet een directe filosofische afstamming van de ongegronde symbolen van klassieke AI naar de ongegronde teksttokens van moderne generatieve modellen. Zijn beoordeling van LLM's is verwoestend: hij noemt ze "meesterlijke bullshitters".44 De term is niet alleen een pejoratief; het is een nauwkeurige technische kritiek. Net als een menselijke bullshitter is een LLM bezorgd over het produceren van een plausibel klinkende output, niet over de waarheidsgetrouwhheid of verbinding met de realiteit. "Ze weten niet wat waar is," betoogt Brooks, maar hebben eenvoudig geleerd van een enorme corpus tekst "welke woorden een beetje samen werken".44
Hij betoogt dat mensen uniek kwetsbaar zijn voor deze vorm van misleiding omdat we "verleid worden door taal".45 We zien vloeiende linguïstische output en schrijven instinctief begrip, intentie en intelligentie toe aan de bron ervan. Brooks waarschuwt dat we niet "verleid moeten worden door LLM's' gemakkelijke gebruik van taal om te geloven dat ze magische capaciteiten hebben".44 In wezen stelt hij dat deze systemen geavanceerde autocorrelatie-engines zijn die geen model van de realiteit bezitten en, cruciaal, geen begrip van causaliteit.45 Deze kritiek is identiek in geest aan zijn oorspronkelijke argument tegen symbolische AI: het systeem manipuleert tokens (of het nu logische symbolen of woorden zijn) die geen inherente betekenis hebben voor de machine zelf.

4.3 Het Langzame Tempo van Verandering in de Echte Wereld

Een belangrijk onderdeel van Brooks's scepsis is zijn verzet tegen de wijdverspreide veronderstelling van exponentiële vooruitgang, een kernprincipe van het "Singularity" narratief. Hij betoogt dat exponentials "niet voor altijd kunnen opereren" en dat veel technologische trends die exponentieel lijken, in feite S-curves van groei zijn die uiteindelijk rijpen en stabiliseren.45 Hij heeft zelfs een acroniem bedacht voor de sociale druk om deze narratieven te accepteren: "FOBAWTPALSL" (Fear of Being a Wimpy Techno-Pessimist and Looking Stupid Later), dat de neiging beschrijft voor mensen om kritiekloos hype te omarmen om niet als technologie-ontkenners te worden gezien.44
Zijn krachtigste argument tegen ongecontroleerde exponentiële groei is geworteld in de beperkingen van de fysieke wereld. Terwijl berekeningen een tijdlang de wet van Moore kunnen volgen, doet de echte wereld dat niet. Hij wijst erop dat we al de fysieke grenzen van energie-efficiëntie voor een robot die een object optilt naderen, wat betekent dat de kosten van fysieke robotarbeid niet exponentieel zullen blijven dalen.44 Bovendien is het inzetten van technologie in de echte wereld onderhevig aan immense wrijving. Hij citeert vaak de trage, decennialange overgang van het internet van het IPv4-protocol naar IPv6 als een prime voorbeeld. Hoewel IPv6 een puur digitale en veel superieure technologie is, is de adoptie ervan belemmerd door de immense kosten en coördinatie die nodig zijn om de bestaande infrastructuur van de wereld bij te werken.44 Een AGI, hoe intelligent ook, kan niet magisch de materiële, economische en systemische traagheid van de fysieke wereld overwinnen. Dit biedt een krachtige realiteitscheck die het abstracte concept van een "snelle opkomst" singulariteit verankert in de rommelige, trage en wrijvingsvolle realiteit van de wereldeconomie.

4.4 De Primacy van Menselijke Agency

Onder al het werk van Brooks ligt een consistente ontwerpfilosofie voor technologie. Hij houdt vol dat het doel van AI en robotica moet zijn om "menselijke capaciteiten te verbeteren in plaats van te proberen ze te repliceren".44 Hij betoogt dat mensen nieuwe technologieën pas echt accepteren en adopteren wanneer ze het gevoel hebben dat ze een zekere controle en agency behouden.44 Gebruikers willen de mogelijkheid hebben om te begrijpen wat het systeem doet en, het belangrijkst, om in te grijpen en het te overrulen wanneer het niet presteert zoals verwacht.45
Hij wijst op de aanhoudende uitdagingen van volledig autonome, of "zelfrijdende," auto's als een belangrijk voorbeeld van dit principe in actie.44 Een belangrijke barrière voor hun acceptatie is de ambiguïteit van controle en het gebrek aan een duidelijke, intuïtieve manier voor de menselijke "bestuurder" om agency over de acties van het voertuig te behouden. Voor Brooks is een succesvol AI-systeem er niet een dat de mens vervangt, maar een dat een betrouwbaar en voorspelbaar hulpmiddel wordt dat aansluit bij het eigen model van de wereld van de mens, waardoor de mens uiteindelijk de controle behoudt.44

Sectie 5: Convergenties, Divergenties en het Brede Sceptische Landschap

Hoewel Yann LeCun, Andrew Ng, Melanie Mitchell en Rodney Brooks elk een uniek perspectief inbrengen, weven hun argumenten samen om een krachtig en samenhangend tegenverhaal te vormen tegen de dominante hype rond AGI. Het analyseren van hun convergentie- en divergentiepunten, en het situeren binnen een bredere intellectuele landschap, onthult de diepte en de strengheid van het pleidooi voor Tool AI.

5.1 Vergelijkend Kader Tabel

Om de verschillende maar overlappende posities van deze vier denkers te verduidelijken, biedt de volgende tabel een hoog-niveau samenvatting van hun kernkritieken, voorgestelde oplossingen en standpunten over AGI en existentiële risico's.
Tabel 1: Een Vergelijkend Kader van Prominente AI-Sceptici
Voorstander
Yann LeCun
Andrew Ng
Melanie Mitchell
Rodney Brooks

5.2 Gemeenschappelijke Draad: De Anti-Cartesiaanse Consensus

De krachtigste gemeenschappelijke draad die deze vier denkers verenigt, is hun gedeelde afwijzing van een ontlichaamde, puur computationele visie op intelligentie. In wezen vormen ze een "anti-Cartesiaanse" consensus, die zich verzet tegen het idee van een geest los van een lichaam en een wereld. Elk, op hun eigen manier, stelt dat intelligentie niet slechts de manipulatie van abstracte symbolen in een vacuüm is.
Rodney Brooks is de oorsprong van deze visie in moderne AI, met zijn decennialange nadruk op fysieke gronding en belichaming als vereisten voor intelligentie.41 Yann LeCun weerlegt dit door taal-alleen modellen te verwerpen en te eisen dat toekomstige AI leert van hoge-bandbreedte sensorische data om voorspellende wereldmodellen te bouwen, net zoals een dier dat doet.2 Melanie Mitchell betoogt dat de "barrière van betekenis" en de verwerving van gezond verstand alleen kunnen worden overwonnen door belichaamd, ontwikkelingsleren dat concepten in wereldse ervaring verankert.28 En hoewel Andrew Ng's focus meer economisch is, behandelt zijn "elektriciteit" analogie AI inherent als een hulpmiddel dat in de wereld moet worden toegepast, waarbij de waarde ervan voortkomt uit de werkelijke effecten, niet uit het bestaan ervan als een ontlichaamde geest in een vat. Deze gedeelde overtuiging dat intelligentie moet worden gesitueerd en gegrond vormt de filosofische kern van het Tool AI-perspectief.

5.3 Punten van Contention: Divergente Paden en Prioriteiten

Ondanks hun filosofische afstemming, stellen deze denkers verschillende oplossingen voor en prioriteren ze verschillende risico's. Terwijl ze het eens zijn over het fundamentele probleem van ontlichaamde AI, divergeren hun paden vooruit. Brooks heeft historisch gepleit voor een bottom-up, gedrag-gebaseerde robotica-aanpak zoals de subsumptiearchitectuur.42 LeCun, afkomstig uit een deep learning-achtergrond, stelt een complexere, top-down (hoewel nog steeds gegronde) architectuur voor in JEPA, die gericht is op het leren van abstracte wereldmodellen door zelfsupervisie.7 Mitchell, de cognitieve wetenschapper, is minder gericht op een specifieke architectuur en meer op het identificeren van de noodzakelijke cognitieve capaciteiten—zoals analogie en abstractie—die elke succesvolle architectuur moet bereiken.37 Ng blijft grotendeels agnostisch over architectuur, en richt zich in plaats daarvan op de economische en toepassingslaag waar bestaande tools waarde kunnen creëren.20
Hun primaire zorgen verschillen ook. Ng richt zich op het onmiddellijke, tastbare en zekere economische risico van banenverlies.16 Mitchell maakt zich zorgen over het kortetermijnsociotechnische risico van mensen die broze, "domme" systemen verkeerd toepassen in kritieke domeinen vanwege onze neiging om ze te overschatten.24 LeCun's zorgen zijn zowel technisch als politiek: ervoor zorgen dat toekomstige systemen controleerbaar zijn bij ontwerp en dat hun ontwikkeling wordt gedemocratiseerd door open source om de concentratie van macht te voorkomen.13 Brooks, de veteranenwaarnemer, richt zich op het ontkrachten van de hype zelf, en herinnert iedereen aan de fysieke en systemische beperkingen die echte vooruitgang in de echte wereld veel langzamer en moeilijker maken dan populaire verhalen suggereren.45

5.4 De Sceptici Situeren: Het Brede Landschap

De opvattingen van deze vier voorstanders worden verrijkt wanneer ze worden geplaatst in de context van andere prominente AI-critici die verschillende maar complementaire uitdagingen aanbrengen.
Gary Marcus, een cognitieve wetenschapper en ondernemer, deelt Mitchell's focus op de broosheid van AI en het gebrek aan echt begrip. Zijn voorgestelde oplossing is echter anders. Hij betoogt dat deep learning "data-hongerig, oppervlakkig en broos" is en moet worden aangevuld met technieken uit de klassieke, symbol-manipulerende AI.46 Zijn oproep voor neuro-symbolische "hybride modellen" vertegenwoordigt een andere weg vooruit, die probeert de regelgebaseerde redenering van klassieke AI expliciet te integreren met de patroonherkenningsterkte van deep learning.46 Dit staat in contrast met LeCun's visie, die gericht is op het bereiken van redeneervaardigheden vanuit een puur deep learning-gebaseerde, zelfsupervised basis.
Judea Pearl, een andere Turing Award-winnaar, biedt misschien de meest fundamentele kritiek op het hele moderne machine learning-paradigma. Hij betoogt dat huidige AI, inclusief deep learning, "vastzit op de eerste trede" van zijn drie-treden "ladder van causaliteit".48 Systemen zijn bedreven in het vinden van correlaties in data (Niveau 1: Zien), maar zijn niet in staat om te redeneren over interventies (Niveau 2: Doen) of tegenfeitelijke "wat als" vragen te stellen (Niveau 3: Verbeelden).50 Pearl stelt dat zonder een ingebouwde capaciteit voor causale redenering, machines slechts geavanceerde "curve fitting" uitvoeren en nooit echte, menselijke intelligentie kunnen bereiken.49 Deze kritiek introduceert een cruciale dimensie—causaliteit—die grotendeels onbesproken blijft door de andere sceptici en vormt een diepgaande uitdaging voor het hele veld.

Conclusie: Voorbij de Hype—Waardevolle en Betrouwbare AI Bouwen

De collectieve argumenten van de Tool AI-voorstanders presenteren een formidabele en noodzakelijke tegenstem tegen de speculatieve narratieven die zo vaak de gesprekken over de toekomst domineren. Hun scepsis is geen pessimistische afwijzing van technologie, maar een pragmatische en constructieve oproep tot intellectuele eerlijkheid en wetenschappelijke rigor. Het is een eis dat het veld van kunstmatige intelligentie zich verankert in het oplossen van de moeilijke, fundamentele problemen van het heden voordat het zich overgeeft aan fantasieën over de toekomst.
De terugkerende thema's zijn duidelijk en overtuigend. Ware intelligentie is geen ontlichaamde algoritme, maar is diep verweven met sensorische ervaring, fysieke interactie en een gegronde begrip van de wereld. De meest significante obstakels zijn niet het bereiken van supermenselijke snelheid, maar het inbedden van basisgezond verstand. De meest dringende risico's komen niet van hypothetische, kwaadaardige superintelligenties, maar van de zeer reële broosheid van onze huidige systemen en onze eigen psychologische vooroordelen die ons ertoe leiden hen ongepast te vertrouwen.
Uiteindelijk is het pleidooi voor Tool AI een pleidooi voor een meer volwassen, verantwoordelijke en productieve visie voor het veld. Het suggereert dat het juiste doel van AI-onderzoek niet de quasi-mythologische zoektocht naar een kunstmatige god moet zijn, maar de geduldige, moeilijke en diep waardevolle engineering van een divers ecosysteem van betrouwbare, transparante en voordelige tools. Het doel moet zijn om systemen te bouwen die echte menselijke problemen oplossen, menselijke intelligentie vergroten en tastbare economische en sociale waarde creëren. Deze gegronde aanpak, zo suggereert het bewijs, is het ware pad naar het realiseren van het immense en transformerende potentieel van kunstmatige intelligentie.
Werken geciteerd
en.wikipedia.org, geraadpleegd op 23 juli 2025, <https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Guide_for_Thinking_Humans>
AI En De Beperkingen Van Taal - Noema Magazine, geraadpleegd op 23 juli 2025, <https://www.noemamag.com/ai-and-the-limits-of-language/>
Yann LeCun Benadrukt de Belofte van AI - NYAS - De New York Academy of Sciences, geraadpleegd op 23 juli 2025, <https://www.nyas.org/ideas-insights/blog/yann-lecun-emphasizes-the-promise-ai/>
Waarom Kan AI Zijn Eigen Ontdekkingen Niet Doen? — Met Yann LeCun ..., geraadpleegd op 23 juli 2025, <https://www.youtube.com/watch?v=qvNCVYkHKfg&pp=0gcJCfwAo7VqN5tD>
Yann LeCun: Een Pad naar Autonome Machine-intelligentie | Shaped Blog, geraadpleegd op 23 juli 2025, <https://www.shaped.ai/blog/yann-lecun-a-path-towards-autonomous-machine-intelligence>
Een Pad naar Autonome Machine-intelligentie Versie 0.9.2, 2022-06-27 - OpenReview, geraadpleegd op 23 juli 2025, <https://openreview.net/pdf?id=BZ5a1r-kVsf>
Een Pad naar Autonome Machine-intelligentie - Temple CIS, geraadpleegd op 23 juli 2025, <https://cis.temple.edu/tagit/presentations/A%20Path%20Towards%20Autonomous%20Machine%20Intelligence.pdf>
Een Pad naar Autonome Machine-intelligentie: Verkenning van Hiërarchische Voorspellende Architecturen | door Lawrence Knight | Medium, geraadpleegd op 23 juli 2025, <https://medium.com/@LawrencewleKnight/a-path-towards-autonomous-machine-intelligence-exploring-hierachical-predictive-architectures-48ba2ca950af>
Yann LeCun: Van Machine Learning naar Autonome Intelligentie - YouTube, geraadpleegd op 23 juli 2025, <https://www.youtube.com/watch?v=VRzvpV9DZ8Y>
Een Pad naar Autonome Machine-intelligentie met Dr. Yann LeCun - YouTube, geraadpleegd op 23 juli 2025, <https://www.youtube.com/watch?v=EvSe0ktD95k>
Yann LeCun over AGI en AI Veiligheid - Effectieve Altruïsme Forum, geraadpleegd op 23 juli 2025, <https://forum.effectivealtruism.org/posts/LSzHmdCdsFieMXLcL/yann-lecun-on-agi-and-ai-safety>
Yann LeCun over AGI en AI Veiligheid - LessWrong, geraadpleegd op 23 juli 2025, <https://www.lesswrong.com/posts/Zfik4xESDyahRALKk/yann-lecun-on-agi-and-ai-safety>
De Vorm van AI die Komt! Yann LeCun op de AI Actie Top 2025 - YouTube, geraadpleegd op 23 juli 2025, <https://www.youtube.com/watch?v=xnFmnU0Pp-8>
Andrew Ng over waarom Kunstmatige Intelligentie de nieuwe elektriciteit is - EECS ..., geraadpleegd op 23 juli 2025, <https://eecs.berkeley.edu/news/andrew-ng-why-artificial-intelligence-new-electricity/>
AI is de Nieuwe Elektriciteit - Dr. Andrew Ng - YouTube, geraadpleegd op 23 juli 2025, <https://www.youtube.com/watch?v=fgbBtnCvcDI>
Andrew Ng: Waarom AI De Nieuwe Elektriciteit Is | Stanford Graduate School of Business, geraadpleegd op 23 juli 2025, <https://www.gsb.stanford.edu/insights/andrew-ng-why-ai-new-electricity>
Waarom AI De 'Nieuwe Elektriciteit' Is – Knowledge@Wharton - Gerd Leonhard, geraadpleegd op 23 juli 2025, <https://futuristgerd.com/2017/11/why-ai-is-the-new-electricity-knowledgewharton/>
Andrew Ng: Ware AI-kracht ligt in Gebruik, Niet in het Najagen van AGI, geraadpleegd op 23 juli 2025, <https://www.thehansindia.com/technology/tech-news/andrew-ng-true-ai-power-lies-in-usage-not-in-chasing-agi-987243>
'Gewoon ridicuul,' zegt de oprichter van Google Brain over de hype dat AI alle banen zal afpakken, deelt tips over hoe iedereen krachtig kan worden - The Economic Times, geraadpleegd op 23 juli 2025, <https://m.economictimes.com/news/new-updates/just-ridiculous-says-google-brain-founder-on-hype-about-ai-taking-away-all-jobs-shares-tips-how-anyone-can-become-powerful/articleshow/122633320.cms>
Andrew Ng over de Opkomst van AI Agents: Herdefiniëren van Automatisering en Innovatie - Medium, geraadpleegd op 23 juli 2025, <https://medium.com/@muslumyildiz17/andrew-ng-on-the-rise-of-ai-agents-redefining-automation-and-innovation-440565ce633b>
Oprichter van Google Brain zegt dat AGI te veel is opgeblazen, echte kracht ligt in weten hoe AI te gebruiken en niet in het bouwen ervan - Reddit, geraadpleegd op 23 juli 2025, <https://www.reddit.com/r/ArtificialInteligence/comments/1lzmu7i/google_brain_founder_says_agi_is_overhyped_real/>
Andrew Ng - AI Keynote Spreker, geraadpleegd op 23 juli 2025, <https://www.aurumbureau.com/speaker/andrew-ng/>
Andrew Ng: Kunstmatige Intelligentie is de Nieuwe Elektriciteit - YouTube, geraadpleegd op 23 juli 2025, <https://www.youtube.com/watch?v=21EiKfQYZXc>
Citaat van Melanie Mitchell: “In elke rangschikking van zorgen op korte termijn ..., geraadpleegd op 23 juli 2025, <https://www.goodreads.com/quotes/10078945-in-any-ranking-of-near-term-worries-about-ai-superintelligence-should>
Kunstmatige Intelligentie Citaten van Melanie Mitchell - Goodreads, geraadpleegd op 23 juli 2025, <https://www.goodreads.com/work/quotes/67780615-artificial-intelligence-a-guide-for-thinking-humans>
[2012.06058] Volgende Golf Kunstmatige Intelligentie: Robuust, Verklaarbaar, Aanpasbaar, Ethisch en Verantwoordelijk - arXiv, geraadpleegd op 23 juli 2025, <https://arxiv.org/abs/2012.06058>
Review van Kunstmatige Intelligentie: Een Gids voor Denkende Mensen ..., geraadpleegd op 23 juli 2025, <https://medium.com/@adnanmasood/review-of-artificial-intelligence-a-guide-for-thinking-humans-an-insiders-appraisal-of-melanie-5a489a6680f1>
Melanie Mitchell: 'De grote sprong in kunstmatige intelligentie zal komen wanneer het wordt ingebed in robots die de wereld ervaren als een kind' | Technologie, geraadpleegd op 23 juli 2025, <https://english.elpais.com/technology/2024-04-14/melanie-mitchell-the-big-leap-in-artificial-intelligence-will-come-when-it-is-inserted-into-robots-that-experience-the-world-like-a-child.html>
Mindscape 68 | Melanie Mitchell over Kunstmatige Intelligentie en de Uitdaging van Gezond Verstand - YouTube, geraadpleegd op 23 juli 2025, <https://www.youtube.com/watch?v=F9Il2Q0mCDI>
Transcript van Aflevering 33 – Melanie Mitchell over de Elementen van AI - The Jim Rutt Show, geraadpleegd op 23 juli 2025, <https://jimruttshow.blubrry.net/the-jim-rutt-show-transcripts/transcript-of-episode-33-melanie-mitchell-on-the-elements-of-ai/>
Evenementen: Kunstmatige Intelligentie en de “Barrière” van Betekenis | Santa Fe Institute, geraadpleegd op 23 juli 2025, <https://www.santafe.edu/events/artificial-intelligence-and-barrier-meaning>
Over het Doorbreken van de Barrière van Betekenis in AI - Melanie Mitchell, geraadpleegd op 23 juli 2025, <https://melaniemitchell.me/PapersContent/AIMagazine2020.pdf>
Kunstmatige Intelligentie en de “Barrière van Betekenis” PROFESSOR MELANIE MITCHELL - Trinity College Dublin, geraadpleegd op 23 juli 2025, <https://www.tcd.ie/Neuroscience/RPPF/assets/pdfs/melanie_mitchell_poster.pdf>
68 | Melanie Mitchell over Kunstmatige Intelligentie en de Uitdaging van Gezond Verstand, geraadpleegd op 23 juli 2025, <https://www.preposterousuniverse.com/podcast/2019/10/14/68-melanie-mitchell-on-artificial-intelligence-and-the-challenge-of-common-sense/>
Podcast: Ep. 1: Wat is Intelligentie | Santa Fe Institute, geraadpleegd op 23 juli 2025, <https://www.santafe.edu/culture/podcasts/ep-1-what-is-intelligence?tab=transcript>
Melanie Mitchell over Kan Kunstmatige Intelligentie Menselijk Denken Verslaan | MHC Ep 203, geraadpleegd op 23 juli 2025, <https://www.youtube.com/watch?v=fmhqrm1er48>
De Computerwetenschapper die AI Traint om te Denken met Analogieën - Quanta Magazine, geraadpleegd op 23 juli 2025, <https://www.quantamagazine.org/melanie-mitchell-trains-ai-to-think-with-analogies-20210714/>
Kunstmatige Intelligentie en de Barrière van Betekenis, geraadpleegd op 23 juli 2025, <https://www.tcd.ie/Neuroscience/RPPF/assets/pdfs/melanie_mitchell.pdf>
Olifanten Spelen Geen Schaak - Mensen - MIT, geraadpleegd op 23 juli 2025, <https://people.csail.mit.edu/brooks/papers/elephants.pdf>
Rodney Brooks - Wikipedia, geraadpleegd op 23 juli 2025, <https://en.wikipedia.org/wiki/Rodney_Brooks>
Olifanten Spelen Geen Schaak - JAWS, geraadpleegd op 23 juli 2025, <https://msujaws.wordpress.com/2010/11/18/elephants-dont-play-chess/>
Olifanten Spelen Geen Schaak, geraadpleegd op 23 juli 2025, <https://www.cse.unr.edu/~monica/Courses/CS493-790/Presentations/Yan1.ppt>
Het Onderzoeken van de Geldigheid, Waarheid en Relevantie van Rodney A. Brooks's Argument Tegen de Noodzaak van Representatie in Intelligente Systemen | The Classic Journal, geraadpleegd op 23 juli 2025, <https://theclassicjournal.uga.edu/index.php/2025/05/09/examining-the-validit/>
De Myth Buster: Rodney Brooks Breekt de Hype Rond AI Af ..., geraadpleegd op 23 juli 2025, <https://www.robust.ai/blog/newsweekaiseries>
De Myth Buster: Rodney Brooks Breekt de Hype Rond AI Af ..., geraadpleegd op 23 juli 2025, <https://www.newsweek.com/rodney-brooks-ai-impact-interview-futures-2034669>
Ter verdediging van scepsis over deep learning | door Gary Marcus ..., geraadpleegd op 23 juli 2025, <https://medium.com/@GaryMarcus/in-defense-of-skepticism-about-deep-learning-6e8bfd5ae0f1>
deep learning a critical appraisal.formatted.pages - arXiv, geraadpleegd op 23 juli 2025, <https://arxiv.org/abs/1801.00631>
Op 87-jarige leeftijd kan Pearl nog steeds van gedachten veranderen - LessWrong, geraadpleegd op 23 juli 2025, <https://www.lesswrong.com/posts/uFqnB6BG4bkMW23LR/at-87-pearl-is-still-able-to-change-his-mind>
Om Werkelijk Intelligente Machines te Bouwen, Leer Ze Oorzaak en Gevolg ..., geraadpleegd op 23 juli 2025, <https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515/>
Het Boek van Waarom: Verkenning van het ontbrekende stuk van kunstmatige ..., geraadpleegd op 23 juli 2025, <https://bdtechtalks.com/2019/12/09/judea-pearl-the-book-of-why-ai-causality/>

---
*Vertaald door AI. Controleer de originele Engelse versie bij twijfel.*